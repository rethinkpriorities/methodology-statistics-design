<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
  <meta charset="utf-8">
  <meta name="generator" content="quarto-0.9.243">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Vignette: Predictive/ML modeling of donations in EA Survey data with Tidymodels and workflow</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>

  <script src="eas_ml_modeling_vignette_files/libs/clipboard/clipboard.min.js"></script>
  <script src="eas_ml_modeling_vignette_files/libs/quarto-html/quarto.js"></script>
  <script src="eas_ml_modeling_vignette_files/libs/quarto-html/popper.min.js"></script>
  <script src="eas_ml_modeling_vignette_files/libs/quarto-html/tippy.umd.min.js"></script>
  <script src="eas_ml_modeling_vignette_files/libs/quarto-html/anchor.min.js"></script>
  <link href="eas_ml_modeling_vignette_files/libs/quarto-html/tippy.css" rel="stylesheet">
  <link id="quarto-text-highlighting-styles" href="eas_ml_modeling_vignette_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet">
  <script src="eas_ml_modeling_vignette_files/libs/bootstrap/bootstrap.min.js"></script>
  <link href="eas_ml_modeling_vignette_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
  <link href="eas_ml_modeling_vignette_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet">
  <script async="" src="https://hypothes.is/embed.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc">
<h2 id="toc-title">Table of contents</h2>
<ul>
<li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"> <span class="header-section-number">1</span> Introduction</a></li>
<li><a href="#setup" id="toc-setup" class="nav-link" data-scroll-target="#setup"> <span class="header-section-number">2</span> Setup</a>
<ul class="collapse">
<li><a href="#packages-and-functions" id="toc-packages-and-functions" class="nav-link" data-scroll-target="#packages-and-functions"> <span class="header-section-number">2.1</span> Packages and functions</a></li>
<li><a href="#reading-in-data-from-a-repo" id="toc-reading-in-data-from-a-repo" class="nav-link" data-scroll-target="#reading-in-data-from-a-repo"> <span class="header-section-number">2.2</span> Reading in data from a repo</a></li>
<li><a href="#some-ad-hoc-data-cleaning-and-filtering-to-enable-modeling" id="toc-some-ad-hoc-data-cleaning-and-filtering-to-enable-modeling" class="nav-link" data-scroll-target="#some-ad-hoc-data-cleaning-and-filtering-to-enable-modeling"> <span class="header-section-number">2.3</span> Some ad-hoc data cleaning and filtering, to enable modeling</a></li>
</ul></li>
<li><a href="#mlsplits" id="toc-mlsplits" class="nav-link" data-scroll-target="#mlsplits"> <span class="header-section-number">3</span> Machine learning environment ‘splits’</a>
<ul class="collapse">
<li><a href="#create-training-and-test-data" id="toc-create-training-and-test-data" class="nav-link" data-scroll-target="#create-training-and-test-data"> <span class="header-section-number">3.1</span> Create training and test data</a></li>
<li><a href="#create-partitions-folds-for-validation-tuning-step" id="toc-create-partitions-folds-for-validation-tuning-step" class="nav-link" data-scroll-target="#create-partitions-folds-for-validation-tuning-step"> <span class="header-section-number">3.2</span> Create partitions (folds) for validation ‘tuning’ step</a></li>
</ul></li>
<li><a href="#defining-and-creating-elements-of-the-modeling" id="toc-defining-and-creating-elements-of-the-modeling" class="nav-link" data-scroll-target="#defining-and-creating-elements-of-the-modeling"> <span class="header-section-number">4</span> Defining and creating ‘elements of the modeling’</a>
<ul class="collapse">
<li><a href="#defining-the-formula-objects-equations-to-model" id="toc-defining-the-formula-objects-equations-to-model" class="nav-link" data-scroll-target="#defining-the-formula-objects-equations-to-model"> <span class="header-section-number">4.1</span> Defining the formula objects (‘equations’ to model)</a></li>
<li><a href="#recipes-for-imputing-standardizing-data-in-a-ml-context" id="toc-recipes-for-imputing-standardizing-data-in-a-ml-context" class="nav-link" data-scroll-target="#recipes-for-imputing-standardizing-data-in-a-ml-context"> <span class="header-section-number">4.2</span> ‘Recipes’ for imputing &amp; standardizing data in a ML context</a></li>
<li><a href="#defining-machine-learning-models-procedures" id="toc-defining-machine-learning-models-procedures" class="nav-link" data-scroll-target="#defining-machine-learning-models-procedures"> <span class="header-section-number">4.3</span> Defining machine learning models (procedures)</a>
<ul class="collapse">
<li><a href="#random-forest-model" id="toc-random-forest-model" class="nav-link" data-scroll-target="#random-forest-model"> <span class="header-section-number">4.3.1</span> Random forest model</a></li>
</ul></li>
<li><a href="#glmnet-penalized-regression" id="toc-glmnet-penalized-regression" class="nav-link" data-scroll-target="#glmnet-penalized-regression"> <span class="header-section-number">4.4</span> Glmnet penalized regression</a></li>
<li><a href="#classification-models-forest-and-logistic-regression" id="toc-classification-models-forest-and-logistic-regression" class="nav-link" data-scroll-target="#classification-models-forest-and-logistic-regression"> <span class="header-section-number">4.5</span> Classification models (Forest and Logistic Regression)</a></li>
<li><a href="#create-workflows" id="toc-create-workflows" class="nav-link" data-scroll-target="#create-workflows"> <span class="header-section-number">4.6</span> Create workflows</a></li>
</ul></li>
<li><a href="#fitting-models" id="toc-fitting-models" class="nav-link" data-scroll-target="#fitting-models"> <span class="header-section-number">5</span> Fitting models</a>
<ul class="collapse">
<li><a href="#actual-fitting" id="toc-actual-fitting" class="nav-link" data-scroll-target="#actual-fitting"> <span class="header-section-number">5.1</span> Actual fitting</a></li>
</ul></li>
<li><a href="#working-with-results" id="toc-working-with-results" class="nav-link" data-scroll-target="#working-with-results"> <span class="header-section-number">6</span> Working with results</a>
<ul class="collapse">
<li><a href="#metrics-of-fit-performance" id="toc-metrics-of-fit-performance" class="nav-link" data-scroll-target="#metrics-of-fit-performance"> <span class="header-section-number">6.1</span> Metrics of fit (performance)</a>
<ul class="collapse">
<li><a href="#our-regression-models-performance" id="toc-our-regression-models-performance" class="nav-link" data-scroll-target="#our-regression-models-performance"> <span class="header-section-number">6.1.1</span> Our regression models’ performance</a></li>
<li><a href="#our-classification-models-performance" id="toc-our-classification-models-performance" class="nav-link" data-scroll-target="#our-classification-models-performance"> <span class="header-section-number">6.1.2</span> Our classification models’ performance</a></li>
</ul></li>
<li><a href="#illustrate-variable-importance" id="toc-illustrate-variable-importance" class="nav-link" data-scroll-target="#illustrate-variable-importance"> <span class="header-section-number">6.2</span> Illustrate variable importance</a>
<ul class="collapse">
<li><a href="#log-donation-outcome-regression" id="toc-log-donation-outcome-regression" class="nav-link" data-scroll-target="#log-donation-outcome-regression"> <span class="header-section-number">6.2.1</span> Log donation outcome (‘regression’)</a></li>
<li><a href="#donated-1k-usd-or-more-outcome-classification" id="toc-donated-1k-usd-or-more-outcome-classification" class="nav-link" data-scroll-target="#donated-1k-usd-or-more-outcome-classification"> <span class="header-section-number">6.2.2</span> Donated 1k USD or more outcome (classification)</a></li>
</ul></li>
</ul></li>
</ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
</div>
<main class="content" id="quarto-document-content">
<header id="title-block-header" class="quarto-title-block default">

<div class="quarto-title"><div class="quarto-title-block"><div><h1 class="title">Vignette: Predictive/ML modeling of donations in EA Survey data with Tidymodels and workflow</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div></div></header>

<section id="introduction" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>This vignette shows how to use a set of <code>Tidymodels</code> tools and other tools, to do a machine learning prediction and validation exercise. We use the EA Survey ‘donation data’ for our example, covering much of the analysis that was done for the comparable section of the 2020 EA Forum post/chapter. Most of that code was written by Oska Fentem in consultation with David Reinstein. This vignette is written by David Reinstein.</p>
<p>I try to show:</p>
<ul>
<li>How the computation works and ‘what is producing what’ … so that you can recreate it in your own context</li>
<li>That the machine learning models do, and why</li>
<li>Why we made specific modeling choices</li>
</ul>
<p>See also: <a href="https://www.tmwr.org/models.html">‘Fitting Models with parsnip’</a></p>
</section>
<section id="setup" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Setup</h1>
<section id="packages-and-functions" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="packages-and-functions"><span class="header-section-number">2.1</span> Packages and functions</h2>
<p>Reinstall key packages so this can be standalone?<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target="#callout-1" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Skipping here, for now; parallel cores, etc.
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Skipping here, for now; this may help processing larger jobs, so we may want to revisit it.</p>
<pre><code>cores &lt;- parallel::detectCores()
if (!grepl("mingw32", R.Version()$platform)) {
  library(doMC)
  registerDoMC(cores = cores)
} else {
  library(doParallel)
  cl &lt;- makePSOCKcluster(cores)
  registerDoParallel(cl)
}</code></pre>
</div>
</div>
</div>
</section>
<section id="reading-in-data-from-a-repo" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="reading-in-data-from-a-repo"><span class="header-section-number">2.2</span> Reading in data from a repo</h2>
<p>The code below reads data in directly from the RP private github repo. You need to have authorization set up for this to work.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>Next we sample from this data and remove labels, to make it process quicker and easier</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  labelled<span class="sc">::</span><span class="fu">remove_attributes</span>(<span class="st">"label"</span>) <span class="sc">%&gt;%</span>  <span class="co"># Labels don't work with tidymodels :/, sadly</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>dplyr<span class="sc">::</span><span class="fu">sample_n</span>(<span class="dv">2000</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2,000 × 48
   donation_usd don_av2_yr l_don_usd l_don_av_2yr don_share_inc_imp_bc5k
          &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;                  &lt;dbl&gt;
 1        400       3200        5.99         8.07                0.04   
 2        916        824.       6.82         6.72                0.0159 
 3       2485.      2604.       7.82         7.87                0.0808 
 4        118.       266.       4.78         5.59                0.00833
 5         36.7       55.1      3.63         4.03                0.00734
 6    1400000     700000       14.2         13.5                 1      
 7       1300.      1300.       7.17         7.17                0.0500 
 8         50         25        3.93         3.26                0.01   
 9        500        500        6.22         6.22                0.01   
10          0          0        0            0                   0      
# … with 1,990 more rows, and 43 more variables: donation_plan_usd &lt;dbl&gt;,
#   d_don_1k &lt;fct&gt;, d_don_10pct &lt;dbl&gt;, ln_years_involved &lt;dbl&gt;, year_f &lt;fct&gt;,
#   ln_age &lt;dbl&gt;, not_male_cat &lt;fct&gt;, student_cat &lt;fct&gt;, race_cat &lt;fct&gt;,
#   where_live_cat &lt;fct&gt;, city_cat &lt;fct&gt;, ln_income_c_imp_bc5k &lt;dbl&gt;,
#   d_pt_employment &lt;dbl&gt;, d_not_employed &lt;dbl&gt;, d_top6_uni &lt;fct&gt;,
#   d_gwwc_ever_0 &lt;fct&gt;, d_career_etg &lt;dbl&gt;, ln_years_involved_post_med &lt;dbl&gt;,
#   ln_age_if_older &lt;dbl&gt;, ln_income_c_imp_if_richer &lt;dbl&gt;, income_c &lt;dbl&gt;, …</code></pre>
</div>
</div>
</section>
<section id="some-ad-hoc-data-cleaning-and-filtering-to-enable-modeling" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="some-ad-hoc-data-cleaning-and-filtering-to-enable-modeling"><span class="header-section-number">2.3</span> Some ad-hoc data cleaning and filtering, to enable modeling</h2>
<p>Normally, we should do the main data manipulation steps separately from the analysis.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> However, if there are processing steps that are very specific to a modeling exercise, it seems OK to do them at this stage; but we should remain vigilant.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> <!-- I think it may be worth expanding on this. In that that we want to perform processing steps which are going to be long and will not vary during modelling. But where we might wish to (for example) impute data we may wish to include this as a part of the modelling process to allow testing of various imputation methods. Also things like normalizing variables should obviously be done as part of the modelling stage because of data leakage. --></p>
<p>First we remove columns with only missing values, to better focus on the interested data, and because this may mess up processing.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove variables (columns) that are all missing</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="fu">where</span>( <span class="sc">~!</span><span class="fu">all</span>(<span class="fu">is.na</span>(.x)) ))  <span class="sc">%&gt;%</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Next, another ‘Big global filtering step’ … .<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>, <a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(<span class="sc">!</span><span class="fu">is.na</span>(d_don_1k))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Next, I define an ‘optional filter’, which we may use below.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> <code>income_filter</code> will remove individuals with an income below 500000.<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>income_filter <span class="ot">&lt;-</span> <span class="fu">quo</span>(income_c_imp_bc5k <span class="sc">&lt;</span> <span class="dv">500000</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target="#callout-2" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
I often like to ‘set modeling choice objects up top’
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Specifying character vectors or list objects (or doing this in sourced scripts).</p>
<p>This usually includes…</p>
<ul>
<li>‘filters’ or slices of the data, and</li>
<li>choices of variables (columns) to include in different specifications of models … perhaps as a list object.</li>
</ul>
<p>Why ‘do this up top’? It makes it clearer what ‘all the messy code below does’, and it gives you ‘central control’, allowing you to change everything in one place. And you can also refer to these objects in many ways, including in inline text an in visualizations, to communicate what is being done.</p>
<p>Aside: The ‘choices of variables’ thing is more important in models based on a particular theoretical structure, where we have different sets of pre and post variables and are worried about ‘leakage’ … or where we are aiming at a causal interpretation and are worried about things like ‘bad controls/colliders’.</p>
</div>
</div>
</div>
<p>Finally, for factor variables, we set base categories to the most common values.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">across</span>(<span class="fu">where</span>(is.factor), <span class="co">#note the `across(where...` means 'do the function for all columns where the condition holds, and change the value, keeping the column name constant'</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="sc">~</span> forcats<span class="sc">::</span><span class="fu">fct_infreq</span>(.x))) <span class="co"># here's the abbreviated notation for a function, with a tilde ... hte `.x` refers to the object that is the function argument, here a column (name)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="mlsplits" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Machine learning environment ‘splits’</h1>
<section id="create-training-and-test-data" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="create-training-and-test-data"><span class="header-section-number">3.1</span> Create training and test data</h2>
<p>Before we start, we set a ‘seed’ so we get the same ‘random draw’ whenever we run this stuff.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>seed <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(seed)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>For ML modeling, we need to set aside some data to test our model’s ultimate performance. We thus <em>split</em> our data sets using the <code>rsample</code> package tools. 3/4 of data is used for ‘training’ (fitting the parameters of our model), and the rest for testing.<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>init_split <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">initial_split</span>(df, <span class="at">prop =</span> <span class="dv">3</span><span class="sc">/</span><span class="dv">4</span>) <span class="co">#3/4 of data goes for training, rest for testing</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target="#callout-3" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
What kind of object is <code>init_split</code>?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Typing it into the console just reports the counts of observations in the training and testing sets. If we look into its structure with <code>init_split %&gt;% str()</code> we see a list of four things;</p>
<p><code>data</code> is the dataframe itself,</p>
<p><code>in_id</code> seems to keep an indexing record of the training data,</p>
<p><code>out_id</code> is empty, and</p>
<p><code>id</code> seems to keep track of ‘what this thing is’ (but I’m not sure)</p>
</div>
</div>
</div>
<p>Next, we assign the training data and testing data objects</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">training</span>(init_split)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">testing</span>(init_split)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>I next create the ‘non-highest-income’ subset of the data, using the <code>income_filter</code> quosure object defined above to the testing and training data.<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>train_filter <span class="ot">&lt;-</span> train <span class="sc">%&gt;%</span> <span class="fu">filter</span>(<span class="sc">!!</span>income_filter)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>test_filter <span class="ot">&lt;-</span> test <span class="sc">%&gt;%</span> <span class="fu">filter</span>(<span class="sc">!!</span>income_filter)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>In the full model we compare both the unfiltered and filtered data. For simplicity, I’ll use only the latter here when considering the log donation outcomes.<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a></p>
</section>
<section id="create-partitions-folds-for-validation-tuning-step" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="create-partitions-folds-for-validation-tuning-step"><span class="header-section-number">3.2</span> Create partitions (folds) for validation ‘tuning’ step</h2>
<p>In a machine learning context, especially if we care only about prediction for its own sake, ‘more features (columns) always help’ … as long as these represent pre-outcome data and not a ‘leak’.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target="#callout-4" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
ML, overfitting, regularization, tuning
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>In standard econometrics ‘OLS’ approaches, we learn that including too many variables will <em>worsen</em> a model’s predictive power (out-of-sample fit). However, in ML contexts, to avoid this ‘overfitting’, we impose a Zpenalty’ on the (normalized) coefficient magnitudes (absolute value, squared or both). We also ‘tune’ this penalty to achieve the best performance in the cross-validation partitions. If this is done right, more columns can only help our predictive power, achieving the model that ‘predicts best out of sample’. However we <em>need to be very careful in interpreting these coefficients</em>; they are not ‘unbiased’, they may not have a causal interpretation, and statistical inference (standard errors, etc.) is also not straightforward.</p>
</div>
</div>
</div>
<p>So we do ‘regularization’ (‘trimming’, ‘penalization’, etc.) to avoid ‘overfitting’.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target="#callout-5" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
But how much of this regularization is optimal, and what is the best way of doing it?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>It seems to depend on the situation and structure of the data generating process. ML procedures try to compute the best-performing regularization ‘hyperparameters’ <em>using the data</em>. But (again because of the overfitting issue) we can’t judge the performance of an approach by predicting on the same data that it fit the model on. (And fitting on the set-aside test data would yield other ‘data leak’ problems.) <strong>N-fold cross-validation</strong> tries to get around this problem by splitting the data up into a number of partitions, fitting the model, with a certain tuning parameter, on ‘all but one fold’, and then testing it’s performance on that left-out fold.</p>
<p>This is iterated many times through different regularization specifications (hyper-parameters). The cross-validation results allow one to estimate ‘the level of regularization which provides the best out-of-sample predictive performance’.<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a></p>
</div>
</div>
</div>
<p>So, we use this <em>n-fold cross-validation</em> to ‘tune our hyperparameters’ to achieve the best tradeoffs between complexity and overfitting, to optimize our prediction. To enable this, we also need to define ‘folds’ to split up the training data, which we do below.</p>
<p>The <code>rsample::vfold_cv</code> function does this resampling (with a default of ten folds).<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>cv <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">vfold_cv</span>(train) <span class="co"># 10 fold</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>cv_filter <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(train_filter)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>It creates ten partitions (data frames with some indexing objects and meta-data on the process).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>cv</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>#  10-fold cross-validation 
# A tibble: 10 × 2
   splits             id    
   &lt;list&gt;             &lt;chr&gt; 
 1 &lt;split [1335/149]&gt; Fold01
 2 &lt;split [1335/149]&gt; Fold02
 3 &lt;split [1335/149]&gt; Fold03
 4 &lt;split [1335/149]&gt; Fold04
 5 &lt;split [1336/148]&gt; Fold05
 6 &lt;split [1336/148]&gt; Fold06
 7 &lt;split [1336/148]&gt; Fold07
 8 &lt;split [1336/148]&gt; Fold08
 9 &lt;split [1336/148]&gt; Fold09
10 &lt;split [1336/148]&gt; Fold10</code></pre>
</div>
</div>
<p>And a single partition:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>cv[[<span class="dv">1</span>,<span class="dv">1</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[[1]]
&lt;Analysis/Assess/Total&gt;
&lt;1335/149/1484&gt;</code></pre>
</div>
</div>
<p>Each of these partitions classes 90% of the data for ‘analysis’ and about 10% for ‘assessment’.</p>
</section>
</section>
<section id="defining-and-creating-elements-of-the-modeling" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Defining and creating ‘elements of the modeling’</h1>
<section id="defining-the-formula-objects-equations-to-model" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="defining-the-formula-objects-equations-to-model"><span class="header-section-number">4.1</span> Defining the formula objects (‘equations’ to model)</h2>
<p>First I make a list of ‘right hand side’ (rhs) variables here,<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a> the columns being used in prediction, to shorten later code, avoiding duplication, and centralize things.<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>rhs_vars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"ln_years_involved"</span>, <span class="st">"year_f"</span>, <span class="st">"ln_age"</span>, <span class="st">"not_male_cat"</span>, <span class="st">"student_cat"</span>, <span class="st">"race_cat"</span>, <span class="st">"where_live_cat"</span>,</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>                  <span class="st">"city_cat"</span>, <span class="st">"d_pt_employment"</span>, <span class="st">"d_not_employed"</span>, <span class="st">"d_career_etg"</span>, <span class="st">"ln_years_involved_post_med"</span>, <span class="st">"ln_income_c_imp_bc5k"</span>,</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>                  <span class="st">"first_hear_ea_lump"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target="#callout-6" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
How did we choose these features (rhs variables?)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The choice of features is one of the most important things in doing any modeling or prediction exercise.</p>
<p>Suppose we were strictly doing this ‘how to fit a model to predict future outcomes’. Then I believe we should include all features that we expect to be able to observe in the future in the settings where we want to apply our model. Considering donations, maybe I would want to predict at the time someone first joins EA, how much they would donate a year later. Why? Perhaps to do some sort of budgeting, or perhaps if we were trying to select ‘whom to target’ with a particular promotion, or who to recommend to take a particular path and we expected that those who tend to donate more would respond better.</p>
<p>But this is not what we were trying to do here. We were aiming at different goals here, not prediction per se. See our discussion under <a href="#pred-insights">Prediction models for insights?</a>.</p>
<p>Essentially, I was looking to generate a set of useful strictly-data-driven insights about ‘what is important in predicting donations’, deriving non-rigorous implications from this. So I focused on a subset off features that seemed directly interesting or relevant (such as ‘earn to give career’) and others that seemed helpful interpreting this (like the year dummies).</p>
<p>I was somewhat thinking of this as a causal model, or at least I wanted to allow the possibility of causal interpretation. Thus the ‘Giving What we Can’ pledge was not included here, because this seemed to be too close to the outcome of interest (i.e., it seems to be a very strong collider).</p>
</div>
</div>
</div>
<p>Next we create three formula objects,<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a> each with the same set of rhs variables, but a different ‘outcome’ variable.<a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a></p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target="#callout-7" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Outcomes and models
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Each of these outcomes has a different character:</p>
<p><code>l_don_av_2yr_f</code>: a strictly positive continuous variable (log average donation)</p>
<p><code>don_share_inc_imp_f</code>: donation as a share of (imputed) income, between 0 and 1</p>
<p><code>d_don_1k</code>: A binary for ‘whether donated $1000 or more.’</p>
<p>These will suggest different modeling approaches and interpretations.</p>
</div>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="do">##Consider: -- Medium importance: Consider constructing this starting with lists defined in donations_20 and adding/subtracting things (but could this cause problems?)</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_f <span class="ot">&lt;-</span> rethinkpriorities<span class="sc">::</span><span class="fu">make_formula</span>(<span class="st">"l_don_av_2yr"</span>, rhs_vars) <span class="co">#shortcut for stats::reformulate to make a formal out of rhs and lhs</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>don_share_inc_imp_f <span class="ot">&lt;-</span> <span class="fu">make_formula</span>(<span class="st">"don_share_inc_imp_bc5k"</span>, rhs_vars)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>d_don_1k_f <span class="ot">&lt;-</span> <span class="fu">make_formula</span>(<span class="st">"d_don_1k"</span>, rhs_vars)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>These formulas look like …</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_f</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>l_don_av_2yr ~ ln_years_involved + year_f + ln_age + not_male_cat + 
    student_cat + race_cat + where_live_cat + city_cat + d_pt_employment + 
    d_not_employed + d_career_etg + ln_years_involved_post_med + 
    ln_income_c_imp_bc5k + first_hear_ea_lump</code></pre>
</div>
</div>
<p>etc.</p>
</section>
<section id="recipes-for-imputing-standardizing-data-in-a-ml-context" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="recipes-for-imputing-standardizing-data-in-a-ml-context"><span class="header-section-number">4.2</span> ‘Recipes’ for imputing &amp; standardizing data in a ML context</h2>
<p>As noted, in a machine learning context, especially if we care only about prediction for its own sake, ‘more features (columns) always help’. Thus, we try to fit a model that allows many, many variables, imputing these where there are missing values.<a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a> This should get us the model that ‘predicts best out-of-sample’.<a href="#fn21" class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a></p>
<p>For ML procedures to work, we often always need to standardize each continuous (predictor) column, subtracting its mean and dividing by its estimated standard deviation.<a href="#fn22" class="footnote-ref" id="fnref22" role="doc-noteref"><sup>22</sup></a></p>
<p>Oska notes: This “really depends on the type of model, for very popular tree-based models standardization isn’t required.”</p>
<p><strong>Recipe package:</strong> We can’t merely ‘do all the imputing and standardation on the full data set once.’ This would not yield valid metrics for our tuning because of the ‘data leakage’ issue. Because of the nature of the cross-validation procedure, we need to do the above steps <em>separately for each iteration</em>, imputing and standardizing <em>using only the non-excluded observations in the partition</em> (or ‘fold’).</p>
<p>In the code below, we define a function to do a series of pre-processing steps that seem appropriate for our case at hand.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>preprocess_func <span class="ot">&lt;-</span> <span class="cf">function</span>(formula, <span class="at">data =</span> train){</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">require</span>(recipes)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Function to save time in creating recipes for different outcomes</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">#? Todo -- add to rethinkpriorities package</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>  recipes<span class="sc">::</span><span class="fu">recipe</span>(formula, <span class="at">data=</span>data) <span class="sc">%&gt;%</span> <span class="co">#formula is a 'y~x1+x2` thing, defining rhs and lhs variables</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    recipes<span class="sc">::</span><span class="fu">step_impute_median</span>(<span class="fu">all_numeric_predictors</span>()) <span class="sc">%&gt;%</span> <span class="co">#rem: replaces missing values with medians</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create NA feature</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    recipes<span class="sc">::</span><span class="fu">step_unknown</span>(<span class="fu">all_nominal_predictors</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    recipes<span class="sc">::</span><span class="fu">step_scale</span>(<span class="fu">all_numeric_predictors</span>(), <span class="at">factor=</span><span class="dv">2</span>) <span class="sc">%&gt;%</span> <span class="co">#the 2sd Gelman adjustment</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Removing because redundant: step_impute_mode(all_nominal_predictors(), -all_outcomes()) %&gt;%</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>    recipes<span class="sc">::</span><span class="fu">step_zv</span>(<span class="fu">all_predictors</span>()) <span class="sc">%&gt;%</span> <span class="co">#cut any predictors with zero variance</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>    recipes<span class="sc">::</span><span class="fu">step_dummy</span>(<span class="fu">all_nominal_predictors</span>())</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target="#callout-8" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
In the code above, the <code>preprocess_func</code> function defines a recipe that:
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Is applied to a particular formula and data set</li>
<li>For all numeric rhs variables:
<ul>
<li>imputes them at their median values, where missing</li>
<li>de-means them scales them by a factor of 2 standard deviations (see Gelman)</li>
</ul></li>
<li>Removes any rhs variables with zero variance</li>
<li>Makes standard dummy variables out of all ‘nominal’ (categorical) rhs variables</li>
</ul>
</div>
</div>
</div>
<p>Next, in the code below, we apply the above <code>preprocess_func</code> to actually create the recipes.<a href="#fn23" class="footnote-ref" id="fnref23" role="doc-noteref"><sup>23</sup></a></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create recipes (defined above in preprocess_func) (with 'formulas') attached to data objects (default is 'train')</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_rec <span class="ot">&lt;-</span> <span class="fu">preprocess_func</span>(l_don_av_2yr_f, <span class="at">data=</span>train) <span class="co">#used preprocess_func to define a recipe</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co">#`data=train` as a reminder that this is a data thing</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>don_share_inc_imp_rec <span class="ot">&lt;-</span> <span class="fu">preprocess_func</span>(don_share_inc_imp_f)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>d_don_1k_rec <span class="ot">&lt;-</span> <span class="fu">preprocess_func</span>(d_don_1k_f)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_rec_filter <span class="ot">&lt;-</span> <span class="fu">preprocess_func</span>(l_don_av_2yr_f, <span class="at">data =</span> train_filter)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>For example,</p>
<p><code>l_don_av_2yr_rec_filter &lt;- preprocess_func(l_don_av_2yr_f, data = train_filter)</code></p>
<p>creates a recipe object that is summarized as</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_rec_filter</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Recipe

Inputs:

      role #variables
   outcome          1
 predictor         14

Operations:

Median imputation for all_numeric_predictors()
Unknown factor level assignment for all_nominal_predictors()
Scaling for all_numeric_predictors()
Zero variance filter on all_predictors()
Dummy variables from all_nominal_predictors()</code></pre>
</div>
</div>
</section>
<section id="defining-machine-learning-models-procedures" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="defining-machine-learning-models-procedures"><span class="header-section-number">4.3</span> Defining machine learning models (procedures)</h2>
<p>We defined the data ‘environment’, the formula objects, and the ‘recipes’. Now we define the ‘ML models’, i.e., the procedures for ‘what sort of predictive models do we want to build, and how’?</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target="#callout-9" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
I will skip the ‘decision tree’ model here
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>A regression/decision tree is a rather simple approach, easy to understand and interpret. However, I suspect it is not great for prediction in our example here. IIRC it is dominated by the Random Forest approach. Thus, I skip it, for brevity.</p>
</div>
</div>
</div>
<section id="random-forest-model" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="random-forest-model"><span class="header-section-number">4.3.1</span> Random forest model</h3>
<p>Briefly, the random forest approach tries to predict outcomes through building a number of independent “trees”, and averaging over these.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target="#callout-10" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Trees?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>I’m not going to explain this whole procedure here. We flesh this out a bit more <a href="https://daaronr.github.io/metrics_discussion/control-ml.html#tree-models">here</a>, but note others can do a better job of explaining it than us. Still, a few notes, possibly with incorrect terminology.</p>
<p>Just think of splitting up the data first by one category, then by another category. E.g., we could split it by gender, and then by income being over some threshold, to give us four categories or ‘leaf nodes’. For each category at the bottom of each tree (leaf node), you make a single prediction for the outcome variable. We try to build these trees in away so that there is as much homogeneity as possible within each leaf node, and as much difference between leaf nods as possible… So that our predictions are as good as possible. We fit this in a way that maximize its prediction power within the training sample, obviously, but subject to a ‘penalty for more branchings’ … with the goal of predicting well on data we didn’t use to fit the model.</p>
<p>How do you choose ‘what to split it by first’ and ‘then by what’? There are algorithms. Essentially, you try each variable and see which variable and which split of that variable reduces the “entropy” the most at a particular node.</p>
<p>Why might this approach be better than regression approaches? Trees seem to force you to use each feature rather bluntly, in a sequence of splits at single cutoff points only (for continuous variables). In contrast, regressions allow you to weigh a different features against each other and have different relative strengths. On the other hand, tree models seem to allow intricate patterns of interactions between different features in ways that would be difficult to accommodate in a regression model.</p>
</div>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target="#callout-11" aria-controls="callout-11" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Random forests?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Above, I basically described the creation of an individual tree you could use to predict outcomes with. But it seems the creation of such trees is rather sensitive to initial conditions, and maybe it’s sensitive to the particular date are you are using to fit the model. Random forest does something like… “build a bunch of tree models and average them”. But you can’t build a bunch of different independent tree models unless you make some restrictions to each one, so for each tree it randomly samples a set of features from the full set, and leaves others out of the model.</p>
</div>
</div>
</div>
<p>Below, we define <code>rf_model_reg</code> as a <code>parsnip</code> object.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>rf_model_reg <span class="ot">&lt;-</span> parsnip<span class="sc">::</span><span class="fu">rand_forest</span>(</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">mtry =</span> <span class="fu">tune</span>(), <span class="co">#number of predictors to randomly sample at each 'split'</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">#trees = tune(), #how many trees in the 'ensemble'</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">trees =</span> <span class="dv">50</span>, <span class="co">#how many trees in the 'ensemble'</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">min_n =</span> <span class="fu">tune</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>  parsnip<span class="sc">::</span><span class="fu">set_engine</span>(<span class="st">"ranger"</span>, <span class="at">importance =</span> <span class="st">"impurity"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>  parsnip<span class="sc">::</span><span class="fu">set_mode</span>(<span class="st">"regression"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We specify,</p>
<p><code>mtry = tune()</code>: How many predictors should we randomly sample for each split (tree?). We set this to <code>tune</code>; that means we allow the cross-fold validation process to tell us what seems to work best.</p>
<p>We also set it to ‘tune’: - <code>min_n</code>: how few observations each (leaf) node is allowed to contain</p>
<p>We normally would also tune the</p>
<ul>
<li><code>trees</code>: how many trees in the ‘ensemble’ (the ‘forest’?) … but here I set it to only use 50 trees to save processing time … for this example</li>
</ul>
<p><a href="#fn24" class="footnote-ref" id="fnref24" role="doc-noteref"><sup>24</sup></a></p>
</section>
</section>
<section id="glmnet-penalized-regression" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="glmnet-penalized-regression"><span class="header-section-number">4.4</span> Glmnet penalized regression</h2>
<p>This is simply a regression approach with ‘penalization’ or ‘shrinkage’ … but done in a sophisticated way.</p>
<p>The GLMnet approach combines ‘ridge (L2 norm) and lasso (L2 norm)’, tuning the mix of each, as well as tuning the penalization parameters <em>within</em> each.</p>
<p>We discuss this further under <a href="#penalized-reg">‘penalized regression models’</a> in our machine learning modeling section.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>linear_model_reg <span class="ot">&lt;-</span> <span class="fu">linear_reg</span>(<span class="at">penalty =</span> <span class="fu">tune</span>(), </span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>                               <span class="at">mixture =</span> <span class="fu">tune</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>            <span class="fu">set_engine</span>(<span class="st">"glmnet"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>In the code above, we define the <code>linear_model_reg</code> <code>linear_reg</code> object. We specify the ‘engine’ we use, and, as noted, that we are using cross-validation tuning to determine how much to penalize coefficient sizes overall, and for each norm (with what ‘mixture’ of L1 and L2 norms).</p>
<p>Next we make a list of both of the above defined ‘regression models’</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create list of 'regression models' (i.e., continuous outcomes)</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>regression_models <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">random_forest =</span> rf_model_reg,</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>                          <span class="at">linear_reg =</span> linear_model_reg)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="classification-models-forest-and-logistic-regression" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="classification-models-forest-and-logistic-regression"><span class="header-section-number">4.5</span> Classification models (Forest and Logistic Regression)</h2>
<p>We do the same as above, but defining the models/modeling procedures for ‘classification models’, i.e., for those cases where we have a non-continuous outcome; in our case ‘whether they donated 1000 USD or more`. We define a random forest ’classification’ as well as an elastic net version of a logistic (logit) model, and then a list combining both.s</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Random forest model</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>rf_model_class <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>(<span class="at">mtry =</span> <span class="fu">tune</span>(), <span class="co">#number of predictors to randomly sample at each 'split'</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>                              <span class="at">trees =</span> <span class="fu">tune</span>(), <span class="co">#how many trees in the 'ensemble'</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>                              <span class="at">min_n =</span> <span class="fu">tune</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"ranger"</span>, <span class="at">importance =</span> <span class="st">"impurity"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">"classification"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Logistic regression</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>logistic_model_reg <span class="ot">&lt;-</span> <span class="fu">logistic_reg</span>(<span class="at">penalty =</span> <span class="fu">tune</span>(),</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>                                   <span class="at">mixture =</span> <span class="fu">tune</span>()) <span class="sc">%&gt;%</span> <span class="co">#DR, @OS -- what is the 'mixture' here? -- is it a mixture of L1 and L2 norms (ridge and lasso?)</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"glmnet"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>classification_models <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>                              <span class="at">random_forest =</span> rf_model_class,</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>                              <span class="at">logistic_reg =</span> logistic_model_reg)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="create-workflows" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="create-workflows"><span class="header-section-number">4.6</span> Create workflows</h2>
<blockquote class="blockquote">
<p>A workflow is an object that can bundle together your pre-processing, modeling, and post-processing requests.</p>
</blockquote>
<p>This should make the flow ‘tidy’ and the output easy to use (I hope this becomes obvious below). <a href="#fn25" class="footnote-ref" id="fnref25" role="doc-noteref"><sup>25</sup></a></p>
<p>Next, we create a workflow set for the ‘log of 2 year averaged donation’ outcome (with the income filtered data):<a href="#fn26" class="footnote-ref" id="fnref26" role="doc-noteref"><sup>26</sup></a></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co">#pre-step ... not sure how it works</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>rf_params <span class="ot">&lt;-</span> tune<span class="sc">::</span><span class="fu">parameters</span>(rf_model_reg) <span class="sc">%&gt;%</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>  recipes<span class="sc">::</span><span class="fu">update</span>(<span class="at">mtry =</span> <span class="fu">mtry</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="fu">nrow</span>(d_don_1k_rec<span class="sc">$</span>var_info)<span class="sc">-</span><span class="dv">1</span>))) </span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Note that 'mtry' is 'number of sampled predictors'</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_wf_filter <span class="ot">&lt;-</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">workflow_set</span>(</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">preproc =</span> <span class="fu">list</span>(<span class="at">preprocess =</span> l_don_av_2yr_rec_filter),</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>               <span class="co">#'preprocessing objects' ... here 'recipes'</span></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>               <span class="at">models =</span> regression_models) <span class="sc">%&gt;%</span> <span class="co">#'parsnip model specifications'</span></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">option_add_parameters</span>() <span class="sc">%&gt;%</span> <span class="co">#'adds a parameter object to the 'option' column'</span></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">option_add</span>(<span class="at">param_info =</span> rf_params, <span class="co">#this is the restriction defined above</span></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>             <span class="at">id =</span> <span class="st">"preprocess_random_forest"</span>)</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a><span class="co">#'add options saved in a workflow set' esp in the 'option column'</span></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_wf_filter</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A workflow set/tibble: 2 × 4
  wflow_id                 info             option    result    
  &lt;chr&gt;                    &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    
1 preprocess_random_forest &lt;tibble [1 × 4]&gt; &lt;opts[1]&gt; &lt;list [0]&gt;
2 preprocess_linear_reg    &lt;tibble [1 × 4]&gt; &lt;opts[1]&gt; &lt;list [0]&gt;</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_wf_filter<span class="sc">$</span>info</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[[1]]
# A tibble: 1 × 4
  workflow   preproc model       comment
  &lt;list&gt;     &lt;chr&gt;   &lt;chr&gt;       &lt;chr&gt;  
1 &lt;workflow&gt; recipe  rand_forest ""     

[[2]]
# A tibble: 1 × 4
  workflow   preproc model      comment
  &lt;list&gt;     &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;  
1 &lt;workflow&gt; recipe  linear_reg ""     </code></pre>
</div>
</div>
<p>This has a lot of ‘stuff in it’. We give it the preprocessing recipe <code>l_don_av_2yr_rec</code> (and the formula?) as discussed above, and the set of modeling procedures we defined under <code>regression_models</code>,</p>
<p>We do similarly for the ‘donate over 1k’ binary outcome and associated modeling approach.<a href="#fn27" class="footnote-ref" id="fnref27" role="doc-noteref"><sup>27</sup></a></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>d_don_1k_wf <span class="ot">&lt;-</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">workflow_set</span>(</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">preproc =</span> <span class="fu">list</span>(<span class="at">preprocess =</span> d_don_1k_rec),</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">models =</span> classification_models) <span class="sc">%&gt;%</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">option_add</span>(<span class="at">param_info =</span> rf_params, <span class="at">id =</span> <span class="st">"preprocess_random_forest"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="fitting-models" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Fitting models</h1>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target="#callout-12" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Bayesian optimization
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We have a large space to explore. We use ‘Bayesian optimization’, presumably, for the <em>tuning parameters</em> only, i.e., the combinations of ‘hyper-parameters’ (the penalization parameters). It iterates towards what seems to be an optimum (maximum posterior?) in this ‘structured space’. This is claimed to be “quicker than grid search and more effective than random search.”</p>
<p>Note that the underlying procedures are not Bayesian (as far as I know). We are not assigning a prior over (e.g.) the coefficients/‘weights’ on the variables/features in the linear models. Conditional on the tuning parameters are computed according to a simple algorithm (linear models: minimized least squares subject to the penalization, or some such).</p>
</div>
</div>
</div>
<p>Options for Bayesian optimization (for tuning parameters?)</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>bayes_ctrl <span class="ot">&lt;-</span> <span class="fu">control_bayes</span>(<span class="at">parallel_over =</span> <span class="st">"everything"</span>,</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>                      <span class="at">verbose =</span> <span class="cn">TRUE</span>,</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>                      <span class="co"># no_improve = 1,</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>                      <span class="at">save_pred =</span> <span class="cn">TRUE</span>,</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>                      <span class="at">save_workflow =</span> <span class="cn">TRUE</span>,</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>                      <span class="at">seed =</span> seed)</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="co">#max_iter &lt;- 30</span></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>max_iter <span class="ot">&lt;-</span> <span class="dv">4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Normally we would set a large number of iterations, but as this is a vignette we set it to 4 iterations only. It still takes a few minutes.<a href="#fn28" class="footnote-ref" id="fnref28" role="doc-noteref"><sup>28</sup></a></p>
<section id="actual-fitting" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="actual-fitting"><span class="header-section-number">5.1</span> Actual fitting</h2>
<p>We now ‘map the workflow’ to actually estimate the model, using <code>workflow_map</code>.</p>
<p>It takes the workflow object (below <code>l_don_av_2yr_wf</code>) and ‘runs the function’, here …</p>
<blockquote class="blockquote">
<p>tune_bayes() uses models to generate new candidate tuning parameter combinations based on previous results.</p>
</blockquote>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_results_filter <span class="ot">&lt;-</span> l_don_av_2yr_wf_filter <span class="sc">%&gt;%</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">workflow_map</span>(<span class="st">"tune_bayes"</span>,</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">seed =</span> seed,</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">resamples =</span> cv,</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>               <span class="at">iter =</span> max_iter,</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>               <span class="co"># metrics = metric_set(mae),</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>               <span class="at">control =</span> bayes_ctrl) <span class="co">#'control' how the function works</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<!-- @Oska -- do you know if there is a way to recover those iteration results in the output without having it verbose? -->
<p>Sorry for all the output above … that is because we set <code>verbose=TRUE</code>. It is considering the tuning parameters to minimize root-mean-squared error of the prediction. The random forest seems to swing widely in some dimensions, e.g., first considering about 400 trees, then 4 tree. then a few hundred trees again. It probably needs more iterations to really converge.</p>
<p>The elastic net also seems to have substantially adjusted (reduced) the level of penalization over these few iterations, and moved much more towards the ridge approach (L2 norm) and away from the lasso (L1).</p>
<!-- produces a tibble of fit workflows, has not yet been applied to the testing data  -->
<p>We next fit the models with binary (1k donation) outcome, for the random forest and logistic regression ‘classifiers’.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>bayes_ctrl<span class="sc">$</span>verbose <span class="ot">&lt;-</span> <span class="cn">FALSE</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>d_don_1k_results <span class="ot">&lt;-</span> d_don_1k_wf <span class="sc">%&gt;%</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">workflow_map</span>(<span class="st">"tune_bayes"</span>,</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>               <span class="at">seed =</span> seed,</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>               <span class="at">resamples =</span> cv,</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>               <span class="at">iter =</span> max_iter,</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>               <span class="at">control =</span> bayes_ctrl)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target="#callout-13" aria-controls="callout-13" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Iteration 4 … classification models
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Random forest:</p>
<pre><code>i Current best:     roc_auc=0.8441 (@iter 2)
i Gaussian process model
i Generating 4994 candidates
i Predicted candidates
i mtry=8, trees=106, min_n=40
i Estimating performance
Newest results: roc_auc=0.8424 (+/-0.00992)</code></pre>
<p>Logistic Elastic net:</p>
<pre><code>i Current best:     roc_auc=0.852 (@iter 2)
i Gaussian process model
i Generating 5000 candidates
i Predicted candidates
i penalty=1.75e-06, mixture=0.605
 Estimating performance
 Newest results:    roc_auc=0.8474 (+/-0.0087)</code></pre>
</div>
</div>
</div>
<p>Above (pasted into fold) the iterations are tuning the parameters, as in the ‘regression’ models. Here they focus on a classification measure called the ‘area under the receiver operating curve’; 0 is worst and 1 is best.<a href="#fn29" class="footnote-ref" id="fnref29" role="doc-noteref"><sup>29</sup></a></p>
</section>
</section>
<section id="working-with-results" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Working with results</h1>
<p>So we fit a bunch of models and we have some workflow set/tibble objects. Now what do we do with them?</p>
<p>We may want to</p>
<ol type="1">
<li><p>Assess their performance on the testing data (set aside)</p></li>
<li><p>“Interpret them” (Carefully! This can be dangerous/misleading.)</p></li>
<li><p>Use them for actual prediction and ‘profit’ when we have future data<a href="#fn30" class="footnote-ref" id="fnref30" role="doc-noteref"><sup>30</sup></a></p></li>
</ol>
<p>To enable 1 and 2, we do some cleanup and renaming below.<a href="#fn31" class="footnote-ref" id="fnref31" role="doc-noteref"><sup>31</sup></a></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Char vector for renaming of models from workflowset defaults (for display)</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>pred_model_names <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">"preprocess_random_forest"</span> <span class="ot">=</span> <span class="st">"Random Forest"</span>,</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">"preprocess_linear_reg"</span> <span class="ot">=</span> <span class="st">"Linear Regression (glmnet)"</span>,</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">"preprocess_logistic_reg"</span> <span class="ot">=</span> <span class="st">"Logistic Regression (glmnet)"</span>)</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>rename_metrics <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Workflow"</span> <span class="ot">=</span> <span class="st">"wflow_id"</span>,</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Iteration"</span> <span class="ot">=</span> <span class="st">".config"</span>,</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Iteration Number"</span> <span class="ot">=</span> <span class="st">".iter"</span>,</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Preprocessing"</span> <span class="ot">=</span> <span class="st">"preproc"</span>,</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Model"</span> <span class="ot">=</span> <span class="st">"model"</span>,</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Metric"</span> <span class="ot">=</span> <span class="st">".metric"</span>,</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Estimator"</span> <span class="ot">=</span> <span class="st">".estimator"</span>,</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Mean"</span> <span class="ot">=</span> <span class="st">"mean"</span>,</span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"N"</span> <span class="ot">=</span> <span class="st">"n"</span>,</span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Standard error"</span> <span class="ot">=</span> <span class="st">"std_err"</span>)</span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a>rename_models <span class="ot">&lt;-</span> <span class="cf">function</span>(df, <span class="at">new_names =</span> pred_model_names){</span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>  df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span> </span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">model =</span> stringr<span class="sc">::</span><span class="fu">str_replace_all</span>(model, pred_model_names))</span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(df)</span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Next we use the <code>best_wflow_preds_vi</code> helper to extract the ‘optimized’ parameters and values from the above workflow set/tibble objects, and generate some metrics of fit with the appropriate training data.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_best_params_filter <span class="ot">&lt;-</span> <span class="fu">best_wflow_preds_vi</span>(l_don_av_2yr_results_filter,</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">outcome_var =</span> <span class="st">"l_don_av_2yr"</span>, </span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">train_sample =</span> train_filter,</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">test_sample =</span> test_filter)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>d_don_1k_best_params <span class="ot">&lt;-</span> <span class="fu">best_wflow_preds_vi</span>(d_don_1k_results,</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">outcome_var =</span> <span class="st">"d_don_1k"</span>,</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">classification =</span> <span class="cn">TRUE</span>, </span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">metric =</span> <span class="st">"roc_auc"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in `is_metric_maximize()`:
! Please check the value of `metric`.</code></pre>
</div>
</div>
<p>The ‘vi’, a measure of ‘variable importance’, may be an object of particular interest:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>d_don_1k_best_params<span class="sc">$</span>vi</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in eval(expr, envir, enclos): object 'd_don_1k_best_params' not found</code></pre>
</div>
</div>
<p>For the random forest model we can’t give a ‘sign’ because each variable enters in a complicated way … at lower nodes across multiple averaged trees.</p>
<section id="metrics-of-fit-performance" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="metrics-of-fit-performance"><span class="header-section-number">6.1</span> Metrics of fit (performance)</h2>
<p>We want to know how good our models are predicting the training data (the data that was not used to fit these models). We may want to consider ‘how successful’ our predictive models are at making practically useful predictions. In other words, ‘how far off’ are the predictions and classifications on average, from the actual outcomes. This procedure considers the fit on randomly-drawn <em>set-aside</em> ‘testing data’, data that has not been used in ‘training’ (or ‘fitting’) the model. Below, we consider some commonly-used metrics.</p>
<p>For the continuous outcomes we consider the ‘regression metrics’, and define these in a list below.</p>
<ol type="1">
<li>root mean-squared error and</li>
<li>mean absolute error</li>
</ol>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>regress_metrics <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">rmse =</span> yardstick<span class="sc">::</span>rmse_vec,</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>                        <span class="at">mae =</span> yardstick<span class="sc">::</span>mae_vec)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>For the binary (or categorical outcomes we consider a range of ’classification metrics<a href="#fn32" class="footnote-ref" id="fnref32" role="doc-noteref"><sup>32</sup></a></p>
<ol type="1">
<li>Accuracy: ‘the proportion predicted correctly’</li>
<li>Recall: The share of positive (or ‘relevant’) results that were predicted to be positive. (aka sensitivity <a href="#fn33" class="footnote-ref" id="fnref33" role="doc-noteref"><sup>33</sup></a></li>
<li>Precision: Share of positive predictions that are truly positive<a href="#fn34" class="footnote-ref" id="fnref34" role="doc-noteref"><sup>34</sup></a></li>
<li>F1 score: A weighted (default: harmonic mean) of precision and recall</li>
</ol>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>class_metrics <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">accuracy =</span> yardstick<span class="sc">::</span>accuracy_vec,</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>                      <span class="at">recall =</span> yardstick<span class="sc">::</span>recall_vec,</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>                      <span class="at">precision =</span> yardstick<span class="sc">::</span>precision_vec,</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>                      <span class="at">f1_score =</span> f_meas_vec)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>First we define a little helper function to help calculate the performance metrics.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>calculate_metrics <span class="ot">&lt;-</span> <span class="cf">function</span>(df, metrics, <span class="at">preds =</span> preds, <span class="at">true_y =</span> true_y){</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>  df <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(purrr<span class="sc">::</span><span class="fu">map2_dfr</span>({{true_y}}, {{preds}}, </span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>    <span class="sc">~</span> purrr<span class="sc">::</span><span class="fu">map_dfc</span>(</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>      metrics,</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>      do.call,</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>      <span class="fu">list</span>(.x, .y))))</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Next, we apply it to the fit models tied to the training data:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_best_params_filter <span class="ot">&lt;-</span> l_don_av_2yr_best_params_filter <span class="sc">%&gt;%</span> </span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">c</span>(preds, true_y), <span class="sc">~</span><span class="fu">map</span>(.x, exp))) <span class="sc">%&gt;%</span></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">calculate_metrics</span>(regress_metrics)</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>d_don_1k_best_params <span class="ot">&lt;-</span> <span class="fu">calculate_metrics</span>(d_don_1k_best_params, class_metrics)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in mutate(., purrr::map2_dfr({: object 'd_don_1k_best_params' not found</code></pre>
</div>
</div>
<p>Note that for the continuous outcomes, we first converted from logs to levels before calculating RMSE and MAE</p>
<p>Some tidying up and renaming below. ::: {.cell}</p>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Change model names</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>d_don_1k_best_params <span class="ot">&lt;-</span> <span class="fu">rename_models</span>(d_don_1k_best_params)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in mutate(., model = stringr::str_replace_all(model, pred_model_names)): object 'd_don_1k_best_params' not found</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_best_params_filter <span class="ot">&lt;-</span> <span class="fu">rename_models</span>(l_don_av_2yr_best_params_filter)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<p>:::</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>recode_params <span class="ot">&lt;-</span> <span class="cf">function</span>(df){</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Shortcut function to tidy up variable names in parameter df</span></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>    df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(model, vi) <span class="sc">%&gt;%</span></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>    tidyr<span class="sc">::</span><span class="fu">unnest</span>(vi) <span class="sc">%&gt;%</span></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">model =</span> <span class="fu">str_replace_all</span>(model,</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>                                   <span class="fu">c</span>(<span class="st">"preprocess_"</span> <span class="ot">=</span> <span class="st">""</span>, <span class="st">"_"</span>  <span class="ot">=</span> <span class="st">" "</span>)),</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>           <span class="co">#Variable =  str_replace_all(Variable, key_eas_all_labels),</span></span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>           <span class="at">Variable =</span>  <span class="fu">str_replace_all</span>(Variable,</span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a>                                       <span class="fu">c</span>(<span class="st">"_"</span>  <span class="ot">=</span> <span class="st">" "</span>, <span class="st">"_Student"</span> <span class="ot">=</span><span class="st">""</span>, <span class="st">"ln"</span> <span class="ot">=</span> <span class="st">"log"</span>)),</span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>           <span class="at">Sign =</span> <span class="fu">if_else</span>(<span class="fu">is.na</span>(Sign), <span class="st">"NA"</span>, Sign))</span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Tidy up parameters</span></span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_best_params_recode_filter <span class="ot">&lt;-</span> l_don_av_2yr_best_params_filter <span class="sc">%&gt;%</span> </span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a>  <span class="co">#filter(is.na(filter_name)) %&gt;%</span></span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a>  recode_params</span>
<span id="cb55-17"><a href="#cb55-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-18"><a href="#cb55-18" aria-hidden="true" tabindex="-1"></a>d_don_1k_best_params_recode <span class="ot">&lt;-</span> d_don_1k_best_params <span class="sc">%&gt;%</span> recode_params</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in dplyr::select(., model, vi): object 'd_don_1k_best_params' not found</code></pre>
</div>
</div>
<section id="regression-model-pertformance-rmse-and-mae" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="regression-model-pertformance-rmse-and-mae">Regression Model Pertformance: RMSE and MAE</h4>
<p>In order to assess the usefulness of each predictive regression model we consider both root-mean-square-error (RMSE) and mean-absolute-error (MAE).</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target="#callout-14" aria-controls="callout-14" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Interpretation and construction of RMSE
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>RMSE (aka <a href="https://en.wikipedia.org/wiki/Root-mean-square_deviation">RMSD</a>) can be interpreted as the average ‘Euclidean distance’ between the actual values and the model’s prediction. For each observation (in the set-aside ‘testing sample’), to construct RMSE we:</p>
<ol type="1">
<li>Measure the differences between the actual and predicted outcome (e.g., donation)</li>
<li>Square these differences</li>
<li>Take the average of these squared differences across all observations</li>
<li>Take the square root of this</li>
</ol>
</div>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target="#callout-15" aria-controls="callout-15" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Interpretation and construction of mean-absolute-error (MAE)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-15" class="callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>To construct mean-absolute-error (MAE) we simply</p>
<ol type="1">
<li>Measure the <em>absolute-value</em> differences between the actual and predicted outcome (e.g., donation) for each observation</li>
<li>Take the average of these across all observations</li>
</ol>
<p>MAE has a much more straightforward interpretation: it simply asks ‘how far off are we, on average?’</p>
</div>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target="#callout-16" aria-controls="callout-16" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
RMSE vs MAE
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-16" class="callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>While the RMSE is used in the model <em>fitting</em> for various reasons, it is arguably less-interpretable and less-relevant than MAE in <em>judging</em> the model’s fit in cases like this one. RMSE error negatively assesses the model fit based on <em>squared</em> deviations, and is thus very sensitive to ‘large mistakes’. This may be relevant where ‘large errors are much much worse than small ones’ – here, this is not so clearly the case. In the presence of data with large outlying observations, prediction will tend to be poor by this measure.</p>
</div>
</div>
</div>
<p><strong>Transformations:</strong> Note that when considering models where the outcome is transformed (e.g., log(donations)) we construct the RMSE and MAE by exponentiating to generate predictions for the <em>level</em> outcomes, and then measure the deviations on the level scale.<a href="#fn35" class="footnote-ref" id="fnref35" role="doc-noteref"><sup>35</sup></a></p>
</section>
<section id="our-regression-models-performance" class="level3" data-number="6.1.1">
<h3 data-number="6.1.1" class="anchored" data-anchor-id="our-regression-models-performance"><span class="header-section-number">6.1.1</span> Our regression models’ performance</h3>
<p><a href="#fn36" class="footnote-ref" id="fnref36" role="doc-noteref"><sup>36</sup></a></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_best_params_filter <span class="ot">&lt;-</span> l_don_av_2yr_best_params_filter <span class="sc">%&gt;%</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">dv =</span> <span class="st">"Donation amount*"</span>)</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>  reg_model_performance <span class="ot">&lt;-</span> purrr<span class="sc">::</span><span class="fu">map</span>(<span class="fu">list</span>(l_don_av_2yr_best_params_filter), <span class="sc">~</span>.x <span class="sc">%&gt;%</span></span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>      dplyr<span class="sc">::</span><span class="fu">select</span>(dv, rmse, mae, model)</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>      ) <span class="sc">%&gt;%</span></span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>() <span class="sc">%&gt;%</span></span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="st">"Dependent variable"</span> <span class="ot">=</span> dv,</span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>         <span class="st">"RMSE"</span> <span class="ot">=</span> rmse,</span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>         <span class="st">"MAE aka MAD"</span> <span class="ot">=</span> mae,</span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>         <span class="st">"Model"</span> <span class="ot">=</span> model) <span class="sc">%&gt;%</span></span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">caption =</span> <span class="st">"Regression model performance"</span>,</span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a>        <span class="at">digits =</span> <span class="dv">2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>() <span class="sc">%&gt;%</span></span>
<span id="cb57-17"><a href="#cb57-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_footnote</span>(<span class="st">"Note: While the model was trained using logs of the dependent variable, RMSE and MAD/MAE were calculated in levels"</span>, <span class="at">notation =</span> <span class="st">"symbol"</span>)</span>
<span id="cb57-18"><a href="#cb57-18" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in add_footnote(., "Note: While the model was trained using logs of the dependent variable, RMSE and MAD/MAE were calculated in levels", : could not find function "add_footnote"</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">p_load</span>(ie2misc)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
The downloaded binary packages are in
    /var/folders/nh/gsssbvt5463b77hrh0_gtmnh0000gq/T//Rtmp6X4W8u/downloaded_packages</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>mad_naive <span class="ot">&lt;-</span> ie2misc<span class="sc">::</span><span class="fu">madstat</span>(df<span class="sc">$</span>donation_usd, <span class="at">na.rm=</span><span class="cn">TRUE</span>)</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>sd_naive <span class="ot">&lt;-</span> <span class="fu">round</span>((<span class="fu">sd</span>(df<span class="sc">$</span>donation_usd, <span class="at">na.rm=</span><span class="cn">TRUE</span>)), <span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>How does this compare to a ‘naive model’ in which we predict the average donation for everyone? Note that for the comparable unfiltered data, the mean absolute deviation is 1.6572072^{4} and the standard deviation<a href="#fn37" class="footnote-ref" id="fnref37" role="doc-noteref"><sup>37</sup></a> is 1.39859^{5}. The predictive model reduces this uncertainty substantially.</p>
</section>
<section id="our-classification-models-performance" class="level3" data-number="6.1.2">
<h3 data-number="6.1.2" class="anchored" data-anchor-id="our-classification-models-performance"><span class="header-section-number">6.1.2</span> Our classification models’ performance</h3>
<p>There are a variety of metrics for the performance of a classifications model; I discuss the basic concepts of precision, recall, and the ROC curve <a href="https://rethinkpriorities.github.io/methodology-statistics-design/chapters/classification_model_notes.html">here</a>. The ‘performance of a classifier’ is not easy to reduce to a single number; it depends on how you are going to use it, and on the relative the costs and benefits of each type of classifications error</p>
<p>The ROC curve allows us to compare the predictive power of the various models, and to compare it to an uninformed classifier<a href="#fn38" class="footnote-ref" id="fnref38" role="doc-noteref"><sup>38</sup></a></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add column for ROC curve</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>roc_curve <span class="ot">&lt;-</span> yardstick<span class="sc">::</span>roc_curve</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>unnest <span class="ot">&lt;-</span> tidyr<span class="sc">::</span>unnest</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>pr_curve <span class="ot">&lt;-</span> yardstick<span class="sc">::</span>pr_curve</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate ROC curve</span></span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>d_don_1k_best_params<span class="sc">$</span>roc_curve <span class="ot">&lt;-</span> d_don_1k_best_params <span class="sc">%&gt;%</span> <span class="fu">select</span>(true_y, preds, pred_prob, model) <span class="sc">%&gt;%</span></span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(<span class="at">cols =</span> <span class="fu">everything</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(model) <span class="sc">%&gt;%</span></span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_map</span>(<span class="sc">~</span> <span class="fu">roc_curve</span>(., true_y, .pred_FALSE))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in select(., true_y, preds, pred_prob, model): object 'd_don_1k_best_params' not found</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate AUC</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>d_don_1k_best_params<span class="sc">$</span>auc <span class="ot">&lt;-</span> d_don_1k_best_params <span class="sc">%&gt;%</span> <span class="fu">select</span>(true_y, preds, pred_prob, model) <span class="sc">%&gt;%</span></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(<span class="at">cols =</span> <span class="fu">everything</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(model) <span class="sc">%&gt;%</span></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_map</span>(<span class="sc">~</span> yardstick<span class="sc">::</span><span class="fu">roc_auc</span>(., <span class="at">truth =</span> true_y, <span class="at">estimate =</span> .pred_FALSE))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in select(., true_y, preds, pred_prob, model): object 'd_don_1k_best_params' not found</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract AUC</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>d_don_1k_best_params <span class="ot">&lt;-</span> d_don_1k_best_params <span class="sc">%&gt;%</span></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest_wider</span>(., <span class="at">col =</span> auc) <span class="sc">%&gt;%</span></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span><span class="fu">c</span>(.metric, .estimator)) <span class="sc">%&gt;%</span></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">auc =</span> .estimate)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in is.data.frame(data): object 'd_don_1k_best_params' not found</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot ROC curve</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>(roc_curve_d_don_1k <span class="ot">&lt;-</span> d_don_1k_best_params <span class="sc">%&gt;%</span> <span class="fu">select</span>(roc_curve, model) <span class="sc">%&gt;%</span></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(<span class="at">cols =</span> <span class="fu">everything</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename_with</span>(snakecase<span class="sc">::</span>to_title_case) <span class="sc">%&gt;%</span></span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="dv">1</span><span class="sc">-</span>Specificity, <span class="at">y =</span> Sensitivity, <span class="at">colour =</span> Model)) <span class="sc">+</span></span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope=</span><span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>) <span class="sc">+</span></span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in select(., roc_curve, model): object 'd_don_1k_best_params' not found</code></pre>
</div>
</div>
<p>An ROC curve plots the true positive rate (sensitivity) as a function of the false positive rate (1-specificity). Here the true positive rate gives the rate at which our model correctly predicts a respondent to donate over $1000, with the false positive rate giving the rate at which these predictions are incorrect.</p>
<p>Better classifiers will have an ROC curve that is further North-West, with the perfect classifier being an L-shaped curve passing through <span class="math inline">\((0,0) \rightarrow(0,1) \rightarrow(1,1)\)</span>. Where classifiers ROC curves do not cross, it is clear that one will be performing better than another. That is not the case here. Both models seem to be performing relatively similarly, with the ROC curves overlapping somewhat. It is difficult to discern which model is performing the best, and this will depend on our criterion.</p>
<p>However, both models yield curves substantially above the 45 degree line, thus substantially outperforming an uninformed classifier. For example, if we are willing to accept about a 25% rate of false positives (falsely predicting a 1k+ donation), the logistic regression model correctly predicts about 75% of true positives (and the random forest model about 73%).</p>
<p>We can use the area under the curve (AUC) measure to compare classifiers for all costs of misclassification. This is one measure of ‘how close the ROC curve is to the optimal L-shaped curve.’</p>
<p><a href="#fn39" class="footnote-ref" id="fnref39" role="doc-noteref"><sup>39</sup></a></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>calculate_metrics <span class="ot">&lt;-</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">function</span>(df,</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>    metrics,</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">preds =</span> preds,</span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">true_y =</span> true_y) {</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>    df <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(purrr<span class="sc">::</span><span class="fu">map2_dfr</span>({</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>      {</span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>        true_y</span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>    }, {</span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a>      {</span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a>        preds</span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb70-14"><a href="#cb70-14" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb70-15"><a href="#cb70-15" aria-hidden="true" tabindex="-1"></a>      <span class="sc">~</span> purrr<span class="sc">::</span><span class="fu">map_dfc</span>(metrics,</span>
<span id="cb70-16"><a href="#cb70-16" aria-hidden="true" tabindex="-1"></a>        do.call,</span>
<span id="cb70-17"><a href="#cb70-17" aria-hidden="true" tabindex="-1"></a>        <span class="fu">list</span>(.x, .y))))</span>
<span id="cb70-18"><a href="#cb70-18" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb70-19"><a href="#cb70-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-20"><a href="#cb70-20" aria-hidden="true" tabindex="-1"></a>class_metrics <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">accuracy =</span> yardstick<span class="sc">::</span>accuracy_vec,</span>
<span id="cb70-21"><a href="#cb70-21" aria-hidden="true" tabindex="-1"></a>                      <span class="at">recall =</span> yardstick<span class="sc">::</span>recall_vec,</span>
<span id="cb70-22"><a href="#cb70-22" aria-hidden="true" tabindex="-1"></a>                      <span class="at">precision =</span> yardstick<span class="sc">::</span>precision_vec,</span>
<span id="cb70-23"><a href="#cb70-23" aria-hidden="true" tabindex="-1"></a>                      <span class="at">f1_score =</span> yardstick<span class="sc">::</span>f_meas_vec)</span>
<span id="cb70-24"><a href="#cb70-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-25"><a href="#cb70-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Adding a no skill classifier to d_don_1k</span></span>
<span id="cb70-26"><a href="#cb70-26" aria-hidden="true" tabindex="-1"></a><span class="do">## Messy code</span></span>
<span id="cb70-27"><a href="#cb70-27" aria-hidden="true" tabindex="-1"></a>truth <span class="ot">&lt;-</span> d_don_1k_best_params<span class="sc">$</span>true_y[[<span class="dv">1</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in eval(expr, envir, enclos): object 'd_don_1k_best_params' not found</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>majority <span class="ot">&lt;-</span> <span class="fu">tail</span>(<span class="fu">names</span>(<span class="fu">sort</span>(<span class="fu">table</span>(truth))), <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'tail': object 'truth' not found</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>pred_majority <span class="ot">&lt;-</span> <span class="fu">as.logical</span>(<span class="fu">rep</span>(majority, <span class="fu">length</span>(truth)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in eval(expr, envir, enclos): object 'majority' not found</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>.pred_FALSE <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> pred_majority</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in eval(expr, envir, enclos): object 'pred_majority' not found</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>.pred_TRUE <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> .pred_FALSE</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in eval(expr, envir, enclos): object '.pred_FALSE' not found</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>pred_prob <span class="ot">&lt;-</span> <span class="fu">tibble</span>(.pred_FALSE, .pred_TRUE, truth)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in eval_tidy(xs[[j]], mask): object '.pred_FALSE' not found</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>no_skill <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">model =</span> <span class="st">"No Skill"</span>,</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>                   <span class="at">true_y =</span> <span class="fu">list</span>(truth),</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>                   <span class="at">pred_prob =</span> <span class="fu">list</span>(pred_prob),</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>                   <span class="at">preds =</span> <span class="fu">list</span>(<span class="fu">factor</span>(pred_majority, <span class="at">levels =</span> <span class="fu">levels</span>(truth)))) <span class="sc">%&gt;%</span></span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">calculate_metrics</span>(class_metrics)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in eval_tidy(xs[[j]], mask): object 'truth' not found</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>no_skill<span class="sc">$</span>auc <span class="ot">&lt;-</span> yardstick<span class="sc">::</span><span class="fu">roc_auc_vec</span>(truth, .pred_TRUE)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in is_multiclass(x): object 'truth' not found</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>purrr<span class="sc">::</span><span class="fu">map_df</span>(<span class="fu">list</span>(no_skill, d_don_1k_best_params), <span class="sc">~</span>.x <span class="sc">%&gt;%</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>             <span class="fu">select</span>(model, auc, accuracy)) <span class="sc">%&gt;%</span></span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename_with</span>(snakecase<span class="sc">::</span>to_title_case) <span class="sc">%&gt;%</span></span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">AUC =</span> Auc) <span class="sc">%&gt;%</span></span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">3</span>) <span class="sc">%&gt;%</span></span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in kable_styling(.): could not find function "kable_styling"</code></pre>
</div>
</div>
<p>Here the tuned logistic regression performs better in terms of the AUC metric, and both perform much better than the no-skill classifier.</p>
</section>
</section>
<section id="illustrate-variable-importance" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="illustrate-variable-importance"><span class="header-section-number">6.2</span> Illustrate variable importance</h2>
<p><a href="#fn40" class="footnote-ref" id="fnref40" role="doc-noteref"><sup>40</sup></a></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>plot_vi <span class="ot">&lt;-</span> <span class="cf">function</span>(df, <span class="at">shapes =</span> shape_colours){</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Shortcut function for plotting normalized variable importance (output of norm_vi)</span></span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>  df <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">y =</span> Variable, <span class="at">x =</span> Norm, <span class="at">colour =</span> model, <span class="at">shape =</span> Sign)) <span class="sc">+</span></span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_shape_manual</span>(<span class="at">values =</span> shapes) <span class="sc">+</span></span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">4</span>, <span class="at">stroke =</span> <span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">xlab</span>(<span class="st">"Normalised feature importance"</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">""</span>)</span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb88-8"><a href="#cb88-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-9"><a href="#cb88-9" aria-hidden="true" tabindex="-1"></a><span class="co">#specific changing of variable and signs for the below.</span></span>
<span id="cb88-10"><a href="#cb88-10" aria-hidden="true" tabindex="-1"></a>mutate_labels_sign_snip <span class="ot">&lt;-</span> <span class="cf">function</span>(df) {</span>
<span id="cb88-11"><a href="#cb88-11" aria-hidden="true" tabindex="-1"></a>  df <span class="sc">%&gt;%</span></span>
<span id="cb88-12"><a href="#cb88-12" aria-hidden="true" tabindex="-1"></a>     <span class="fu">mutate</span>(</span>
<span id="cb88-13"><a href="#cb88-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">Variable =</span> <span class="fu">str_replace_all</span>(Variable,</span>
<span id="cb88-14"><a href="#cb88-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(<span class="st">"First-heard EA"</span><span class="ot">=</span><span class="st">"Heard EA:"</span>,</span>
<span id="cb88-15"><a href="#cb88-15" aria-hidden="true" tabindex="-1"></a>      <span class="st">"response"</span> <span class="ot">=</span> <span class="st">"resp."</span>,</span>
<span id="cb88-16"><a href="#cb88-16" aria-hidden="true" tabindex="-1"></a>      <span class="st">"Gender Gender"</span> <span class="ot">=</span> <span class="st">"Gender"</span>,</span>
<span id="cb88-17"><a href="#cb88-17" aria-hidden="true" tabindex="-1"></a>      <span class="st">"unknown"</span> <span class="ot">=</span> <span class="st">"No resp."</span>,</span>
<span id="cb88-18"><a href="#cb88-18" aria-hidden="true" tabindex="-1"></a>      <span class="st">"Student Student"</span> <span class="ot">=</span> <span class="st">"Student"</span>,</span>
<span id="cb88-19"><a href="#cb88-19" aria-hidden="true" tabindex="-1"></a>      <span class="st">"X80000"</span> <span class="ot">=</span> <span class="st">"80000"</span>)),</span>
<span id="cb88-20"><a href="#cb88-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">Sign =</span> <span class="fu">if_else</span>(<span class="fu">is.na</span>(Sign), <span class="st">"NA"</span>, Sign)</span>
<span id="cb88-21"><a href="#cb88-21" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb88-22"><a href="#cb88-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb88-23"><a href="#cb88-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-24"><a href="#cb88-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Set colors for shapes as a named vector</span></span>
<span id="cb88-25"><a href="#cb88-25" aria-hidden="true" tabindex="-1"></a>shape_colours <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"NA"</span> <span class="ot">=</span> <span class="dv">120</span>, <span class="st">"NEG"</span> <span class="ot">=</span> <span class="dv">95</span>, <span class="st">"POS"</span> <span class="ot">=</span> <span class="dv">43</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><a href="#fn41" class="footnote-ref" id="fnref41" role="doc-noteref"><sup>41</sup></a></p>
<section id="log-donation-outcome-regression" class="level3" data-number="6.2.1">
<h3 data-number="6.2.1" class="anchored" data-anchor-id="log-donation-outcome-regression"><span class="header-section-number">6.2.1</span> Log donation outcome (‘regression’)</h3>
<p>Below, we plot the variable importance.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>iplot_l_don_av_2yr_best_params_filter <span class="ot">&lt;-</span></span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>  l_don_av_2yr_best_params_recode_filter <span class="sc">%&gt;%</span></span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>      <span class="fu">filter</span>(<span class="sc">!</span><span class="fu">grepl</span>(<span class="st">"tree"</span>, model, <span class="at">ignore.case =</span> <span class="cn">TRUE</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">norm_vi</span>(<span class="at">slice_top =</span> <span class="dv">10</span>) <span class="sc">%&gt;%</span></span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>    mutate_labels_sign_snip <span class="sc">%&gt;%</span></span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_max</span>(Total_Norm, <span class="at">n =</span> <span class="dv">10</span>) <span class="sc">%&gt;%</span></span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Variable =</span> <span class="fu">fct_reorder</span>(Variable, Norm)) <span class="sc">%&gt;%</span></span>
<span id="cb89-9"><a href="#cb89-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">y =</span> Variable, <span class="at">x =</span> Norm, <span class="at">colour =</span> model, <span class="at">shape =</span> Sign)) <span class="sc">+</span></span>
<span id="cb89-10"><a href="#cb89-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_shape_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="dv">120</span>, <span class="dv">95</span>, <span class="dv">43</span>)) <span class="sc">+</span></span>
<span id="cb89-11"><a href="#cb89-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(</span>
<span id="cb89-12"><a href="#cb89-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">position =</span> <span class="fu">position_jitter</span>(<span class="at">seed =</span> <span class="dv">42</span>,  <span class="at">width =</span> <span class="fl">0.1</span>, <span class="at">height =</span> <span class="fl">0.1</span>),</span>
<span id="cb89-13"><a href="#cb89-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> <span class="dv">4</span>, <span class="at">stroke =</span> <span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb89-14"><a href="#cb89-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Normalised feature importance"</span>) <span class="sc">+</span></span>
<span id="cb89-15"><a href="#cb89-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Importance: predict log(don.) (filter: income &lt; 500k)"</span>)</span>
<span id="cb89-16"><a href="#cb89-16" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="eas_ml_modeling_vignette_files/figure-html/iplot_l_don_av_2yr_best_params_filter-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Above, we report the ‘importance scores’ for the ten most important features (‘variables’) for two distinct approaches to predicting log (average) donation.<a href="#fn42" class="footnote-ref" id="fnref42" role="doc-noteref"><sup>42</sup></a></p>
<p>These importance scores are technically defined <a href="https://topepo.github.io/caret/variable-importance.html#model-specific-metrics">here</a>. For the elastic net (“linear reg”) approzach, we depict the coefficients’ signs with a “+” or “-”; for tree/forest-based modeling this is less straightforward.</p>
<p>Income (normalized, bottom-coded at 5000 USD, and logged) is the most important predictor for each model, by a wide margin. After this, the relative importances vary.<a href="#fn43" class="footnote-ref" id="fnref43" role="doc-noteref"><sup>43</sup></a></p>
<p>We next focus specifically on the elastic-net regression-based model.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>enet_coefs_ldon <span class="ot">&lt;-</span> l_don_av_2yr_best_params_recode_filter <span class="sc">%&gt;%</span></span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>      <span class="fu">filter</span>(</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>        <span class="fu">grepl</span>(<span class="st">"regression"</span>, model, <span class="at">ignore.case =</span> <span class="cn">TRUE</span>)  <span class="sc">&amp;</span> Importance<span class="sc">!=</span><span class="dv">0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a>  mutate_labels_sign_snip <span class="sc">%&gt;%</span></span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">#mutate(Norm = scale_var(Importance)) %&gt;%</span></span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">Variable =</span> <span class="fu">fct_reorder</span>(Variable, Importance)) <span class="sc">%&gt;%</span></span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">y =</span> Variable, <span class="at">x =</span> Importance, <span class="at">shape =</span> Sign)) <span class="sc">+</span></span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a>      <span class="fu">scale_shape_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="dv">95</span>, <span class="dv">43</span>)) <span class="sc">+</span></span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">2</span>, <span class="at">stroke =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb90-12"><a href="#cb90-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Feature importance"</span>) <span class="sc">+</span></span>
<span id="cb90-13"><a href="#cb90-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Importance scores: predicting log(don.)"</span>)</span>
<span id="cb90-14"><a href="#cb90-14" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="eas_ml_modeling_vignette_files/figure-html/enet-coefs-plot-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The graph above presents the overall ranking of importance scores within the elastic-net linear regression model, with symbols depicting whether these features take on a positive or negative sign.</p>
</section>
<section id="donated-1k-usd-or-more-outcome-classification" class="level3" data-number="6.2.2">
<h3 data-number="6.2.2" class="anchored" data-anchor-id="donated-1k-usd-or-more-outcome-classification"><span class="header-section-number">6.2.2</span> Donated 1k USD or more outcome (classification)</h3>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>  iplot_don_1k_best_params <span class="ot">&lt;-</span> d_don_1k_best_params_recode <span class="sc">%&gt;%</span></span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>      <span class="fu">filter</span>(<span class="sc">!</span><span class="fu">grepl</span>(<span class="st">"tree"</span>, model, <span class="at">ignore.case =</span> <span class="cn">TRUE</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>    mutate_labels_sign_snip <span class="sc">%&gt;%</span></span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">norm_vi</span>(<span class="at">slice_top =</span> <span class="dv">10</span>) <span class="sc">%&gt;%</span></span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot_vi</span>() <span class="sc">+</span></span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Importance scores: predicting donation &gt; 1k USD "</span>)</span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in filter(., !grepl("tree", model, ignore.case = TRUE)): object 'd_don_1k_best_params_recode' not found</code></pre>
</div>
</div>
<p>Again, both approaches deem (logged, imputed, bottom-coded) income to be the most important predictor of donating 1k USD or more.</p>

<!-- -->

</section>
</section>
</section>

<div id="quarto-appendix" class="default"><section class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1" role="doc-endnote"><p>Note: not all these packages may be needed; let’s search only the ones that are and drop the rest<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>Note this data was already edited in an analysis file – we should move that over to one of the R ‘build files’<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>In the present case this would be in <code>build/eas_cross_year_harmonisation.R</code>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>Furthermore, data-based imputation and standardizing variables must be done <em>later,</em> at the modeling stage; we do this with the <code>recipe</code> package below.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>However, this is a case where this ‘might as well have been done at the ’build the data’ stage … so I’ll move it there.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>This should remove any people who did not answer the donation question… on which (all our) outcome variables are based. But actually, something is weird here – it removes very few observations, so I’m not sure what is going on, need to doublecheck it<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>Of course, as the decision to answer the donation question is nonrandom, this is not uncontroversial. There may be some selection issues here. Alternate models could consider, e.g., 1. Non-responses as zeroes, 2. The binary outcome ‘reported a positive donation’, 3. Some explicit selection model.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>I define this ‘filter object’ using fancy ‘quosure’ syntax here, rather than actually creating another slice of the data as an object. I did this to avoid clutter in the environment while still making a clear definition up top.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p><code>income_c_imp_bc5k</code> actually does a particular imputation for missing or near-zero incomes. I use this imputed variable here for consistency, but it is not important here, as we are removing the <em>highest</em> income people only.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" role="doc-endnote"><p>This could have been done in the building process, but different procedures and reporting may want to use these categories differently, so it’s OK to do it “in the moment” here.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11" role="doc-endnote"><p>Why this particular split? I’m not sure, maybe it’s a rule of thumb.<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12" role="doc-endnote"><p>Consider: in some cases we might want to filter <em>before</em> making training/test, but there are pros and cons.<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13" role="doc-endnote"><p>Why this filter? I suspected that our methods may be sensitive to outliers, particularly with some of the functional forms. I could instead try to adjust the <em>method</em> of course, considering the real criteria of interest. This may be just an interim solution.<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14" role="doc-endnote"><p>This may not always be necessary. There are some claims that [Oska … ref?]</p>
<blockquote class="blockquote">
<p>if you specify good defaults for hyperparameters, then optimizing via randomised search/Bayesian opt or grid search is likely to only net a very minor performance improvement. For more complex methods (NN’s) it definitely isn’t worth trying to optimise parameters this way and is much better to think properly about good parameters/parameter ranges</p>
</blockquote>
<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></li>
<li id="fn15" role="doc-endnote"><p>Why ten? Maybe that’s a conventional rule of thumb? <em>Oska:</em> This seems to be standard in ML, in cases where leave-one-out cross-validation isn’t feasible (which is most of the time).<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16" role="doc-endnote"><p>I previously labeled these <code>control_vars</code>. But ‘control variables’ has a particular meaning in the context of causal inference and interpretation. In other work that <em>is</em> aiming at causal interpretation, I separate <code>control_vars</code> from the key variable of (causal) interest. But here ‘they are all equal’ so I just call it <code>rhs_vars.</code> “Right hand side variables” obviously refers to the position on the right hand side of a stated modeling equation.<a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17" role="doc-endnote"><p>I know I said this is good to do ‘at the top’, but this is the part where we are starting to actually get into the modeling, so it seems OK.<a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18" role="doc-endnote"><p>It might be more tidy to do this by inputting a list of <em>outcome</em> variables too, and generating a list of formulas to use later. Leaving this as a ‘to do’.<a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn19" role="doc-endnote"><p><code>make_formula</code> uses <code>stats::reformulate</code> to collapse lists into a formula object.<a href="#fnref19" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn20" role="doc-endnote"><p>Imputing them based on non-leaky variables only, of course, not based on any post-outcome measures.<a href="#fnref20" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn21" role="doc-endnote"><p>But once again, we <em>need to be very careful in interpreting these coefficients</em>.<a href="#fnref21" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn22" role="doc-endnote"><p>This is basically because we need to ‘penalize each coefficient fairly’. Note that we can also divide by any scalar for interpretation, as long as we do this the same for all columns. This comes up later. (This may only be the case for regression-based approaches.)<a href="#fnref22" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn23" role="doc-endnote"><p>Note that this is still not modifying any <em>data</em>, as we are not <em>applying</em> the recipes yet.<a href="#fnref23" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn24" role="doc-endnote"><p><code>set_mode("regression")</code> indicates that the outcome is continuous, rather than ‘classification’, I believe. I am not sure what exactly the <code>set_engine</code> options mean here.<a href="#fnref24" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn25" role="doc-endnote"><p>While we tend to do only ‘one of each thing’ below (a single recipe step tied to a single modeling step), the package is designed to enable lists of each, to enable all, or some combinations to be produced. See the authors’ vignette <a href="https://workflowsets.tidymodels.org/reference/workflow_set.html">here</a><a href="#fnref25" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn26" role="doc-endnote"><p>Also, as a preparation for this we ‘fit random forest parameter ranges to data’. I am not conpletely sure what is going on here. We should also find a cleaner way to do this.<a href="#fnref26" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn27" role="doc-endnote"><p>I will skip the ‘donation share’ outcome here for brevity<a href="#fnref27" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn28" role="doc-endnote"><p>I wonder if there is a way to speed it up further, for demo purposes. It generates a lot of ‘candidates’ – maybe this can be reduced.s<a href="#fnref28" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn29" role="doc-endnote"><p>This considers both types of error (false negatives and positive; i.e., precision and recall). This metric equals with the area above the diagonal in a plot of the true positive rate against the false positive rate. For the elastic-net, it looks like the penalization rate is extremely low; I would want to dig more deeply into this.<a href="#fnref29" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn30" role="doc-endnote"><p>We could also use them for loose predictions for hypothetical scases or groups of people we expect to have certain characteristics.<a href="#fnref30" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn31" role="doc-endnote"><p>To save time in later work, we might try to build a function or something to automatically rename this stuff.<a href="#fnref31" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn32" role="doc-endnote"><p>I discuss these issues at length <a href="https://rethinkpriorities.github.io/methodology-statistics-design/chapters/classification_model_notes.html">here</a>. However this is a fairly mainstream topic, and thereare a range of other, more precise or more intuitive discussions throughout the web.<a href="#fnref32" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn33" role="doc-endnote"><p>1 - the rate of false negative<a href="#fnref33" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn34" role="doc-endnote"><p>1- rate of false positive<a href="#fnref34" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn35" role="doc-endnote"><p> When considering predicted outcomes on the <em>logarithmic</em> scale, both RMSE and MAE indicate roughly ‘how many exponential orders of magnitude our predictions for the <em>non-logged outcomes</em> are off. E.g., a MSE of 1.5 for ’log donation’ suggests an we are off by about <span class="math inline">\(exp(1.5) =\)</span> 4.48 times in terms of donations, getting them off by a factor of about 5. This conversion avoid such complications.<a href="#fnref35" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn36" role="doc-endnote"><p>Code note: I am using a purrrr:map below but I think it is pointless because it is a ‘list of 1’ … I previously had also included the donation share models <a href="#fnref36" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn37" role="doc-endnote"><p>I.e., the ‘standard error’ of a model that predicts the mean every time<a href="#fnref37" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn38" role="doc-endnote"><p>which would simply predict a positive outcome with some random probability <span class="math inline">\(p\)</span>; thus this maps out the 45 degree line.<a href="#fnref38" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn39" role="doc-endnote"><p>Note: the code below is a bit messy; we can probably do better or use some existing package.<a href="#fnref39" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn40" role="doc-endnote"><p>Some renaming/recoding and helper functions in the code below:<a href="#fnref40" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn41" role="doc-endnote"><p>adding content from <code>modeling_vignettes/based_off_of/donations_20.Rmd</code><a href="#fnref41" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn42" role="doc-endnote"><p>Note that (as is common in machine learning modeling) all features have been normalized to be on the same scale; for continuous features such as age and income we take the natural log of each, and divide each by two standard deviations of the logged feature, following <span class="citation" data-cites="gelmanScalingRegressionInputs2008">@gelmanScalingRegressionInputs2008</span>.<a href="#fnref42" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn43" role="doc-endnote"><p>Note that ‘student category non-response’ is the second most important predictor in the linear model. This doesn’t seem to have a clear interpretation, but including this may help us better interpret other features like student status. To the extent that it is predictive, we might also expect it to be predictive in future cases, and it should go into useful predictions. On the other hand this non-reporting isn’t the sort of feature we could apply to predictions and policy judgements for broad groups in the wild, absent a similar survey. We can’t say “let’s target our program to people who are unlikely to indicate student status in a survey’. … We might expect non-response to be associated with lower engagement, and perhaps lower donation rates. However, we are considering non-responses to particular questions <em>among</em> those who did report a donation amount.<a href="#fnref43" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main>
<!-- /main column -->
<script type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    setTimeout(function() {
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb93" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Vignette: Predictive/ML modeling of donations in EA Survey data with Tidymodels and workflow"</span></span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a><span class="an">project:</span></span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a><span class="co">  type: website</span></span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a><span class="co">  output-dir: docs/vignettes</span></span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a><span class="co">  </span></span>
<span id="cb93-8"><a href="#cb93-8" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb93-9"><a href="#cb93-9" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb93-10"><a href="#cb93-10" aria-hidden="true" tabindex="-1"></a><span class="co">    theme: cosmo</span></span>
<span id="cb93-11"><a href="#cb93-11" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb93-12"><a href="#cb93-12" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb93-13"><a href="#cb93-13" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb93-14"><a href="#cb93-14" aria-hidden="true" tabindex="-1"></a><span class="co">    number-sections: true</span></span>
<span id="cb93-15"><a href="#cb93-15" aria-hidden="true" tabindex="-1"></a><span class="co">    citations-hover: true</span></span>
<span id="cb93-16"><a href="#cb93-16" aria-hidden="true" tabindex="-1"></a><span class="co">    footnotes-hover: true</span></span>
<span id="cb93-17"><a href="#cb93-17" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span></span>
<span id="cb93-18"><a href="#cb93-18" aria-hidden="true" tabindex="-1"></a><span class="co">    freeze: auto # re-render only when source changes</span></span>
<span id="cb93-19"><a href="#cb93-19" aria-hidden="true" tabindex="-1"></a><span class="co">    warning: false</span></span>
<span id="cb93-20"><a href="#cb93-20" aria-hidden="true" tabindex="-1"></a><span class="co">    message: false</span></span>
<span id="cb93-21"><a href="#cb93-21" aria-hidden="true" tabindex="-1"></a><span class="co">    error: true</span></span>
<span id="cb93-22"><a href="#cb93-22" aria-hidden="true" tabindex="-1"></a><span class="an">comments:</span></span>
<span id="cb93-23"><a href="#cb93-23" aria-hidden="true" tabindex="-1"></a><span class="co">    hypothesis: true</span></span>
<span id="cb93-24"><a href="#cb93-24" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb93-25"><a href="#cb93-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-26"><a href="#cb93-26" aria-hidden="true" tabindex="-1"></a><span class="fu"># Introduction</span></span>
<span id="cb93-27"><a href="#cb93-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-28"><a href="#cb93-28" aria-hidden="true" tabindex="-1"></a>This vignette shows how to use a set of <span class="in">`Tidymodels`</span> tools and other tools, to do a machine learning prediction and validation exercise. We use the EA Survey 'donation data' for our example, covering much of the analysis that was done for the comparable section of the 2020 EA Forum post/chapter. Most of that code was written by Oska Fentem in consultation with David Reinstein. This vignette is written by David Reinstein. </span>
<span id="cb93-29"><a href="#cb93-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-30"><a href="#cb93-30" aria-hidden="true" tabindex="-1"></a>I try to show:</span>
<span id="cb93-31"><a href="#cb93-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-32"><a href="#cb93-32" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>How the computation works and 'what is producing what' ... so that you can recreate it in your own context</span>
<span id="cb93-33"><a href="#cb93-33" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>That the machine learning models do, and why</span>
<span id="cb93-34"><a href="#cb93-34" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Why we made specific modeling choices </span>
<span id="cb93-35"><a href="#cb93-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-36"><a href="#cb93-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-37"><a href="#cb93-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-38"><a href="#cb93-38" aria-hidden="true" tabindex="-1"></a>See also: <span class="co">[</span><span class="ot">'Fitting Models with parsnip'</span><span class="co">](https://www.tmwr.org/models.html)</span></span>
<span id="cb93-39"><a href="#cb93-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-40"><a href="#cb93-40" aria-hidden="true" tabindex="-1"></a><span class="fu"># Setup</span></span>
<span id="cb93-41"><a href="#cb93-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-42"><a href="#cb93-42" aria-hidden="true" tabindex="-1"></a><span class="fu">## Packages and functions</span></span>
<span id="cb93-43"><a href="#cb93-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-44"><a href="#cb93-44" aria-hidden="true" tabindex="-1"></a>Reinstall key packages so this can be standalone?<span class="ot">[^eas_ml_modeling_vignette-1]</span></span>
<span id="cb93-45"><a href="#cb93-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-46"><a href="#cb93-46" aria-hidden="true" tabindex="-1"></a><span class="ot">[^eas_ml_modeling_vignette-1]: </span>Note: not all these packages may be needed; let's search only the ones that are and drop the rest</span>
<span id="cb93-47"><a href="#cb93-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-48"><a href="#cb93-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-49"><a href="#cb93-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-50"><a href="#cb93-50" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, include=FALSE}</span></span>
<span id="cb93-51"><a href="#cb93-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-52"><a href="#cb93-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-53"><a href="#cb93-53" aria-hidden="true" tabindex="-1"></a><span class="co">#or instead source(here("code", "methods_setup.R"))</span></span>
<span id="cb93-54"><a href="#cb93-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-55"><a href="#cb93-55" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(here)</span>
<span id="cb93-56"><a href="#cb93-56" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pacman)</span>
<span id="cb93-57"><a href="#cb93-57" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb93-58"><a href="#cb93-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-59"><a href="#cb93-59" aria-hidden="true" tabindex="-1"></a><span class="fu">p_load</span>(rsample, <span class="at">install =</span> <span class="cn">FALSE</span>) <span class="co"># Why p_load these? (Can create issues with dependencies)</span></span>
<span id="cb93-60"><a href="#cb93-60" aria-hidden="true" tabindex="-1"></a><span class="fu">p_load</span>(ggplot2, forcats, <span class="at">install =</span> <span class="cn">FALSE</span>)</span>
<span id="cb93-61"><a href="#cb93-61" aria-hidden="true" tabindex="-1"></a><span class="fu">p_load</span>(parsnip, tune, dials, <span class="at">install =</span> <span class="cn">FALSE</span>) <span class="co"># If loading multiple packages, better to use p_load with install = FALSE option</span></span>
<span id="cb93-62"><a href="#cb93-62" aria-hidden="true" tabindex="-1"></a><span class="fu">p_load</span>(conflicted, workflowsets,  <span class="at">install=</span><span class="cn">FALSE</span>)</span>
<span id="cb93-63"><a href="#cb93-63" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(stringr)</span>
<span id="cb93-64"><a href="#cb93-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-65"><a href="#cb93-65" aria-hidden="true" tabindex="-1"></a><span class="fu">p_load</span>(dynverse, <span class="at">install=</span><span class="cn">FALSE</span>)</span>
<span id="cb93-66"><a href="#cb93-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-67"><a href="#cb93-67" aria-hidden="true" tabindex="-1"></a>conflicted<span class="sc">::</span><span class="fu">conflict_prefer</span>(<span class="st">"set_label"</span>, <span class="st">"sjlabelled"</span>)</span>
<span id="cb93-68"><a href="#cb93-68" aria-hidden="true" tabindex="-1"></a>conflicted<span class="sc">::</span><span class="fu">conflict_prefer</span>(<span class="st">"add_footnote"</span>, <span class="st">"kableExtra"</span>)</span>
<span id="cb93-69"><a href="#cb93-69" aria-hidden="true" tabindex="-1"></a>conflicted<span class="sc">::</span><span class="fu">conflict_prefer</span>(<span class="st">"sample_n"</span>, <span class="st">"tidylog"</span>)</span>
<span id="cb93-70"><a href="#cb93-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-71"><a href="#cb93-71" aria-hidden="true" tabindex="-1"></a>set_label <span class="ot">&lt;-</span> sjlabelled<span class="sc">::</span>set_label</span>
<span id="cb93-72"><a href="#cb93-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-73"><a href="#cb93-73" aria-hidden="true" tabindex="-1"></a>filter <span class="ot">&lt;-</span> dplyr<span class="sc">::</span>filter</span>
<span id="cb93-74"><a href="#cb93-74" aria-hidden="true" tabindex="-1"></a>ungroup <span class="ot">&lt;-</span> dplyr<span class="sc">::</span>ungroup</span>
<span id="cb93-75"><a href="#cb93-75" aria-hidden="true" tabindex="-1"></a>mutate <span class="ot">&lt;-</span> dplyr<span class="sc">::</span>mutate</span>
<span id="cb93-76"><a href="#cb93-76" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb93-77"><a href="#cb93-77" aria-hidden="true" tabindex="-1"></a><span class="fu">p_load</span>(devtools)</span>
<span id="cb93-78"><a href="#cb93-78" aria-hidden="true" tabindex="-1"></a><span class="fu">source_url</span>(<span class="st">"https://raw.githubusercontent.com/daaronr/dr-rstuff/master/functions/baseoptions.R"</span>)</span>
<span id="cb93-79"><a href="#cb93-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-80"><a href="#cb93-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-81"><a href="#cb93-81" aria-hidden="true" tabindex="-1"></a><span class="co">#github api yelled at me, and I had to do this: https://gist.github.com/Z3tt/3dab3535007acf108391649766409421</span></span>
<span id="cb93-82"><a href="#cb93-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-83"><a href="#cb93-83" aria-hidden="true" tabindex="-1"></a>devtools<span class="sc">::</span><span class="fu">install_github</span>(<span class="st">"rethinkpriorities/rp-r-package"</span>, <span class="at">force =</span> <span class="cn">TRUE</span>)</span>
<span id="cb93-84"><a href="#cb93-84" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rethinkpriorities)</span>
<span id="cb93-85"><a href="#cb93-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-86"><a href="#cb93-86" aria-hidden="true" tabindex="-1"></a>devtools<span class="sc">::</span><span class="fu">install_github</span>(<span class="st">"rethinkpriorities/r-noodling-package"</span>)</span>
<span id="cb93-87"><a href="#cb93-87" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rnoodling)</span>
<span id="cb93-88"><a href="#cb93-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-89"><a href="#cb93-89" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-90"><a href="#cb93-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-91"><a href="#cb93-91" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb93-92"><a href="#cb93-92" aria-hidden="true" tabindex="-1"></a><span class="fu">## Skipping here, for now; parallel cores, etc.</span></span>
<span id="cb93-93"><a href="#cb93-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-94"><a href="#cb93-94" aria-hidden="true" tabindex="-1"></a>Skipping here, for now; this may help processing larger jobs, so we may want to revisit it.</span>
<span id="cb93-95"><a href="#cb93-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-96"><a href="#cb93-96" aria-hidden="true" tabindex="-1"></a><span class="in">    cores &lt;- parallel::detectCores()</span></span>
<span id="cb93-97"><a href="#cb93-97" aria-hidden="true" tabindex="-1"></a><span class="in">    if (!grepl("mingw32", R.Version()$platform)) {</span></span>
<span id="cb93-98"><a href="#cb93-98" aria-hidden="true" tabindex="-1"></a><span class="in">      library(doMC)</span></span>
<span id="cb93-99"><a href="#cb93-99" aria-hidden="true" tabindex="-1"></a><span class="in">      registerDoMC(cores = cores)</span></span>
<span id="cb93-100"><a href="#cb93-100" aria-hidden="true" tabindex="-1"></a><span class="in">    } else {</span></span>
<span id="cb93-101"><a href="#cb93-101" aria-hidden="true" tabindex="-1"></a><span class="in">      library(doParallel)</span></span>
<span id="cb93-102"><a href="#cb93-102" aria-hidden="true" tabindex="-1"></a><span class="in">      cl &lt;- makePSOCKcluster(cores)</span></span>
<span id="cb93-103"><a href="#cb93-103" aria-hidden="true" tabindex="-1"></a><span class="in">      registerDoParallel(cl)</span></span>
<span id="cb93-104"><a href="#cb93-104" aria-hidden="true" tabindex="-1"></a><span class="in">    }</span></span>
<span id="cb93-105"><a href="#cb93-105" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb93-106"><a href="#cb93-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-107"><a href="#cb93-107" aria-hidden="true" tabindex="-1"></a><span class="fu">## Reading in data from a repo</span></span>
<span id="cb93-108"><a href="#cb93-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-109"><a href="#cb93-109" aria-hidden="true" tabindex="-1"></a>The code below reads data in directly from the RP private github repo. You need to have authorization set up for this to work.<span class="ot">[^eas_ml_modeling_vignette-3]</span></span>
<span id="cb93-110"><a href="#cb93-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-111"><a href="#cb93-111" aria-hidden="true" tabindex="-1"></a><span class="ot">[^eas_ml_modeling_vignette-3]: </span>Note this data was already edited in an analysis file -- we should move that over to one of the R 'build files'</span>
<span id="cb93-112"><a href="#cb93-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-113"><a href="#cb93-113" aria-hidden="true" tabindex="-1"></a><span class="in">```{r input, include=FALSE}</span></span>
<span id="cb93-114"><a href="#cb93-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-115"><a href="#cb93-115" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> rethinkpriorities<span class="sc">::</span><span class="fu">read_file_from_repo</span>(</span>
<span id="cb93-116"><a href="#cb93-116" aria-hidden="true" tabindex="-1"></a>  <span class="at">repo =</span> <span class="st">"ea-data"</span>,</span>
<span id="cb93-117"><a href="#cb93-117" aria-hidden="true" tabindex="-1"></a>  <span class="at">path =</span> <span class="st">"data/edited_data/eas_all_s_rl_imp.Rdata"</span>,</span>
<span id="cb93-118"><a href="#cb93-118" aria-hidden="true" tabindex="-1"></a>  <span class="at">user =</span> <span class="st">"rethinkpriorities"</span>,</span>
<span id="cb93-119"><a href="#cb93-119" aria-hidden="true" tabindex="-1"></a>  <span class="at">token_key =</span> <span class="st">"github-API"</span>,</span>
<span id="cb93-120"><a href="#cb93-120" aria-hidden="true" tabindex="-1"></a>  <span class="at">private =</span> <span class="cn">TRUE</span></span>
<span id="cb93-121"><a href="#cb93-121" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb93-122"><a href="#cb93-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-123"><a href="#cb93-123" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-124"><a href="#cb93-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-125"><a href="#cb93-125" aria-hidden="true" tabindex="-1"></a>Next we sample from this data and remove labels, to make it process quicker and easier</span>
<span id="cb93-126"><a href="#cb93-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-127"><a href="#cb93-127" aria-hidden="true" tabindex="-1"></a><span class="in">```{r simplify_for_tidymodel}</span></span>
<span id="cb93-128"><a href="#cb93-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-129"><a href="#cb93-129" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb93-130"><a href="#cb93-130" aria-hidden="true" tabindex="-1"></a>  labelled<span class="sc">::</span><span class="fu">remove_attributes</span>(<span class="st">"label"</span>) <span class="sc">%&gt;%</span>  <span class="co"># Labels don't work with tidymodels :/, sadly</span></span>
<span id="cb93-131"><a href="#cb93-131" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb93-132"><a href="#cb93-132" aria-hidden="true" tabindex="-1"></a>dplyr<span class="sc">::</span><span class="fu">sample_n</span>(<span class="dv">2000</span>)</span>
<span id="cb93-133"><a href="#cb93-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-134"><a href="#cb93-134" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-135"><a href="#cb93-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-138"><a href="#cb93-138" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-139"><a href="#cb93-139" aria-hidden="true" tabindex="-1"></a>df</span>
<span id="cb93-140"><a href="#cb93-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-141"><a href="#cb93-141" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-142"><a href="#cb93-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-143"><a href="#cb93-143" aria-hidden="true" tabindex="-1"></a><span class="fu">## Some ad-hoc data cleaning and filtering, to enable modeling</span></span>
<span id="cb93-144"><a href="#cb93-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-145"><a href="#cb93-145" aria-hidden="true" tabindex="-1"></a>Normally, we should do the main data manipulation steps separately from the analysis.<span class="ot">[^eas_ml_modeling_vignette-4]</span> However, if there are processing steps that are very specific to a modeling exercise, it seems OK to do them at this stage; but we should remain vigilant.<span class="ot">[^eas_ml_modeling_vignette-5]</span> <span class="co">&lt;!-- I think it may be worth expanding on this. In that that we want to perform processing steps which are going to be long and will not vary during modelling. But where we might wish to (for example) impute data we may wish to include this as a part of the modelling process to allow testing of various imputation methods. Also things like normalizing variables should obviously be done as part of the modelling stage because of data leakage. --&gt;</span></span>
<span id="cb93-146"><a href="#cb93-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-147"><a href="#cb93-147" aria-hidden="true" tabindex="-1"></a><span class="ot">[^eas_ml_modeling_vignette-4]: </span>In the present case this would be in <span class="in">`build/eas_cross_year_harmonisation.R`</span>.</span>
<span id="cb93-148"><a href="#cb93-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-149"><a href="#cb93-149" aria-hidden="true" tabindex="-1"></a><span class="ot">[^eas_ml_modeling_vignette-5]: </span>Furthermore, data-based imputation and standardizing variables must be done *later,* at the modeling stage; we do this with the <span class="in">`recipe`</span> package below.</span>
<span id="cb93-150"><a href="#cb93-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-151"><a href="#cb93-151" aria-hidden="true" tabindex="-1"></a>First we remove columns with only missing values, to better focus on the interested data, and because this may mess up processing.<span class="ot">[^eas_ml_modeling_vignette-6]</span></span>
<span id="cb93-152"><a href="#cb93-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-153"><a href="#cb93-153" aria-hidden="true" tabindex="-1"></a><span class="ot">[^eas_ml_modeling_vignette-6]: </span>However, this is a case where this 'might as well have been done at the 'build the data' stage ... so I'll move it there.</span>
<span id="cb93-154"><a href="#cb93-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-157"><a href="#cb93-157" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-158"><a href="#cb93-158" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove variables (columns) that are all missing</span></span>
<span id="cb93-159"><a href="#cb93-159" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="fu">where</span>( <span class="sc">~!</span><span class="fu">all</span>(<span class="fu">is.na</span>(.x)) ))  <span class="sc">%&gt;%</span></span>
<span id="cb93-160"><a href="#cb93-160" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>()</span>
<span id="cb93-161"><a href="#cb93-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-162"><a href="#cb93-162" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-163"><a href="#cb93-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-164"><a href="#cb93-164" aria-hidden="true" tabindex="-1"></a>Next, another 'Big global filtering step' ... .<span class="ot">[^eas_ml_modeling_vignette-7]</span>, <span class="ot">[^eas_ml_modeling_vignette-8]</span></span>
<span id="cb93-165"><a href="#cb93-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-166"><a href="#cb93-166" aria-hidden="true" tabindex="-1"></a><span class="ot">[^eas_ml_modeling_vignette-7]: </span>This should remove any people who did not answer the donation question... on which (all our) outcome variables are based. But actually, something is weird here -- it removes very few observations, so I'm not sure what is going on, need to doublecheck it</span>
<span id="cb93-167"><a href="#cb93-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-168"><a href="#cb93-168" aria-hidden="true" tabindex="-1"></a><span class="ot">[^eas_ml_modeling_vignette-8]: </span>Of course, as the decision to answer the donation question is nonrandom, this is not uncontroversial. There may be some selection issues here. Alternate models could consider, e.g., 1. Non-responses as zeroes, 2. The binary outcome 'reported a positive donation', 3. Some explicit selection model.</span>
<span id="cb93-169"><a href="#cb93-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-170"><a href="#cb93-170" aria-hidden="true" tabindex="-1"></a><span class="in">```{r no-missing-don}</span></span>
<span id="cb93-171"><a href="#cb93-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-172"><a href="#cb93-172" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb93-173"><a href="#cb93-173" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(<span class="sc">!</span><span class="fu">is.na</span>(d_don_1k))</span>
<span id="cb93-174"><a href="#cb93-174" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-175"><a href="#cb93-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-176"><a href="#cb93-176" aria-hidden="true" tabindex="-1"></a>Next, I define an 'optional filter', which we may use below.<span class="ot">[^eas_ml_modeling_vignette-9]</span> <span class="in">`income_filter`</span> will remove individuals with an income below 500000.<span class="ot">[^eas_ml_modeling_vignette-10]</span></span>
<span id="cb93-177"><a href="#cb93-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-178"><a href="#cb93-178" aria-hidden="true" tabindex="-1"></a><span class="ot">[^eas_ml_modeling_vignette-9]: </span>I define this 'filter object' using fancy 'quosure' syntax here, rather than actually creating another slice of the data as an object. I did this to avoid clutter in the environment while still making a clear definition up top.</span>
<span id="cb93-179"><a href="#cb93-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-180"><a href="#cb93-180" aria-hidden="true" tabindex="-1"></a><span class="ot">[^eas_ml_modeling_vignette-10]: </span><span class="in">`income_c_imp_bc5k`</span> actually does a particular imputation for missing or near-zero incomes. I use this imputed variable here for consistency, but it is not important here, as we are removing the *highest* income people only.</span>
<span id="cb93-181"><a href="#cb93-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-184"><a href="#cb93-184" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-185"><a href="#cb93-185" aria-hidden="true" tabindex="-1"></a>income_filter <span class="ot">&lt;-</span> <span class="fu">quo</span>(income_c_imp_bc5k <span class="sc">&lt;</span> <span class="dv">500000</span>)</span>
<span id="cb93-186"><a href="#cb93-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-187"><a href="#cb93-187" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-188"><a href="#cb93-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-189"><a href="#cb93-189" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb93-190"><a href="#cb93-190" aria-hidden="true" tabindex="-1"></a><span class="fu">## I often like to 'set modeling choice objects up top'</span></span>
<span id="cb93-191"><a href="#cb93-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-192"><a href="#cb93-192" aria-hidden="true" tabindex="-1"></a>Specifying character vectors or list objects (or doing this in sourced scripts).</span>
<span id="cb93-193"><a href="#cb93-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-194"><a href="#cb93-194" aria-hidden="true" tabindex="-1"></a>This usually includes...</span>
<span id="cb93-195"><a href="#cb93-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-196"><a href="#cb93-196" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>'filters' or slices of the data, and</span>
<span id="cb93-197"><a href="#cb93-197" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>choices of variables (columns) to include in different specifications of models ... perhaps as a list object.</span>
<span id="cb93-198"><a href="#cb93-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-199"><a href="#cb93-199" aria-hidden="true" tabindex="-1"></a>Why 'do this up top'? It makes it clearer what 'all the messy code below does', and it gives you 'central control', allowing you to change everything in one place. And you can also refer to these objects in many ways, including in inline text an in visualizations, to communicate what is being done.</span>
<span id="cb93-200"><a href="#cb93-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-201"><a href="#cb93-201" aria-hidden="true" tabindex="-1"></a>Aside: The 'choices of variables' thing is more important in models based on a particular theoretical structure, where we have different sets of pre and post variables and are worried about 'leakage' ... or where we are aiming at a causal interpretation and are worried about things like 'bad controls/colliders'.</span>
<span id="cb93-202"><a href="#cb93-202" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb93-203"><a href="#cb93-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-204"><a href="#cb93-204" aria-hidden="true" tabindex="-1"></a>Finally, for factor variables, we set base categories to the most common values.<span class="ot">[^eas_ml_modeling_vignette-11]</span></span>
<span id="cb93-205"><a href="#cb93-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-206"><a href="#cb93-206" aria-hidden="true" tabindex="-1"></a><span class="ot">[^eas_ml_modeling_vignette-11]: </span>This could have been done in the building process, but different procedures and reporting may want to use these categories differently, so it's OK to do it "in the moment" here.</span>
<span id="cb93-207"><a href="#cb93-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-210"><a href="#cb93-210" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-211"><a href="#cb93-211" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(</span>
<span id="cb93-212"><a href="#cb93-212" aria-hidden="true" tabindex="-1"></a>  <span class="fu">across</span>(<span class="fu">where</span>(is.factor), <span class="co">#note the `across(where...` means 'do the function for all columns where the condition holds, and change the value, keeping the column name constant'</span></span>
<span id="cb93-213"><a href="#cb93-213" aria-hidden="true" tabindex="-1"></a>    <span class="sc">~</span> forcats<span class="sc">::</span><span class="fu">fct_infreq</span>(.x))) <span class="co"># here's the abbreviated notation for a function, with a tilde ... hte `.x` refers to the object that is the function argument, here a column (name)</span></span>
<span id="cb93-214"><a href="#cb93-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-215"><a href="#cb93-215" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-216"><a href="#cb93-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-217"><a href="#cb93-217" aria-hidden="true" tabindex="-1"></a><span class="fu"># Machine learning environment 'splits' {#mlsplits}</span></span>
<span id="cb93-218"><a href="#cb93-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-219"><a href="#cb93-219" aria-hidden="true" tabindex="-1"></a><span class="fu">## Create training and test data</span></span>
<span id="cb93-220"><a href="#cb93-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-221"><a href="#cb93-221" aria-hidden="true" tabindex="-1"></a>Before we start, we set a 'seed' so we get the same 'random draw' whenever we run this stuff.</span>
<span id="cb93-222"><a href="#cb93-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-225"><a href="#cb93-225" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-226"><a href="#cb93-226" aria-hidden="true" tabindex="-1"></a>seed <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb93-227"><a href="#cb93-227" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(seed)</span>
<span id="cb93-228"><a href="#cb93-228" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-229"><a href="#cb93-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-230"><a href="#cb93-230" aria-hidden="true" tabindex="-1"></a>For ML modeling, we need to set aside some data to test our model's ultimate performance. We thus *split* our data sets using the <span class="in">`rsample`</span> package tools. 3/4 of data is used for 'training' (fitting the parameters of our model), and the rest for testing.<span class="ot">[^eas_ml_modeling_vignette-12]</span></span>
<span id="cb93-231"><a href="#cb93-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-232"><a href="#cb93-232" aria-hidden="true" tabindex="-1"></a><span class="ot">[^eas_ml_modeling_vignette-12]: </span>Why this particular split? I'm not sure, maybe it's a rule of thumb.</span>
<span id="cb93-233"><a href="#cb93-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-234"><a href="#cb93-234" aria-hidden="true" tabindex="-1"></a><span class="in">```{r init_split}</span></span>
<span id="cb93-235"><a href="#cb93-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-236"><a href="#cb93-236" aria-hidden="true" tabindex="-1"></a>init_split <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">initial_split</span>(df, <span class="at">prop =</span> <span class="dv">3</span><span class="sc">/</span><span class="dv">4</span>) <span class="co">#3/4 of data goes for training, rest for testing</span></span>
<span id="cb93-237"><a href="#cb93-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-238"><a href="#cb93-238" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-239"><a href="#cb93-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-240"><a href="#cb93-240" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb93-241"><a href="#cb93-241" aria-hidden="true" tabindex="-1"></a><span class="fu">## What kind of object is `init_split`?</span></span>
<span id="cb93-242"><a href="#cb93-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-243"><a href="#cb93-243" aria-hidden="true" tabindex="-1"></a>Typing it into the console just reports the counts of observations in the training and testing sets. If we look into its structure with <span class="in">`init_split %&gt;% str()`</span> we see a list of four things;</span>
<span id="cb93-244"><a href="#cb93-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-245"><a href="#cb93-245" aria-hidden="true" tabindex="-1"></a><span class="in">`data`</span> is the dataframe itself,</span>
<span id="cb93-246"><a href="#cb93-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-247"><a href="#cb93-247" aria-hidden="true" tabindex="-1"></a><span class="in">`in_id`</span> seems to keep an indexing record of the training data,</span>
<span id="cb93-248"><a href="#cb93-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-249"><a href="#cb93-249" aria-hidden="true" tabindex="-1"></a><span class="in">`out_id`</span> is empty, and</span>
<span id="cb93-250"><a href="#cb93-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-251"><a href="#cb93-251" aria-hidden="true" tabindex="-1"></a><span class="in">`id`</span> seems to keep track of 'what this thing is' (but I'm not sure)</span>
<span id="cb93-252"><a href="#cb93-252" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb93-253"><a href="#cb93-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-254"><a href="#cb93-254" aria-hidden="true" tabindex="-1"></a>Next, we assign the training data and testing data objects</span>
<span id="cb93-255"><a href="#cb93-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-256"><a href="#cb93-256" aria-hidden="true" tabindex="-1"></a><span class="in">```{r train-test}</span></span>
<span id="cb93-257"><a href="#cb93-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-258"><a href="#cb93-258" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">training</span>(init_split)</span>
<span id="cb93-259"><a href="#cb93-259" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">testing</span>(init_split)</span>
<span id="cb93-260"><a href="#cb93-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-261"><a href="#cb93-261" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-262"><a href="#cb93-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-263"><a href="#cb93-263" aria-hidden="true" tabindex="-1"></a>I next create the 'non-highest-income' subset of the data, using the <span class="in">`income_filter`</span> quosure object defined above to the testing and training data.<span class="ot">[^eas_ml_modeling_vignette-13]</span></span>
<span id="cb93-264"><a href="#cb93-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-265"><a href="#cb93-265" aria-hidden="true" tabindex="-1"></a><span class="ot">[^eas_ml_modeling_vignette-13]: </span>Consider: in some cases we might want to filter *before* making training/test, but there are pros and cons.</span>
<span id="cb93-266"><a href="#cb93-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-267"><a href="#cb93-267" aria-hidden="true" tabindex="-1"></a><span class="in">```{r train-test_filter}</span></span>
<span id="cb93-268"><a href="#cb93-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-269"><a href="#cb93-269" aria-hidden="true" tabindex="-1"></a>train_filter <span class="ot">&lt;-</span> train <span class="sc">%&gt;%</span> <span class="fu">filter</span>(<span class="sc">!!</span>income_filter)</span>
<span id="cb93-270"><a href="#cb93-270" aria-hidden="true" tabindex="-1"></a>test_filter <span class="ot">&lt;-</span> test <span class="sc">%&gt;%</span> <span class="fu">filter</span>(<span class="sc">!!</span>income_filter)</span>
<span id="cb93-271"><a href="#cb93-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-272"><a href="#cb93-272" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-273"><a href="#cb93-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-274"><a href="#cb93-274" aria-hidden="true" tabindex="-1"></a>In the full model we compare both the unfiltered and filtered data. For simplicity, I'll use only the latter here when considering the log donation outcomes.<span class="ot">[^eas_ml_modeling_vignette-14]</span></span>
<span id="cb93-275"><a href="#cb93-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-276"><a href="#cb93-276" aria-hidden="true" tabindex="-1"></a><span class="ot">[^eas_ml_modeling_vignette-14]: </span>Why this filter? I suspected that our methods may be sensitive to outliers, particularly with some of the functional forms. I could instead try to adjust the *method* of course, considering the real criteria of interest. This may be just an interim solution.</span>
<span id="cb93-277"><a href="#cb93-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-278"><a href="#cb93-278" aria-hidden="true" tabindex="-1"></a><span class="fu">## Create partitions (folds) for validation 'tuning' step</span></span>
<span id="cb93-279"><a href="#cb93-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-280"><a href="#cb93-280" aria-hidden="true" tabindex="-1"></a>In a machine learning context, especially if we care only about prediction for its own sake, 'more features (columns) always help' ... as long as these represent pre-outcome data and not a 'leak'.</span>
<span id="cb93-281"><a href="#cb93-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-282"><a href="#cb93-282" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb93-283"><a href="#cb93-283" aria-hidden="true" tabindex="-1"></a><span class="fu">## ML, overfitting, regularization, tuning</span></span>
<span id="cb93-284"><a href="#cb93-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-285"><a href="#cb93-285" aria-hidden="true" tabindex="-1"></a>In standard econometrics 'OLS' approaches, we learn that including too many variables will *worsen* a model's predictive power (out-of-sample fit). However, in ML contexts, to avoid this 'overfitting', we impose a Zpenalty' on the (normalized) coefficient magnitudes (absolute value, squared or both). We also 'tune' this penalty to achieve the best performance in the cross-validation partitions. If this is done right, more columns can only help our predictive power, achieving the model that 'predicts best out of sample'. However we *need to be very careful in interpreting these coefficients*; they are not 'unbiased', they may not have a causal interpretation, and statistical inference (standard errors, etc.) is also not straightforward.</span>
<span id="cb93-286"><a href="#cb93-286" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb93-287"><a href="#cb93-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-288"><a href="#cb93-288" aria-hidden="true" tabindex="-1"></a>So we do 'regularization' ('trimming', 'penalization', etc.) to avoid 'overfitting'.</span>
<span id="cb93-289"><a href="#cb93-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-290"><a href="#cb93-290" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb93-291"><a href="#cb93-291" aria-hidden="true" tabindex="-1"></a><span class="fu">## But how much of this regularization is optimal, and what is the best way of doing it?</span></span>
<span id="cb93-292"><a href="#cb93-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-293"><a href="#cb93-293" aria-hidden="true" tabindex="-1"></a>It seems to depend on the situation and structure of the data generating process. ML procedures try to compute the best-performing regularization 'hyperparameters' *using the data*. But (again because of the overfitting issue) we can't judge the performance of an approach by predicting on the same data that it fit the model on. (And fitting on the set-aside test data would yield other 'data leak' problems.) **N-fold cross-validation** tries to get around this problem by splitting the data up into a number of partitions, fitting the model, with a certain tuning parameter, on 'all but one fold', and then testing it's performance on that left-out fold.</span>
<span id="cb93-294"><a href="#cb93-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-295"><a href="#cb93-295" aria-hidden="true" tabindex="-1"></a>This is iterated many times through different regularization specifications (hyper-parameters). The cross-validation results allow one to estimate 'the level of regularization which provides the best out-of-sample predictive performance'.<span class="ot">[^eas_ml_modeling_vignette-15]</span></span>
<span id="cb93-296"><a href="#cb93-296" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb93-297"><a href="#cb93-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-298"><a href="#cb93-298" aria-hidden="true" tabindex="-1"></a><span class="ot">[^eas_ml_modeling_vignette-15]: </span>This may not always be necessary. There are some claims that <span class="sc">\[</span>Oska ... ref?<span class="sc">\]</span></span>
<span id="cb93-299"><a href="#cb93-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-300"><a href="#cb93-300" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; if you specify good defaults for hyperparameters, then optimizing via randomised search/Bayesian opt or grid search is likely to only net a very minor performance improvement. For more complex methods (NN's) it definitely isn't worth trying to optimise parameters this way and is much better to think properly about good parameters/parameter ranges</span></span>
<span id="cb93-301"><a href="#cb93-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-302"><a href="#cb93-302" aria-hidden="true" tabindex="-1"></a>So, we use this *n-fold cross-validation* to 'tune our hyperparameters' to achieve the best tradeoffs between complexity and overfitting, to optimize our prediction. To enable this, we also need to define 'folds' to split up the training data, which we do below.</span>
<span id="cb93-303"><a href="#cb93-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-304"><a href="#cb93-304" aria-hidden="true" tabindex="-1"></a>The <span class="in">`rsample::vfold_cv`</span> function does this resampling (with a default of ten folds).<span class="ot">[^eas_ml_modeling_vignette-16]</span></span>
<span id="cb93-305"><a href="#cb93-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-306"><a href="#cb93-306" aria-hidden="true" tabindex="-1"></a><span class="ot">[^eas_ml_modeling_vignette-16]: </span>Why ten? Maybe that's a conventional rule of thumb? *Oska:* This seems to be standard in ML, in cases where leave-one-out cross-validation isn't feasible (which is most of the time).</span>
<span id="cb93-307"><a href="#cb93-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-310"><a href="#cb93-310" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-311"><a href="#cb93-311" aria-hidden="true" tabindex="-1"></a>cv <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">vfold_cv</span>(train) <span class="co"># 10 fold</span></span>
<span id="cb93-312"><a href="#cb93-312" aria-hidden="true" tabindex="-1"></a>cv_filter <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(train_filter)</span>
<span id="cb93-313"><a href="#cb93-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-314"><a href="#cb93-314" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-315"><a href="#cb93-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-316"><a href="#cb93-316" aria-hidden="true" tabindex="-1"></a>It creates ten partitions (data frames with some indexing objects and meta-data on the process).</span>
<span id="cb93-317"><a href="#cb93-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-318"><a href="#cb93-318" aria-hidden="true" tabindex="-1"></a><span class="in">```{r cv-show}</span></span>
<span id="cb93-319"><a href="#cb93-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-320"><a href="#cb93-320" aria-hidden="true" tabindex="-1"></a>cv</span>
<span id="cb93-321"><a href="#cb93-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-322"><a href="#cb93-322" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-323"><a href="#cb93-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-324"><a href="#cb93-324" aria-hidden="true" tabindex="-1"></a>And a single partition:</span>
<span id="cb93-325"><a href="#cb93-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-328"><a href="#cb93-328" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-329"><a href="#cb93-329" aria-hidden="true" tabindex="-1"></a>cv[[<span class="dv">1</span>,<span class="dv">1</span>]]</span>
<span id="cb93-330"><a href="#cb93-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-331"><a href="#cb93-331" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-332"><a href="#cb93-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-333"><a href="#cb93-333" aria-hidden="true" tabindex="-1"></a>Each of these partitions classes 90% of the data for 'analysis' and about 10% for 'assessment'.</span>
<span id="cb93-334"><a href="#cb93-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-335"><a href="#cb93-335" aria-hidden="true" tabindex="-1"></a><span class="fu"># Defining and creating 'elements of the modeling'</span></span>
<span id="cb93-336"><a href="#cb93-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-337"><a href="#cb93-337" aria-hidden="true" tabindex="-1"></a><span class="fu">## Defining the formula objects ('equations' to model)</span></span>
<span id="cb93-338"><a href="#cb93-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-339"><a href="#cb93-339" aria-hidden="true" tabindex="-1"></a>First I make a list of 'right hand side' (rhs) variables here,<span class="ot">[^eas_ml_modeling_vignette-17]</span> the columns being used in prediction, to shorten later code, avoiding duplication, and centralize things.<span class="ot">[^eas_ml_modeling_vignette-18]</span></span>
<span id="cb93-340"><a href="#cb93-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-341"><a href="#cb93-341" aria-hidden="true" tabindex="-1"></a><span class="ot">[^eas_ml_modeling_vignette-17]: </span>I previously labeled these <span class="in">`control_vars`</span>. But 'control variables' has a particular meaning in the context of causal inference and interpretation. In other work that *is* aiming at causal interpretation, I separate <span class="in">`control_vars`</span> from the key variable of (causal) interest. But here 'they are all equal' so I just call it <span class="in">`rhs_vars.`</span> "Right hand side variables" obviously refers to the position on the right hand side of a stated modeling equation.</span>
<span id="cb93-342"><a href="#cb93-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-343"><a href="#cb93-343" aria-hidden="true" tabindex="-1"></a><span class="ot">[^eas_ml_modeling_vignette-18]: </span>I know I said this is good to do 'at the top', but this is the part where we are starting to actually get into the modeling, so it seems OK.</span>
<span id="cb93-344"><a href="#cb93-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-345"><a href="#cb93-345" aria-hidden="true" tabindex="-1"></a><span class="in">```{r rhs_vars}</span></span>
<span id="cb93-346"><a href="#cb93-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-347"><a href="#cb93-347" aria-hidden="true" tabindex="-1"></a>rhs_vars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"ln_years_involved"</span>, <span class="st">"year_f"</span>, <span class="st">"ln_age"</span>, <span class="st">"not_male_cat"</span>, <span class="st">"student_cat"</span>, <span class="st">"race_cat"</span>, <span class="st">"where_live_cat"</span>,</span>
<span id="cb93-348"><a href="#cb93-348" aria-hidden="true" tabindex="-1"></a>                  <span class="st">"city_cat"</span>, <span class="st">"d_pt_employment"</span>, <span class="st">"d_not_employed"</span>, <span class="st">"d_career_etg"</span>, <span class="st">"ln_years_involved_post_med"</span>, <span class="st">"ln_income_c_imp_bc5k"</span>,</span>
<span id="cb93-349"><a href="#cb93-349" aria-hidden="true" tabindex="-1"></a>                  <span class="st">"first_hear_ea_lump"</span>)</span>
<span id="cb93-350"><a href="#cb93-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-351"><a href="#cb93-351" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-352"><a href="#cb93-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-353"><a href="#cb93-353" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb93-354"><a href="#cb93-354" aria-hidden="true" tabindex="-1"></a><span class="fu">## How did we choose these features (rhs variables?)</span></span>
<span id="cb93-355"><a href="#cb93-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-356"><a href="#cb93-356" aria-hidden="true" tabindex="-1"></a>The choice of features is one of the most important things in doing any modeling or prediction exercise. </span>
<span id="cb93-357"><a href="#cb93-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-358"><a href="#cb93-358" aria-hidden="true" tabindex="-1"></a>Suppose we were strictly doing this 'how to fit a model to predict future outcomes'. Then I believe we should include all features that we expect to be able to observe in the future in the settings where we want to apply our model. Considering donations, maybe I would want to predict at the time someone first joins EA, how much they would donate a year later. Why? Perhaps to do some sort of budgeting, or perhaps if we were trying to select 'whom to target' with a particular promotion, or who to recommend to take a particular path and we expected that those who tend to donate more would respond better. </span>
<span id="cb93-359"><a href="#cb93-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-360"><a href="#cb93-360" aria-hidden="true" tabindex="-1"></a>But this is not what we were trying to do here. We were aiming at different goals here, not prediction per se.  See our discussion under <span class="co">[</span><span class="ot">Prediction models for insights?</span><span class="co">](#pred-insights)</span>.</span>
<span id="cb93-361"><a href="#cb93-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-362"><a href="#cb93-362" aria-hidden="true" tabindex="-1"></a>Essentially, I was looking to generate a set of useful strictly-data-driven insights about 'what is important in predicting donations', deriving non-rigorous implications from this. So I focused on a subset off features that seemed directly interesting or relevant (such as 'earn to give career') and others that seemed helpful interpreting this (like the year dummies).</span>
<span id="cb93-363"><a href="#cb93-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-364"><a href="#cb93-364" aria-hidden="true" tabindex="-1"></a>I was somewhat thinking of this as a causal model, or at least I wanted to allow the possibility of causal interpretation. Thus the 'Giving What we Can' pledge was not included here, because this seemed to be too close to the outcome of interest (i.e., it seems to be a very strong collider).</span>
<span id="cb93-365"><a href="#cb93-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-366"><a href="#cb93-366" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb93-367"><a href="#cb93-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-368"><a href="#cb93-368" aria-hidden="true" tabindex="-1"></a>Next we create three formula objects,<span class="ot">[^eas_ml_modeling_vignette-19]</span> each with the same set of rhs variables, but a different 'outcome' variable.<span class="ot">[^eas_ml_modeling_vignette-20]</span></span>
<span id="cb93-369"><a href="#cb93-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-370"><a href="#cb93-370" aria-hidden="true" tabindex="-1"></a><span class="ot">[^eas_ml_modeling_vignette-19]: </span>It might be more tidy to do this by inputting a list of *outcome* variables too, and generating a list of formulas to use later. Leaving this as a 'to do'.</span>
<span id="cb93-371"><a href="#cb93-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-372"><a href="#cb93-372" aria-hidden="true" tabindex="-1"></a><span class="ot">[^eas_ml_modeling_vignette-20]: </span><span class="in">`make_formula`</span> uses <span class="in">`stats::reformulate`</span> to collapse lists into a formula object.</span>
<span id="cb93-373"><a href="#cb93-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-374"><a href="#cb93-374" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb93-375"><a href="#cb93-375" aria-hidden="true" tabindex="-1"></a><span class="fu">## Outcomes and models</span></span>
<span id="cb93-376"><a href="#cb93-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-377"><a href="#cb93-377" aria-hidden="true" tabindex="-1"></a>Each of these outcomes has a different character:</span>
<span id="cb93-378"><a href="#cb93-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-379"><a href="#cb93-379" aria-hidden="true" tabindex="-1"></a><span class="in">`l_don_av_2yr_f`</span>: a strictly positive continuous variable (log average donation)</span>
<span id="cb93-380"><a href="#cb93-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-381"><a href="#cb93-381" aria-hidden="true" tabindex="-1"></a><span class="in">`don_share_inc_imp_f`</span>: donation as a share of (imputed) income, between 0 and 1</span>
<span id="cb93-382"><a href="#cb93-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-383"><a href="#cb93-383" aria-hidden="true" tabindex="-1"></a><span class="in">`d_don_1k`</span>: A binary for 'whether donated \$1000 or more.'</span>
<span id="cb93-384"><a href="#cb93-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-385"><a href="#cb93-385" aria-hidden="true" tabindex="-1"></a>These will suggest different modeling approaches and interpretations.</span>
<span id="cb93-386"><a href="#cb93-386" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb93-387"><a href="#cb93-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-390"><a href="#cb93-390" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-391"><a href="#cb93-391" aria-hidden="true" tabindex="-1"></a><span class="do">##Consider: -- Medium importance: Consider constructing this starting with lists defined in donations_20 and adding/subtracting things (but could this cause problems?)</span></span>
<span id="cb93-392"><a href="#cb93-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-393"><a href="#cb93-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-394"><a href="#cb93-394" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_f <span class="ot">&lt;-</span> rethinkpriorities<span class="sc">::</span><span class="fu">make_formula</span>(<span class="st">"l_don_av_2yr"</span>, rhs_vars) <span class="co">#shortcut for stats::reformulate to make a formal out of rhs and lhs</span></span>
<span id="cb93-395"><a href="#cb93-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-396"><a href="#cb93-396" aria-hidden="true" tabindex="-1"></a>don_share_inc_imp_f <span class="ot">&lt;-</span> <span class="fu">make_formula</span>(<span class="st">"don_share_inc_imp_bc5k"</span>, rhs_vars)</span>
<span id="cb93-397"><a href="#cb93-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-398"><a href="#cb93-398" aria-hidden="true" tabindex="-1"></a>d_don_1k_f <span class="ot">&lt;-</span> <span class="fu">make_formula</span>(<span class="st">"d_don_1k"</span>, rhs_vars)</span>
<span id="cb93-399"><a href="#cb93-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-400"><a href="#cb93-400" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-401"><a href="#cb93-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-402"><a href="#cb93-402" aria-hidden="true" tabindex="-1"></a>These formulas look like ...</span>
<span id="cb93-403"><a href="#cb93-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-406"><a href="#cb93-406" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-407"><a href="#cb93-407" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_f</span>
<span id="cb93-408"><a href="#cb93-408" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-409"><a href="#cb93-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-410"><a href="#cb93-410" aria-hidden="true" tabindex="-1"></a>etc.</span>
<span id="cb93-411"><a href="#cb93-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-412"><a href="#cb93-412" aria-hidden="true" tabindex="-1"></a><span class="fu">## 'Recipes' for imputing &amp; standardizing data in a ML context</span></span>
<span id="cb93-413"><a href="#cb93-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-414"><a href="#cb93-414" aria-hidden="true" tabindex="-1"></a>As noted, in a machine learning context, especially if we care only about prediction for its own sake, 'more features (columns) always help'. Thus, we try to fit a model that allows many, many variables, imputing these where there are missing values.<span class="ot">[^eas_ml_modeling_vignette-21]</span> This should get us the model that 'predicts best out-of-sample'.^<span class="co">[</span><span class="ot">But once again,  we *need to be very careful in interpreting these coefficients*.</span><span class="co">]</span></span>
<span id="cb93-415"><a href="#cb93-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-416"><a href="#cb93-416" aria-hidden="true" tabindex="-1"></a><span class="ot">[^eas_ml_modeling_vignette-21]: </span>Imputing them based on non-leaky variables only, of course, not based on any post-outcome measures.</span>
<span id="cb93-417"><a href="#cb93-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-418"><a href="#cb93-418" aria-hidden="true" tabindex="-1"></a>For ML procedures to work, we often always need to standardize each continuous (predictor) column, subtracting its mean and dividing by its estimated standard deviation.<span class="ot">[^eas_ml_modeling_vignette-22]</span></span>
<span id="cb93-419"><a href="#cb93-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-420"><a href="#cb93-420" aria-hidden="true" tabindex="-1"></a><span class="ot">[^eas_ml_modeling_vignette-22]: </span>This is basically because we need to 'penalize each coefficient fairly'. Note that we can also divide by any scalar for interpretation, as long as we do this the same for all columns. This comes up later. (This may only be the case for regression-based approaches.)</span>
<span id="cb93-421"><a href="#cb93-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-422"><a href="#cb93-422" aria-hidden="true" tabindex="-1"></a>Oska notes: This "really depends on the type of model, for very popular tree-based models standardization isn't required."</span>
<span id="cb93-423"><a href="#cb93-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-424"><a href="#cb93-424" aria-hidden="true" tabindex="-1"></a>**Recipe package:** We can't merely 'do all the imputing and standardation on the full data set once.' This would not yield valid metrics for our tuning because of the 'data leakage' issue. Because of the nature of the cross-validation procedure, we need to do the above steps *separately for each iteration*, imputing and standardizing *using only the non-excluded observations in the partition* (or 'fold').</span>
<span id="cb93-425"><a href="#cb93-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-426"><a href="#cb93-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-427"><a href="#cb93-427" aria-hidden="true" tabindex="-1"></a>In the code below, we define a function to do a series of pre-processing steps that seem appropriate for our case at hand.</span>
<span id="cb93-428"><a href="#cb93-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-429"><a href="#cb93-429" aria-hidden="true" tabindex="-1"></a><span class="in">```{r preprocess_func}</span></span>
<span id="cb93-430"><a href="#cb93-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-431"><a href="#cb93-431" aria-hidden="true" tabindex="-1"></a>preprocess_func <span class="ot">&lt;-</span> <span class="cf">function</span>(formula, <span class="at">data =</span> train){</span>
<span id="cb93-432"><a href="#cb93-432" aria-hidden="true" tabindex="-1"></a>  <span class="fu">require</span>(recipes)</span>
<span id="cb93-433"><a href="#cb93-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-434"><a href="#cb93-434" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Function to save time in creating recipes for different outcomes</span></span>
<span id="cb93-435"><a href="#cb93-435" aria-hidden="true" tabindex="-1"></a>  <span class="co">#? Todo -- add to rethinkpriorities package</span></span>
<span id="cb93-436"><a href="#cb93-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-437"><a href="#cb93-437" aria-hidden="true" tabindex="-1"></a>  recipes<span class="sc">::</span><span class="fu">recipe</span>(formula, <span class="at">data=</span>data) <span class="sc">%&gt;%</span> <span class="co">#formula is a 'y~x1+x2` thing, defining rhs and lhs variables</span></span>
<span id="cb93-438"><a href="#cb93-438" aria-hidden="true" tabindex="-1"></a>    recipes<span class="sc">::</span><span class="fu">step_impute_median</span>(<span class="fu">all_numeric_predictors</span>()) <span class="sc">%&gt;%</span> <span class="co">#rem: replaces missing values with medians</span></span>
<span id="cb93-439"><a href="#cb93-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-440"><a href="#cb93-440" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create NA feature</span></span>
<span id="cb93-441"><a href="#cb93-441" aria-hidden="true" tabindex="-1"></a>    recipes<span class="sc">::</span><span class="fu">step_unknown</span>(<span class="fu">all_nominal_predictors</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb93-442"><a href="#cb93-442" aria-hidden="true" tabindex="-1"></a>    recipes<span class="sc">::</span><span class="fu">step_scale</span>(<span class="fu">all_numeric_predictors</span>(), <span class="at">factor=</span><span class="dv">2</span>) <span class="sc">%&gt;%</span> <span class="co">#the 2sd Gelman adjustment</span></span>
<span id="cb93-443"><a href="#cb93-443" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Removing because redundant: step_impute_mode(all_nominal_predictors(), -all_outcomes()) %&gt;%</span></span>
<span id="cb93-444"><a href="#cb93-444" aria-hidden="true" tabindex="-1"></a>    recipes<span class="sc">::</span><span class="fu">step_zv</span>(<span class="fu">all_predictors</span>()) <span class="sc">%&gt;%</span> <span class="co">#cut any predictors with zero variance</span></span>
<span id="cb93-445"><a href="#cb93-445" aria-hidden="true" tabindex="-1"></a>    recipes<span class="sc">::</span><span class="fu">step_dummy</span>(<span class="fu">all_nominal_predictors</span>())</span>
<span id="cb93-446"><a href="#cb93-446" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb93-447"><a href="#cb93-447" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-448"><a href="#cb93-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-449"><a href="#cb93-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-450"><a href="#cb93-450" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb93-451"><a href="#cb93-451" aria-hidden="true" tabindex="-1"></a><span class="fu">## In the code above, the `preprocess_func` function defines a recipe that:</span></span>
<span id="cb93-452"><a href="#cb93-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-453"><a href="#cb93-453" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Is applied to a particular formula and data set</span>
<span id="cb93-454"><a href="#cb93-454" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>For all numeric rhs variables:</span>
<span id="cb93-455"><a href="#cb93-455" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>imputes them at their median values, where missing</span>
<span id="cb93-456"><a href="#cb93-456" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>de-means them scales them by a factor of 2 standard deviations (see Gelman)</span>
<span id="cb93-457"><a href="#cb93-457" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Removes any rhs variables with zero variance</span>
<span id="cb93-458"><a href="#cb93-458" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Makes standard dummy variables out of all 'nominal' (categorical) rhs variables </span>
<span id="cb93-459"><a href="#cb93-459" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb93-460"><a href="#cb93-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-461"><a href="#cb93-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-462"><a href="#cb93-462" aria-hidden="true" tabindex="-1"></a>Next, in the code below, we apply the above <span class="in">`preprocess_func`</span> to actually create the recipes.^<span class="co">[</span><span class="ot">Note that this is still not modifying any *data*, as we are not *applying* the recipes yet.</span><span class="co">]</span></span>
<span id="cb93-463"><a href="#cb93-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-464"><a href="#cb93-464" aria-hidden="true" tabindex="-1"></a><span class="in">```{r create_recipes}</span></span>
<span id="cb93-465"><a href="#cb93-465" aria-hidden="true" tabindex="-1"></a><span class="co"># Create recipes (defined above in preprocess_func) (with 'formulas') attached to data objects (default is 'train')</span></span>
<span id="cb93-466"><a href="#cb93-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-467"><a href="#cb93-467" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_rec <span class="ot">&lt;-</span> <span class="fu">preprocess_func</span>(l_don_av_2yr_f, <span class="at">data=</span>train) <span class="co">#used preprocess_func to define a recipe</span></span>
<span id="cb93-468"><a href="#cb93-468" aria-hidden="true" tabindex="-1"></a><span class="co">#`data=train` as a reminder that this is a data thing</span></span>
<span id="cb93-469"><a href="#cb93-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-470"><a href="#cb93-470" aria-hidden="true" tabindex="-1"></a>don_share_inc_imp_rec <span class="ot">&lt;-</span> <span class="fu">preprocess_func</span>(don_share_inc_imp_f)</span>
<span id="cb93-471"><a href="#cb93-471" aria-hidden="true" tabindex="-1"></a>d_don_1k_rec <span class="ot">&lt;-</span> <span class="fu">preprocess_func</span>(d_don_1k_f)</span>
<span id="cb93-472"><a href="#cb93-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-473"><a href="#cb93-473" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_rec_filter <span class="ot">&lt;-</span> <span class="fu">preprocess_func</span>(l_don_av_2yr_f, <span class="at">data =</span> train_filter)</span>
<span id="cb93-474"><a href="#cb93-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-475"><a href="#cb93-475" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-476"><a href="#cb93-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-477"><a href="#cb93-477" aria-hidden="true" tabindex="-1"></a>For example, </span>
<span id="cb93-478"><a href="#cb93-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-479"><a href="#cb93-479" aria-hidden="true" tabindex="-1"></a><span class="in">`l_don_av_2yr_rec_filter &lt;- preprocess_func(l_don_av_2yr_f, data = train_filter)`</span></span>
<span id="cb93-480"><a href="#cb93-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-481"><a href="#cb93-481" aria-hidden="true" tabindex="-1"></a>creates a recipe object that is summarized as</span>
<span id="cb93-482"><a href="#cb93-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-485"><a href="#cb93-485" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-486"><a href="#cb93-486" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_rec_filter</span>
<span id="cb93-487"><a href="#cb93-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-488"><a href="#cb93-488" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-489"><a href="#cb93-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-490"><a href="#cb93-490" aria-hidden="true" tabindex="-1"></a><span class="fu">## Defining machine learning models (procedures)</span></span>
<span id="cb93-491"><a href="#cb93-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-492"><a href="#cb93-492" aria-hidden="true" tabindex="-1"></a>We defined the data 'environment', the formula objects, and the 'recipes'.  Now we define the 'ML models', i.e., the procedures for 'what sort of predictive models do we want to build, and how'?</span>
<span id="cb93-493"><a href="#cb93-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-494"><a href="#cb93-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-495"><a href="#cb93-495" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb93-496"><a href="#cb93-496" aria-hidden="true" tabindex="-1"></a><span class="fu">## I will skip the 'decision tree' model here</span></span>
<span id="cb93-497"><a href="#cb93-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-498"><a href="#cb93-498" aria-hidden="true" tabindex="-1"></a>A regression/decision tree is a rather simple approach, easy to understand and interpret. However, I suspect it is not great for prediction in our example here. IIRC it is dominated by the Random Forest approach. Thus, I skip it, for brevity.</span>
<span id="cb93-499"><a href="#cb93-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-500"><a href="#cb93-500" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb93-501"><a href="#cb93-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-502"><a href="#cb93-502" aria-hidden="true" tabindex="-1"></a><span class="fu">### Random forest model</span></span>
<span id="cb93-503"><a href="#cb93-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-504"><a href="#cb93-504" aria-hidden="true" tabindex="-1"></a>Briefly, the random forest approach tries to predict outcomes through building a number of independent "trees", and averaging over these. </span>
<span id="cb93-505"><a href="#cb93-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-506"><a href="#cb93-506" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb93-507"><a href="#cb93-507" aria-hidden="true" tabindex="-1"></a><span class="fu">## Trees?</span></span>
<span id="cb93-508"><a href="#cb93-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-509"><a href="#cb93-509" aria-hidden="true" tabindex="-1"></a>I'm not going to explain this whole procedure here. We flesh this out a bit more <span class="co">[</span><span class="ot">here</span><span class="co">](https://daaronr.github.io/metrics_discussion/control-ml.html#tree-models)</span>, but note others can  do a better job of explaining it than us.  Still, a few notes, possibly with incorrect terminology. </span>
<span id="cb93-510"><a href="#cb93-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-511"><a href="#cb93-511" aria-hidden="true" tabindex="-1"></a>Just think of splitting up the data first by one category, then by another category. E.g., we could split it by gender, and then by income being over some threshold, to give us four categories or 'leaf nodes'. For each category at the bottom of each tree (leaf node), you make a single prediction for the outcome variable. We try to build these trees in away so that there is as much homogeneity as possible within each leaf node, and as much difference between leaf nods as possible... So that our predictions are as good as possible.  We fit this in a way that maximize its prediction power within the training sample, obviously, but subject to a 'penalty for more branchings' ...  with the goal of predicting well on data we didn't use to fit the model. </span>
<span id="cb93-512"><a href="#cb93-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-513"><a href="#cb93-513" aria-hidden="true" tabindex="-1"></a>How do you choose 'what to split it by first' and 'then by what'? There are algorithms. Essentially, you try each variable and see which variable and which split of that variable reduces the "entropy" the most at a particular node.</span>
<span id="cb93-514"><a href="#cb93-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-515"><a href="#cb93-515" aria-hidden="true" tabindex="-1"></a>Why might this approach be better than regression approaches? Trees seem to force you to use each feature rather bluntly, in a sequence of splits at single cutoff points only (for continuous variables). In contrast, regressions allow you to weigh a different features against each other and have different relative strengths. On the other hand, tree models seem to allow intricate patterns of interactions between different features in ways that would be difficult to accommodate in a regression model. </span>
<span id="cb93-516"><a href="#cb93-516" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb93-517"><a href="#cb93-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-518"><a href="#cb93-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-519"><a href="#cb93-519" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb93-520"><a href="#cb93-520" aria-hidden="true" tabindex="-1"></a><span class="fu">## Random forests?</span></span>
<span id="cb93-521"><a href="#cb93-521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-522"><a href="#cb93-522" aria-hidden="true" tabindex="-1"></a>Above, I basically described the creation of an individual tree you could use to predict outcomes with. But it seems the creation of such trees is rather sensitive to initial conditions, and maybe it's sensitive to the particular date are you are using to fit the model. Random forest does something like... "build a bunch of tree models and average them". But you can't build a bunch of different independent tree models unless you make some restrictions to each one, so for each tree it randomly samples a set of features from the full set, and leaves others out of the model.</span>
<span id="cb93-523"><a href="#cb93-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-524"><a href="#cb93-524" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb93-525"><a href="#cb93-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-526"><a href="#cb93-526" aria-hidden="true" tabindex="-1"></a>Below, we define <span class="in">`rf_model_reg`</span> as a <span class="in">`parsnip`</span> object. </span>
<span id="cb93-527"><a href="#cb93-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-530"><a href="#cb93-530" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-531"><a href="#cb93-531" aria-hidden="true" tabindex="-1"></a>rf_model_reg <span class="ot">&lt;-</span> parsnip<span class="sc">::</span><span class="fu">rand_forest</span>(</span>
<span id="cb93-532"><a href="#cb93-532" aria-hidden="true" tabindex="-1"></a>  <span class="at">mtry =</span> <span class="fu">tune</span>(), <span class="co">#number of predictors to randomly sample at each 'split'</span></span>
<span id="cb93-533"><a href="#cb93-533" aria-hidden="true" tabindex="-1"></a>  <span class="co">#trees = tune(), #how many trees in the 'ensemble'</span></span>
<span id="cb93-534"><a href="#cb93-534" aria-hidden="true" tabindex="-1"></a>  <span class="at">trees =</span> <span class="dv">50</span>, <span class="co">#how many trees in the 'ensemble'</span></span>
<span id="cb93-535"><a href="#cb93-535" aria-hidden="true" tabindex="-1"></a>  <span class="at">min_n =</span> <span class="fu">tune</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb93-536"><a href="#cb93-536" aria-hidden="true" tabindex="-1"></a>  parsnip<span class="sc">::</span><span class="fu">set_engine</span>(<span class="st">"ranger"</span>, <span class="at">importance =</span> <span class="st">"impurity"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb93-537"><a href="#cb93-537" aria-hidden="true" tabindex="-1"></a>  parsnip<span class="sc">::</span><span class="fu">set_mode</span>(<span class="st">"regression"</span>)</span>
<span id="cb93-538"><a href="#cb93-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-539"><a href="#cb93-539" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-540"><a href="#cb93-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-541"><a href="#cb93-541" aria-hidden="true" tabindex="-1"></a>We specify, </span>
<span id="cb93-542"><a href="#cb93-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-543"><a href="#cb93-543" aria-hidden="true" tabindex="-1"></a><span class="in">`mtry = tune()`</span>: How many predictors should we randomly sample for each split (tree?). We set this to <span class="in">`tune`</span>; that means we allow the cross-fold validation process to tell us what seems to work best.</span>
<span id="cb93-544"><a href="#cb93-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-545"><a href="#cb93-545" aria-hidden="true" tabindex="-1"></a>We also set it to 'tune':</span>
<span id="cb93-546"><a href="#cb93-546" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`min_n`</span>: how few observations each (leaf) node is allowed to contain</span>
<span id="cb93-547"><a href="#cb93-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-548"><a href="#cb93-548" aria-hidden="true" tabindex="-1"></a>We normally would also tune the </span>
<span id="cb93-549"><a href="#cb93-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-550"><a href="#cb93-550" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`trees`</span>: how many trees in the 'ensemble' (the 'forest'?)</span>
<span id="cb93-551"><a href="#cb93-551" aria-hidden="true" tabindex="-1"></a>... but here I set it to only use 50 trees to save processing time ... for this example</span>
<span id="cb93-552"><a href="#cb93-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-553"><a href="#cb93-553" aria-hidden="true" tabindex="-1"></a>^<span class="co">[</span><span class="ot">`set_mode("regression")` indicates that the outcome is continuous, rather than 'classification', I believe.  I am not sure what exactly  the `set_engine` options mean here.</span><span class="co">]</span></span>
<span id="cb93-554"><a href="#cb93-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-555"><a href="#cb93-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-556"><a href="#cb93-556" aria-hidden="true" tabindex="-1"></a><span class="fu">## Glmnet penalized regression</span></span>
<span id="cb93-557"><a href="#cb93-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-558"><a href="#cb93-558" aria-hidden="true" tabindex="-1"></a>This is simply a regression approach with 'penalization' or 'shrinkage' ... but done in a sophisticated way. </span>
<span id="cb93-559"><a href="#cb93-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-560"><a href="#cb93-560" aria-hidden="true" tabindex="-1"></a>The GLMnet approach combines 'ridge (L2 norm) and lasso (L2 norm)', tuning the mix of each, as well as tuning the penalization parameters *within* each.</span>
<span id="cb93-561"><a href="#cb93-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-562"><a href="#cb93-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-563"><a href="#cb93-563" aria-hidden="true" tabindex="-1"></a>We discuss this further under <span class="co">[</span><span class="ot">'penalized regression models'</span><span class="co">](#penalized-reg)</span> in our machine learning modeling section. </span>
<span id="cb93-564"><a href="#cb93-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-565"><a href="#cb93-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-566"><a href="#cb93-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-567"><a href="#cb93-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-568"><a href="#cb93-568" aria-hidden="true" tabindex="-1"></a><span class="in">```{r linear_model_reg}</span></span>
<span id="cb93-569"><a href="#cb93-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-570"><a href="#cb93-570" aria-hidden="true" tabindex="-1"></a>linear_model_reg <span class="ot">&lt;-</span> <span class="fu">linear_reg</span>(<span class="at">penalty =</span> <span class="fu">tune</span>(), </span>
<span id="cb93-571"><a href="#cb93-571" aria-hidden="true" tabindex="-1"></a>                               <span class="at">mixture =</span> <span class="fu">tune</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb93-572"><a href="#cb93-572" aria-hidden="true" tabindex="-1"></a>            <span class="fu">set_engine</span>(<span class="st">"glmnet"</span>)</span>
<span id="cb93-573"><a href="#cb93-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-574"><a href="#cb93-574" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-575"><a href="#cb93-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-576"><a href="#cb93-576" aria-hidden="true" tabindex="-1"></a>In the code above, we define the <span class="in">`linear_model_reg`</span> <span class="in">`linear_reg`</span> object. We specify the 'engine' we use, and, as noted, that we are using cross-validation tuning to determine how much to penalize coefficient sizes overall, and for each norm (with what 'mixture' of L1 and L2 norms).</span>
<span id="cb93-577"><a href="#cb93-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-578"><a href="#cb93-578" aria-hidden="true" tabindex="-1"></a>Next we make a list of both of the above defined 'regression models'</span>
<span id="cb93-579"><a href="#cb93-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-582"><a href="#cb93-582" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-583"><a href="#cb93-583" aria-hidden="true" tabindex="-1"></a><span class="co"># Create list of 'regression models' (i.e., continuous outcomes)</span></span>
<span id="cb93-584"><a href="#cb93-584" aria-hidden="true" tabindex="-1"></a>regression_models <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">random_forest =</span> rf_model_reg,</span>
<span id="cb93-585"><a href="#cb93-585" aria-hidden="true" tabindex="-1"></a>                          <span class="at">linear_reg =</span> linear_model_reg)</span>
<span id="cb93-586"><a href="#cb93-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-587"><a href="#cb93-587" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-588"><a href="#cb93-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-589"><a href="#cb93-589" aria-hidden="true" tabindex="-1"></a><span class="fu">## Classification models (Forest and Logistic  Regression)</span></span>
<span id="cb93-590"><a href="#cb93-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-591"><a href="#cb93-591" aria-hidden="true" tabindex="-1"></a>We do the same as above, but defining the models/modeling procedures for 'classification models', i.e., for those cases where we have a non-continuous outcome; in our case 'whether they donated 1000 USD or more`. We define a random forest 'classification' as well as an elastic net version of a logistic (logit) model, and then a list combining both.s</span>
<span id="cb93-592"><a href="#cb93-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-593"><a href="#cb93-593" aria-hidden="true" tabindex="-1"></a><span class="in">```{r rf_model_class}</span></span>
<span id="cb93-594"><a href="#cb93-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-595"><a href="#cb93-595" aria-hidden="true" tabindex="-1"></a><span class="co"># Random forest model</span></span>
<span id="cb93-596"><a href="#cb93-596" aria-hidden="true" tabindex="-1"></a>rf_model_class <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>(<span class="at">mtry =</span> <span class="fu">tune</span>(), <span class="co">#number of predictors to randomly sample at each 'split'</span></span>
<span id="cb93-597"><a href="#cb93-597" aria-hidden="true" tabindex="-1"></a>                              <span class="at">trees =</span> <span class="fu">tune</span>(), <span class="co">#how many trees in the 'ensemble'</span></span>
<span id="cb93-598"><a href="#cb93-598" aria-hidden="true" tabindex="-1"></a>                              <span class="at">min_n =</span> <span class="fu">tune</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb93-599"><a href="#cb93-599" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"ranger"</span>, <span class="at">importance =</span> <span class="st">"impurity"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb93-600"><a href="#cb93-600" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">"classification"</span>)</span>
<span id="cb93-601"><a href="#cb93-601" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-602"><a href="#cb93-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-603"><a href="#cb93-603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-604"><a href="#cb93-604" aria-hidden="true" tabindex="-1"></a><span class="in">```{r logistic_model_reg}</span></span>
<span id="cb93-605"><a href="#cb93-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-606"><a href="#cb93-606" aria-hidden="true" tabindex="-1"></a><span class="co"># Logistic regression</span></span>
<span id="cb93-607"><a href="#cb93-607" aria-hidden="true" tabindex="-1"></a>logistic_model_reg <span class="ot">&lt;-</span> <span class="fu">logistic_reg</span>(<span class="at">penalty =</span> <span class="fu">tune</span>(),</span>
<span id="cb93-608"><a href="#cb93-608" aria-hidden="true" tabindex="-1"></a>                                   <span class="at">mixture =</span> <span class="fu">tune</span>()) <span class="sc">%&gt;%</span> <span class="co">#DR, @OS -- what is the 'mixture' here? -- is it a mixture of L1 and L2 norms (ridge and lasso?)</span></span>
<span id="cb93-609"><a href="#cb93-609" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"glmnet"</span>)</span>
<span id="cb93-610"><a href="#cb93-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-611"><a href="#cb93-611" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-612"><a href="#cb93-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-615"><a href="#cb93-615" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-616"><a href="#cb93-616" aria-hidden="true" tabindex="-1"></a>classification_models <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb93-617"><a href="#cb93-617" aria-hidden="true" tabindex="-1"></a>                              <span class="at">random_forest =</span> rf_model_class,</span>
<span id="cb93-618"><a href="#cb93-618" aria-hidden="true" tabindex="-1"></a>                              <span class="at">logistic_reg =</span> logistic_model_reg)</span>
<span id="cb93-619"><a href="#cb93-619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-620"><a href="#cb93-620" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-621"><a href="#cb93-621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-622"><a href="#cb93-622" aria-hidden="true" tabindex="-1"></a><span class="fu">## Create workflows</span></span>
<span id="cb93-623"><a href="#cb93-623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-624"><a href="#cb93-624" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; A workflow is an object that can bundle together your pre-processing, modeling, and post-processing requests.</span></span>
<span id="cb93-625"><a href="#cb93-625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-626"><a href="#cb93-626" aria-hidden="true" tabindex="-1"></a>This should make the flow 'tidy' and the output easy to use (I hope this becomes obvious below). ^<span class="co">[</span><span class="ot">While we tend to do only 'one of each thing' below (a single recipe step tied to a single modeling step), the package is designed to enable lists of each, to enable all, or some combinations to be produced. See the authors' vignette [here](https://workflowsets.tidymodels.org/reference/workflow_set.html)</span><span class="co">]</span></span>
<span id="cb93-627"><a href="#cb93-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-628"><a href="#cb93-628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-629"><a href="#cb93-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-630"><a href="#cb93-630" aria-hidden="true" tabindex="-1"></a>Next, we create a workflow set for the 'log of 2 year averaged donation' outcome (with the income filtered data):^<span class="co">[</span><span class="ot">Also, as a preparation for this we 'fit random forest parameter ranges to data'. I am not conpletely sure what is going on here. We should also find a cleaner way to do this.</span><span class="co">]</span></span>
<span id="cb93-631"><a href="#cb93-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-632"><a href="#cb93-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-633"><a href="#cb93-633" aria-hidden="true" tabindex="-1"></a><span class="in">```{r l_don_av_2yr_wf_filter}</span></span>
<span id="cb93-634"><a href="#cb93-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-635"><a href="#cb93-635" aria-hidden="true" tabindex="-1"></a><span class="co">#pre-step ... not sure how it works</span></span>
<span id="cb93-636"><a href="#cb93-636" aria-hidden="true" tabindex="-1"></a>rf_params <span class="ot">&lt;-</span> tune<span class="sc">::</span><span class="fu">parameters</span>(rf_model_reg) <span class="sc">%&gt;%</span></span>
<span id="cb93-637"><a href="#cb93-637" aria-hidden="true" tabindex="-1"></a>  recipes<span class="sc">::</span><span class="fu">update</span>(<span class="at">mtry =</span> <span class="fu">mtry</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="fu">nrow</span>(d_don_1k_rec<span class="sc">$</span>var_info)<span class="sc">-</span><span class="dv">1</span>))) </span>
<span id="cb93-638"><a href="#cb93-638" aria-hidden="true" tabindex="-1"></a><span class="co">#Note that 'mtry' is 'number of sampled predictors'</span></span>
<span id="cb93-639"><a href="#cb93-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-640"><a href="#cb93-640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-641"><a href="#cb93-641" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_wf_filter <span class="ot">&lt;-</span></span>
<span id="cb93-642"><a href="#cb93-642" aria-hidden="true" tabindex="-1"></a>  <span class="fu">workflow_set</span>(</span>
<span id="cb93-643"><a href="#cb93-643" aria-hidden="true" tabindex="-1"></a>    <span class="at">preproc =</span> <span class="fu">list</span>(<span class="at">preprocess =</span> l_don_av_2yr_rec_filter),</span>
<span id="cb93-644"><a href="#cb93-644" aria-hidden="true" tabindex="-1"></a>               <span class="co">#'preprocessing objects' ... here 'recipes'</span></span>
<span id="cb93-645"><a href="#cb93-645" aria-hidden="true" tabindex="-1"></a>               <span class="at">models =</span> regression_models) <span class="sc">%&gt;%</span> <span class="co">#'parsnip model specifications'</span></span>
<span id="cb93-646"><a href="#cb93-646" aria-hidden="true" tabindex="-1"></a>  <span class="fu">option_add_parameters</span>() <span class="sc">%&gt;%</span> <span class="co">#'adds a parameter object to the 'option' column'</span></span>
<span id="cb93-647"><a href="#cb93-647" aria-hidden="true" tabindex="-1"></a>  <span class="fu">option_add</span>(<span class="at">param_info =</span> rf_params, <span class="co">#this is the restriction defined above</span></span>
<span id="cb93-648"><a href="#cb93-648" aria-hidden="true" tabindex="-1"></a>             <span class="at">id =</span> <span class="st">"preprocess_random_forest"</span>)</span>
<span id="cb93-649"><a href="#cb93-649" aria-hidden="true" tabindex="-1"></a><span class="co">#'add options saved in a workflow set' esp in the 'option column'</span></span>
<span id="cb93-650"><a href="#cb93-650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-651"><a href="#cb93-651" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_wf_filter</span>
<span id="cb93-652"><a href="#cb93-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-653"><a href="#cb93-653" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_wf_filter<span class="sc">$</span>info</span>
<span id="cb93-654"><a href="#cb93-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-655"><a href="#cb93-655" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-656"><a href="#cb93-656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-657"><a href="#cb93-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-658"><a href="#cb93-658" aria-hidden="true" tabindex="-1"></a>This has a lot of 'stuff in it'. We give it the preprocessing recipe <span class="in">`l_don_av_2yr_rec`</span> (and the formula?)  as discussed above, and the set of modeling procedures  we defined under <span class="in">`regression_models`</span>,</span>
<span id="cb93-659"><a href="#cb93-659" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb93-660"><a href="#cb93-660" aria-hidden="true" tabindex="-1"></a> We do similarly for the 'donate over 1k' binary outcome and associated modeling approach.^<span class="co">[</span><span class="ot">I will skip the 'donation share' outcome here for brevity</span><span class="co">]</span></span>
<span id="cb93-661"><a href="#cb93-661" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb93-662"><a href="#cb93-662" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb93-663"><a href="#cb93-663" aria-hidden="true" tabindex="-1"></a><span class="in">```{r d_don_1k_wf}</span></span>
<span id="cb93-664"><a href="#cb93-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-665"><a href="#cb93-665" aria-hidden="true" tabindex="-1"></a>d_don_1k_wf <span class="ot">&lt;-</span></span>
<span id="cb93-666"><a href="#cb93-666" aria-hidden="true" tabindex="-1"></a>  <span class="fu">workflow_set</span>(</span>
<span id="cb93-667"><a href="#cb93-667" aria-hidden="true" tabindex="-1"></a>    <span class="at">preproc =</span> <span class="fu">list</span>(<span class="at">preprocess =</span> d_don_1k_rec),</span>
<span id="cb93-668"><a href="#cb93-668" aria-hidden="true" tabindex="-1"></a>               <span class="at">models =</span> classification_models) <span class="sc">%&gt;%</span></span>
<span id="cb93-669"><a href="#cb93-669" aria-hidden="true" tabindex="-1"></a>  <span class="fu">option_add</span>(<span class="at">param_info =</span> rf_params, <span class="at">id =</span> <span class="st">"preprocess_random_forest"</span>)</span>
<span id="cb93-670"><a href="#cb93-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-671"><a href="#cb93-671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-672"><a href="#cb93-672" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-673"><a href="#cb93-673" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb93-674"><a href="#cb93-674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-675"><a href="#cb93-675" aria-hidden="true" tabindex="-1"></a><span class="fu"># Fitting models </span></span>
<span id="cb93-676"><a href="#cb93-676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-677"><a href="#cb93-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-678"><a href="#cb93-678" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb93-679"><a href="#cb93-679" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bayesian optimization</span></span>
<span id="cb93-680"><a href="#cb93-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-681"><a href="#cb93-681" aria-hidden="true" tabindex="-1"></a>We have a large space to explore. We use 'Bayesian optimization', presumably, for the *tuning parameters* only, i.e., the combinations of 'hyper-parameters' (the penalization parameters). It iterates towards what seems to be an optimum (maximum posterior?) in this 'structured space'. This is claimed to be "quicker than grid search and more effective than random search." </span>
<span id="cb93-682"><a href="#cb93-682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-683"><a href="#cb93-683" aria-hidden="true" tabindex="-1"></a>Note that the underlying procedures are not Bayesian (as far as I know). We are not assigning a prior over (e.g.) the coefficients/'weights' on the variables/features in the linear models. Conditional on the tuning parameters are computed according to a simple algorithm (linear models: minimized least squares subject to the penalization, or some such).</span>
<span id="cb93-684"><a href="#cb93-684" aria-hidden="true" tabindex="-1"></a>::: </span>
<span id="cb93-685"><a href="#cb93-685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-686"><a href="#cb93-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-687"><a href="#cb93-687" aria-hidden="true" tabindex="-1"></a>Options for Bayesian optimization (for tuning parameters?)</span>
<span id="cb93-688"><a href="#cb93-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-689"><a href="#cb93-689" aria-hidden="true" tabindex="-1"></a><span class="in">```{r bayes_ctrl}</span></span>
<span id="cb93-690"><a href="#cb93-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-691"><a href="#cb93-691" aria-hidden="true" tabindex="-1"></a>bayes_ctrl <span class="ot">&lt;-</span> <span class="fu">control_bayes</span>(<span class="at">parallel_over =</span> <span class="st">"everything"</span>,</span>
<span id="cb93-692"><a href="#cb93-692" aria-hidden="true" tabindex="-1"></a>                      <span class="at">verbose =</span> <span class="cn">TRUE</span>,</span>
<span id="cb93-693"><a href="#cb93-693" aria-hidden="true" tabindex="-1"></a>                      <span class="co"># no_improve = 1,</span></span>
<span id="cb93-694"><a href="#cb93-694" aria-hidden="true" tabindex="-1"></a>                      <span class="at">save_pred =</span> <span class="cn">TRUE</span>,</span>
<span id="cb93-695"><a href="#cb93-695" aria-hidden="true" tabindex="-1"></a>                      <span class="at">save_workflow =</span> <span class="cn">TRUE</span>,</span>
<span id="cb93-696"><a href="#cb93-696" aria-hidden="true" tabindex="-1"></a>                      <span class="at">seed =</span> seed)</span>
<span id="cb93-697"><a href="#cb93-697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-698"><a href="#cb93-698" aria-hidden="true" tabindex="-1"></a><span class="co">#max_iter &lt;- 30</span></span>
<span id="cb93-699"><a href="#cb93-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-700"><a href="#cb93-700" aria-hidden="true" tabindex="-1"></a>max_iter <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb93-701"><a href="#cb93-701" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-702"><a href="#cb93-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-703"><a href="#cb93-703" aria-hidden="true" tabindex="-1"></a>Normally we would set a large number of iterations, but as this is a vignette we set it to 4 iterations only. It still takes a few minutes.^<span class="co">[</span><span class="ot">I wonder if there is a way to speed it up further, for demo purposes. It generates a lot of 'candidates' -- maybe this can be reduced.s</span><span class="co">]</span></span>
<span id="cb93-704"><a href="#cb93-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-705"><a href="#cb93-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-706"><a href="#cb93-706" aria-hidden="true" tabindex="-1"></a><span class="fu">## Actual fitting</span></span>
<span id="cb93-707"><a href="#cb93-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-708"><a href="#cb93-708" aria-hidden="true" tabindex="-1"></a>We now 'map the workflow' to actually estimate the model, using <span class="in">`workflow_map`</span>. </span>
<span id="cb93-709"><a href="#cb93-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-710"><a href="#cb93-710" aria-hidden="true" tabindex="-1"></a>It takes the workflow object (below <span class="in">`l_don_av_2yr_wf`</span>) and 'runs the function', here ... </span>
<span id="cb93-711"><a href="#cb93-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-712"><a href="#cb93-712" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; tune_bayes() uses models to generate new candidate tuning parameter combinations based on previous results.</span></span>
<span id="cb93-713"><a href="#cb93-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-714"><a href="#cb93-714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-715"><a href="#cb93-715" aria-hidden="true" tabindex="-1"></a><span class="in">```{r l_don_av_2yr_results_filter}</span></span>
<span id="cb93-716"><a href="#cb93-716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-717"><a href="#cb93-717" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_results_filter <span class="ot">&lt;-</span> l_don_av_2yr_wf_filter <span class="sc">%&gt;%</span></span>
<span id="cb93-718"><a href="#cb93-718" aria-hidden="true" tabindex="-1"></a>  <span class="fu">workflow_map</span>(<span class="st">"tune_bayes"</span>,</span>
<span id="cb93-719"><a href="#cb93-719" aria-hidden="true" tabindex="-1"></a>               <span class="at">seed =</span> seed,</span>
<span id="cb93-720"><a href="#cb93-720" aria-hidden="true" tabindex="-1"></a>               <span class="at">resamples =</span> cv,</span>
<span id="cb93-721"><a href="#cb93-721" aria-hidden="true" tabindex="-1"></a>               <span class="at">iter =</span> max_iter,</span>
<span id="cb93-722"><a href="#cb93-722" aria-hidden="true" tabindex="-1"></a>               <span class="co"># metrics = metric_set(mae),</span></span>
<span id="cb93-723"><a href="#cb93-723" aria-hidden="true" tabindex="-1"></a>               <span class="at">control =</span> bayes_ctrl) <span class="co">#'control' how the function works</span></span>
<span id="cb93-724"><a href="#cb93-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-725"><a href="#cb93-725" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-726"><a href="#cb93-726" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-727"><a href="#cb93-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-728"><a href="#cb93-728" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- @Oska -- do you know if there is a way to recover those iteration results in the output without having it verbose? --&gt;</span></span>
<span id="cb93-729"><a href="#cb93-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-730"><a href="#cb93-730" aria-hidden="true" tabindex="-1"></a>Sorry for all the output above ... that is because we set <span class="in">`verbose=TRUE`</span>. It is considering the tuning parameters to minimize root-mean-squared error of the prediction. The random forest seems to swing widely in some dimensions, e.g., first considering about 400 trees, then 4 tree. then a few hundred trees again. It probably needs more iterations to really converge. </span>
<span id="cb93-731"><a href="#cb93-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-732"><a href="#cb93-732" aria-hidden="true" tabindex="-1"></a>The elastic net also seems to have substantially adjusted (reduced) the level of penalization over these few iterations, and moved much more towards the ridge approach (L2 norm) and away from the lasso (L1).</span>
<span id="cb93-733"><a href="#cb93-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-734"><a href="#cb93-734" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- produces a tibble of fit workflows, has not yet been applied to the testing data  --&gt;</span></span>
<span id="cb93-735"><a href="#cb93-735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-736"><a href="#cb93-736" aria-hidden="true" tabindex="-1"></a>We next fit the models with binary (1k donation) outcome, for the random forest and logistic regression 'classifiers'.</span>
<span id="cb93-737"><a href="#cb93-737" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-738"><a href="#cb93-738" aria-hidden="true" tabindex="-1"></a><span class="in">```{r d_don_1k_results}</span></span>
<span id="cb93-739"><a href="#cb93-739" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-740"><a href="#cb93-740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-741"><a href="#cb93-741" aria-hidden="true" tabindex="-1"></a>bayes_ctrl<span class="sc">$</span>verbose <span class="ot">&lt;-</span> <span class="cn">FALSE</span></span>
<span id="cb93-742"><a href="#cb93-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-743"><a href="#cb93-743" aria-hidden="true" tabindex="-1"></a>d_don_1k_results <span class="ot">&lt;-</span> d_don_1k_wf <span class="sc">%&gt;%</span></span>
<span id="cb93-744"><a href="#cb93-744" aria-hidden="true" tabindex="-1"></a>  <span class="fu">workflow_map</span>(<span class="st">"tune_bayes"</span>,</span>
<span id="cb93-745"><a href="#cb93-745" aria-hidden="true" tabindex="-1"></a>               <span class="at">seed =</span> seed,</span>
<span id="cb93-746"><a href="#cb93-746" aria-hidden="true" tabindex="-1"></a>               <span class="at">resamples =</span> cv,</span>
<span id="cb93-747"><a href="#cb93-747" aria-hidden="true" tabindex="-1"></a>               <span class="at">iter =</span> max_iter,</span>
<span id="cb93-748"><a href="#cb93-748" aria-hidden="true" tabindex="-1"></a>               <span class="at">control =</span> bayes_ctrl)</span>
<span id="cb93-749"><a href="#cb93-749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-750"><a href="#cb93-750" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-751"><a href="#cb93-751" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-752"><a href="#cb93-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-753"><a href="#cb93-753" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb93-754"><a href="#cb93-754" aria-hidden="true" tabindex="-1"></a><span class="fu">## Iteration 4 ... classification models</span></span>
<span id="cb93-755"><a href="#cb93-755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-756"><a href="#cb93-756" aria-hidden="true" tabindex="-1"></a>Random forest:</span>
<span id="cb93-757"><a href="#cb93-757" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-758"><a href="#cb93-758" aria-hidden="true" tabindex="-1"></a><span class="in">i Current best:     roc_auc=0.8441 (@iter 2)</span></span>
<span id="cb93-759"><a href="#cb93-759" aria-hidden="true" tabindex="-1"></a><span class="in">i Gaussian process model</span></span>
<span id="cb93-760"><a href="#cb93-760" aria-hidden="true" tabindex="-1"></a><span class="in">i Generating 4994 candidates</span></span>
<span id="cb93-761"><a href="#cb93-761" aria-hidden="true" tabindex="-1"></a><span class="in">i Predicted candidates</span></span>
<span id="cb93-762"><a href="#cb93-762" aria-hidden="true" tabindex="-1"></a><span class="in">i mtry=8, trees=106, min_n=40</span></span>
<span id="cb93-763"><a href="#cb93-763" aria-hidden="true" tabindex="-1"></a><span class="in">i Estimating performance</span></span>
<span id="cb93-764"><a href="#cb93-764" aria-hidden="true" tabindex="-1"></a><span class="in">Newest results: roc_auc=0.8424 (+/-0.00992)</span></span>
<span id="cb93-765"><a href="#cb93-765" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-766"><a href="#cb93-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-767"><a href="#cb93-767" aria-hidden="true" tabindex="-1"></a>Logistic Elastic net:</span>
<span id="cb93-768"><a href="#cb93-768" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-769"><a href="#cb93-769" aria-hidden="true" tabindex="-1"></a><span class="in">i Current best:     roc_auc=0.852 (@iter 2)</span></span>
<span id="cb93-770"><a href="#cb93-770" aria-hidden="true" tabindex="-1"></a><span class="in">i Gaussian process model</span></span>
<span id="cb93-771"><a href="#cb93-771" aria-hidden="true" tabindex="-1"></a><span class="in">i Generating 5000 candidates</span></span>
<span id="cb93-772"><a href="#cb93-772" aria-hidden="true" tabindex="-1"></a><span class="in">i Predicted candidates</span></span>
<span id="cb93-773"><a href="#cb93-773" aria-hidden="true" tabindex="-1"></a><span class="in">i penalty=1.75e-06, mixture=0.605</span></span>
<span id="cb93-774"><a href="#cb93-774" aria-hidden="true" tabindex="-1"></a><span class="in"> Estimating performance</span></span>
<span id="cb93-775"><a href="#cb93-775" aria-hidden="true" tabindex="-1"></a><span class="in"> Newest results:    roc_auc=0.8474 (+/-0.0087)</span></span>
<span id="cb93-776"><a href="#cb93-776" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-777"><a href="#cb93-777" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb93-778"><a href="#cb93-778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-779"><a href="#cb93-779" aria-hidden="true" tabindex="-1"></a>Above (pasted into fold) the iterations are tuning the parameters, as in the 'regression' models. Here they focus on a classification measure called the 'area under the receiver operating curve'; 0 is worst and 1 is best.^<span class="co">[</span><span class="ot">This considers both types of error (false negatives and positive; i.e., precision and recall). This metric equals with the area above the diagonal in a plot of the true positive rate against the false positive rate. For the elastic-net, it looks like the penalization rate is extremely low; I would want to dig more deeply into this.</span><span class="co">]</span></span>
<span id="cb93-780"><a href="#cb93-780" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-781"><a href="#cb93-781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-782"><a href="#cb93-782" aria-hidden="true" tabindex="-1"></a><span class="fu"># Working with results </span></span>
<span id="cb93-783"><a href="#cb93-783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-784"><a href="#cb93-784" aria-hidden="true" tabindex="-1"></a>So we fit a bunch of models and we have some workflow set/tibble objects. Now what do we do with them?</span>
<span id="cb93-785"><a href="#cb93-785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-786"><a href="#cb93-786" aria-hidden="true" tabindex="-1"></a>We may want to </span>
<span id="cb93-787"><a href="#cb93-787" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-788"><a href="#cb93-788" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Assess their performance on the testing data (set aside)</span>
<span id="cb93-789"><a href="#cb93-789" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-790"><a href="#cb93-790" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>"Interpret them" (Carefully! This can be dangerous/misleading.)</span>
<span id="cb93-791"><a href="#cb93-791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-792"><a href="#cb93-792" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Use them for actual prediction and 'profit' when we have future data^<span class="co">[</span><span class="ot">We could also use them for loose predictions for hypothetical scases or groups of people we expect to have certain characteristics.</span><span class="co">]</span></span>
<span id="cb93-793"><a href="#cb93-793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-794"><a href="#cb93-794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-795"><a href="#cb93-795" aria-hidden="true" tabindex="-1"></a>To enable 1 and 2, we do some cleanup and renaming below.^<span class="co">[</span><span class="ot">To save time in later work, we might try to build a function or something to automatically rename this stuff.</span><span class="co">]</span></span>
<span id="cb93-796"><a href="#cb93-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-799"><a href="#cb93-799" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-800"><a href="#cb93-800" aria-hidden="true" tabindex="-1"></a><span class="co"># Char vector for renaming of models from workflowset defaults (for display)</span></span>
<span id="cb93-801"><a href="#cb93-801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-802"><a href="#cb93-802" aria-hidden="true" tabindex="-1"></a>pred_model_names <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb93-803"><a href="#cb93-803" aria-hidden="true" tabindex="-1"></a>  <span class="st">"preprocess_random_forest"</span> <span class="ot">=</span> <span class="st">"Random Forest"</span>,</span>
<span id="cb93-804"><a href="#cb93-804" aria-hidden="true" tabindex="-1"></a>  <span class="st">"preprocess_linear_reg"</span> <span class="ot">=</span> <span class="st">"Linear Regression (glmnet)"</span>,</span>
<span id="cb93-805"><a href="#cb93-805" aria-hidden="true" tabindex="-1"></a>  <span class="st">"preprocess_logistic_reg"</span> <span class="ot">=</span> <span class="st">"Logistic Regression (glmnet)"</span>)</span>
<span id="cb93-806"><a href="#cb93-806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-807"><a href="#cb93-807" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-808"><a href="#cb93-808" aria-hidden="true" tabindex="-1"></a>rename_metrics <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Workflow"</span> <span class="ot">=</span> <span class="st">"wflow_id"</span>,</span>
<span id="cb93-809"><a href="#cb93-809" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Iteration"</span> <span class="ot">=</span> <span class="st">".config"</span>,</span>
<span id="cb93-810"><a href="#cb93-810" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Iteration Number"</span> <span class="ot">=</span> <span class="st">".iter"</span>,</span>
<span id="cb93-811"><a href="#cb93-811" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Preprocessing"</span> <span class="ot">=</span> <span class="st">"preproc"</span>,</span>
<span id="cb93-812"><a href="#cb93-812" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Model"</span> <span class="ot">=</span> <span class="st">"model"</span>,</span>
<span id="cb93-813"><a href="#cb93-813" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Metric"</span> <span class="ot">=</span> <span class="st">".metric"</span>,</span>
<span id="cb93-814"><a href="#cb93-814" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Estimator"</span> <span class="ot">=</span> <span class="st">".estimator"</span>,</span>
<span id="cb93-815"><a href="#cb93-815" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Mean"</span> <span class="ot">=</span> <span class="st">"mean"</span>,</span>
<span id="cb93-816"><a href="#cb93-816" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"N"</span> <span class="ot">=</span> <span class="st">"n"</span>,</span>
<span id="cb93-817"><a href="#cb93-817" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Standard error"</span> <span class="ot">=</span> <span class="st">"std_err"</span>)</span>
<span id="cb93-818"><a href="#cb93-818" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-819"><a href="#cb93-819" aria-hidden="true" tabindex="-1"></a>rename_models <span class="ot">&lt;-</span> <span class="cf">function</span>(df, <span class="at">new_names =</span> pred_model_names){</span>
<span id="cb93-820"><a href="#cb93-820" aria-hidden="true" tabindex="-1"></a>  df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span> </span>
<span id="cb93-821"><a href="#cb93-821" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">model =</span> stringr<span class="sc">::</span><span class="fu">str_replace_all</span>(model, pred_model_names))</span>
<span id="cb93-822"><a href="#cb93-822" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(df)</span>
<span id="cb93-823"><a href="#cb93-823" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb93-824"><a href="#cb93-824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-825"><a href="#cb93-825" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-826"><a href="#cb93-826" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-827"><a href="#cb93-827" aria-hidden="true" tabindex="-1"></a>Next we use the <span class="in">`best_wflow_preds_vi`</span> helper to extract the 'optimized' parameters and values from the above workflow set/tibble objects, and generate some metrics of fit with the appropriate training data. </span>
<span id="cb93-828"><a href="#cb93-828" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-829"><a href="#cb93-829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-830"><a href="#cb93-830" aria-hidden="true" tabindex="-1"></a><span class="in">```{r best_wflow_preds_vi_extract}</span></span>
<span id="cb93-831"><a href="#cb93-831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-832"><a href="#cb93-832" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_best_params_filter <span class="ot">&lt;-</span> <span class="fu">best_wflow_preds_vi</span>(l_don_av_2yr_results_filter,</span>
<span id="cb93-833"><a href="#cb93-833" aria-hidden="true" tabindex="-1"></a>  <span class="at">outcome_var =</span> <span class="st">"l_don_av_2yr"</span>, </span>
<span id="cb93-834"><a href="#cb93-834" aria-hidden="true" tabindex="-1"></a>  <span class="at">train_sample =</span> train_filter,</span>
<span id="cb93-835"><a href="#cb93-835" aria-hidden="true" tabindex="-1"></a>  <span class="at">test_sample =</span> test_filter)</span>
<span id="cb93-836"><a href="#cb93-836" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-837"><a href="#cb93-837" aria-hidden="true" tabindex="-1"></a>d_don_1k_best_params <span class="ot">&lt;-</span> <span class="fu">best_wflow_preds_vi</span>(d_don_1k_results,</span>
<span id="cb93-838"><a href="#cb93-838" aria-hidden="true" tabindex="-1"></a>  <span class="at">outcome_var =</span> <span class="st">"d_don_1k"</span>,</span>
<span id="cb93-839"><a href="#cb93-839" aria-hidden="true" tabindex="-1"></a>  <span class="at">classification =</span> <span class="cn">TRUE</span>, </span>
<span id="cb93-840"><a href="#cb93-840" aria-hidden="true" tabindex="-1"></a>  <span class="at">metric =</span> <span class="st">"roc_auc"</span>)</span>
<span id="cb93-841"><a href="#cb93-841" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-842"><a href="#cb93-842" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-843"><a href="#cb93-843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-844"><a href="#cb93-844" aria-hidden="true" tabindex="-1"></a>The 'vi', a measure of 'variable importance', may be an object of particular interest:</span>
<span id="cb93-845"><a href="#cb93-845" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-848"><a href="#cb93-848" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-849"><a href="#cb93-849" aria-hidden="true" tabindex="-1"></a>d_don_1k_best_params<span class="sc">$</span>vi</span>
<span id="cb93-850"><a href="#cb93-850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-851"><a href="#cb93-851" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-852"><a href="#cb93-852" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-853"><a href="#cb93-853" aria-hidden="true" tabindex="-1"></a>For the random forest model we can't give a 'sign' because each variable enters in a complicated way ... at lower nodes across multiple averaged trees.</span>
<span id="cb93-854"><a href="#cb93-854" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-855"><a href="#cb93-855" aria-hidden="true" tabindex="-1"></a><span class="fu">## Metrics of fit (performance)</span></span>
<span id="cb93-856"><a href="#cb93-856" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-857"><a href="#cb93-857" aria-hidden="true" tabindex="-1"></a>We want to know how good our models are predicting the training data (the data that was not used to fit these models).  We may want to consider 'how successful' our predictive models are at making practically useful predictions. In other words, 'how far off' are the predictions and classifications on average, from the actual outcomes. This procedure considers the fit on randomly-drawn *set-aside* 'testing data', data that has not been used in 'training' (or 'fitting') the model. Below, we consider some commonly-used metrics.</span>
<span id="cb93-858"><a href="#cb93-858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-859"><a href="#cb93-859" aria-hidden="true" tabindex="-1"></a>For the continuous outcomes we consider the 'regression metrics', and define these in a list below.</span>
<span id="cb93-860"><a href="#cb93-860" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-861"><a href="#cb93-861" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>root mean-squared error and</span>
<span id="cb93-862"><a href="#cb93-862" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>mean absolute error</span>
<span id="cb93-863"><a href="#cb93-863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-864"><a href="#cb93-864" aria-hidden="true" tabindex="-1"></a><span class="in">```{r regress_metrics}</span></span>
<span id="cb93-865"><a href="#cb93-865" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb93-866"><a href="#cb93-866" aria-hidden="true" tabindex="-1"></a>regress_metrics <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">rmse =</span> yardstick<span class="sc">::</span>rmse_vec,</span>
<span id="cb93-867"><a href="#cb93-867" aria-hidden="true" tabindex="-1"></a>                        <span class="at">mae =</span> yardstick<span class="sc">::</span>mae_vec)</span>
<span id="cb93-868"><a href="#cb93-868" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-869"><a href="#cb93-869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-870"><a href="#cb93-870" aria-hidden="true" tabindex="-1"></a>For the binary (or categorical outcomes we consider a range of 'classification metrics^<span class="co">[</span><span class="ot">I discuss these issues at length [here](https://rethinkpriorities.github.io/methodology-statistics-design/chapters/classification_model_notes.html). However this is a fairly mainstream topic, and thereare a range of other, more precise or more intuitive discussions throughout the web.</span><span class="co">]</span></span>
<span id="cb93-871"><a href="#cb93-871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-872"><a href="#cb93-872" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Accuracy: 'the proportion predicted correctly'</span>
<span id="cb93-873"><a href="#cb93-873" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Recall: The share of positive (or 'relevant') results that were predicted to be positive. (aka sensitivity ^<span class="co">[</span><span class="ot">1 - the rate of false negative</span><span class="co">]</span></span>
<span id="cb93-874"><a href="#cb93-874" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Precision: Share of positive predictions that are truly positive^<span class="co">[</span><span class="ot">1- rate of false positive</span><span class="co">]</span></span>
<span id="cb93-875"><a href="#cb93-875" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>F1 score: A weighted (default: harmonic mean) of precision and recall</span>
<span id="cb93-876"><a href="#cb93-876" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-879"><a href="#cb93-879" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-880"><a href="#cb93-880" aria-hidden="true" tabindex="-1"></a>class_metrics <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">accuracy =</span> yardstick<span class="sc">::</span>accuracy_vec,</span>
<span id="cb93-881"><a href="#cb93-881" aria-hidden="true" tabindex="-1"></a>                      <span class="at">recall =</span> yardstick<span class="sc">::</span>recall_vec,</span>
<span id="cb93-882"><a href="#cb93-882" aria-hidden="true" tabindex="-1"></a>                      <span class="at">precision =</span> yardstick<span class="sc">::</span>precision_vec,</span>
<span id="cb93-883"><a href="#cb93-883" aria-hidden="true" tabindex="-1"></a>                      <span class="at">f1_score =</span> f_meas_vec)</span>
<span id="cb93-884"><a href="#cb93-884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-885"><a href="#cb93-885" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-886"><a href="#cb93-886" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-887"><a href="#cb93-887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-888"><a href="#cb93-888" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-889"><a href="#cb93-889" aria-hidden="true" tabindex="-1"></a>First we define a little helper function to help calculate the performance metrics.</span>
<span id="cb93-890"><a href="#cb93-890" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-891"><a href="#cb93-891" aria-hidden="true" tabindex="-1"></a><span class="in">```{r calculate_metrics}</span></span>
<span id="cb93-892"><a href="#cb93-892" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-893"><a href="#cb93-893" aria-hidden="true" tabindex="-1"></a>calculate_metrics <span class="ot">&lt;-</span> <span class="cf">function</span>(df, metrics, <span class="at">preds =</span> preds, <span class="at">true_y =</span> true_y){</span>
<span id="cb93-894"><a href="#cb93-894" aria-hidden="true" tabindex="-1"></a>  df <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(purrr<span class="sc">::</span><span class="fu">map2_dfr</span>({{true_y}}, {{preds}}, </span>
<span id="cb93-895"><a href="#cb93-895" aria-hidden="true" tabindex="-1"></a>    <span class="sc">~</span> purrr<span class="sc">::</span><span class="fu">map_dfc</span>(</span>
<span id="cb93-896"><a href="#cb93-896" aria-hidden="true" tabindex="-1"></a>      metrics,</span>
<span id="cb93-897"><a href="#cb93-897" aria-hidden="true" tabindex="-1"></a>      do.call,</span>
<span id="cb93-898"><a href="#cb93-898" aria-hidden="true" tabindex="-1"></a>      <span class="fu">list</span>(.x, .y))))</span>
<span id="cb93-899"><a href="#cb93-899" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb93-900"><a href="#cb93-900" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-901"><a href="#cb93-901" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-902"><a href="#cb93-902" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-903"><a href="#cb93-903" aria-hidden="true" tabindex="-1"></a>Next, we apply it to the fit models tied to the training data: </span>
<span id="cb93-904"><a href="#cb93-904" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-907"><a href="#cb93-907" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-908"><a href="#cb93-908" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_best_params_filter <span class="ot">&lt;-</span> l_don_av_2yr_best_params_filter <span class="sc">%&gt;%</span> </span>
<span id="cb93-909"><a href="#cb93-909" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">c</span>(preds, true_y), <span class="sc">~</span><span class="fu">map</span>(.x, exp))) <span class="sc">%&gt;%</span></span>
<span id="cb93-910"><a href="#cb93-910" aria-hidden="true" tabindex="-1"></a>  <span class="fu">calculate_metrics</span>(regress_metrics)</span>
<span id="cb93-911"><a href="#cb93-911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-912"><a href="#cb93-912" aria-hidden="true" tabindex="-1"></a>d_don_1k_best_params <span class="ot">&lt;-</span> <span class="fu">calculate_metrics</span>(d_don_1k_best_params, class_metrics)</span>
<span id="cb93-913"><a href="#cb93-913" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-914"><a href="#cb93-914" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-915"><a href="#cb93-915" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-916"><a href="#cb93-916" aria-hidden="true" tabindex="-1"></a>Note that for the continuous outcomes, we first converted from logs to levels before calculating RMSE and MAE</span>
<span id="cb93-917"><a href="#cb93-917" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-918"><a href="#cb93-918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-919"><a href="#cb93-919" aria-hidden="true" tabindex="-1"></a>Some tidying up and renaming below.</span>
<span id="cb93-922"><a href="#cb93-922" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-923"><a href="#cb93-923" aria-hidden="true" tabindex="-1"></a><span class="co"># Change model names</span></span>
<span id="cb93-924"><a href="#cb93-924" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-925"><a href="#cb93-925" aria-hidden="true" tabindex="-1"></a>d_don_1k_best_params <span class="ot">&lt;-</span> <span class="fu">rename_models</span>(d_don_1k_best_params)</span>
<span id="cb93-926"><a href="#cb93-926" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_best_params_filter <span class="ot">&lt;-</span> <span class="fu">rename_models</span>(l_don_av_2yr_best_params_filter)</span>
<span id="cb93-927"><a href="#cb93-927" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-928"><a href="#cb93-928" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-929"><a href="#cb93-929" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-930"><a href="#cb93-930" aria-hidden="true" tabindex="-1"></a><span class="in">```{r tidyparams}</span></span>
<span id="cb93-931"><a href="#cb93-931" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-932"><a href="#cb93-932" aria-hidden="true" tabindex="-1"></a>recode_params <span class="ot">&lt;-</span> <span class="cf">function</span>(df){</span>
<span id="cb93-933"><a href="#cb93-933" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Shortcut function to tidy up variable names in parameter df</span></span>
<span id="cb93-934"><a href="#cb93-934" aria-hidden="true" tabindex="-1"></a>    df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(model, vi) <span class="sc">%&gt;%</span></span>
<span id="cb93-935"><a href="#cb93-935" aria-hidden="true" tabindex="-1"></a>    tidyr<span class="sc">::</span><span class="fu">unnest</span>(vi) <span class="sc">%&gt;%</span></span>
<span id="cb93-936"><a href="#cb93-936" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">model =</span> <span class="fu">str_replace_all</span>(model,</span>
<span id="cb93-937"><a href="#cb93-937" aria-hidden="true" tabindex="-1"></a>                                   <span class="fu">c</span>(<span class="st">"preprocess_"</span> <span class="ot">=</span> <span class="st">""</span>, <span class="st">"_"</span>  <span class="ot">=</span> <span class="st">" "</span>)),</span>
<span id="cb93-938"><a href="#cb93-938" aria-hidden="true" tabindex="-1"></a>           <span class="co">#Variable =  str_replace_all(Variable, key_eas_all_labels),</span></span>
<span id="cb93-939"><a href="#cb93-939" aria-hidden="true" tabindex="-1"></a>           <span class="at">Variable =</span>  <span class="fu">str_replace_all</span>(Variable,</span>
<span id="cb93-940"><a href="#cb93-940" aria-hidden="true" tabindex="-1"></a>                                       <span class="fu">c</span>(<span class="st">"_"</span>  <span class="ot">=</span> <span class="st">" "</span>, <span class="st">"_Student"</span> <span class="ot">=</span><span class="st">""</span>, <span class="st">"ln"</span> <span class="ot">=</span> <span class="st">"log"</span>)),</span>
<span id="cb93-941"><a href="#cb93-941" aria-hidden="true" tabindex="-1"></a>           <span class="at">Sign =</span> <span class="fu">if_else</span>(<span class="fu">is.na</span>(Sign), <span class="st">"NA"</span>, Sign))</span>
<span id="cb93-942"><a href="#cb93-942" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb93-943"><a href="#cb93-943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-944"><a href="#cb93-944" aria-hidden="true" tabindex="-1"></a><span class="co"># Tidy up parameters</span></span>
<span id="cb93-945"><a href="#cb93-945" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_best_params_recode_filter <span class="ot">&lt;-</span> l_don_av_2yr_best_params_filter <span class="sc">%&gt;%</span> </span>
<span id="cb93-946"><a href="#cb93-946" aria-hidden="true" tabindex="-1"></a>  <span class="co">#filter(is.na(filter_name)) %&gt;%</span></span>
<span id="cb93-947"><a href="#cb93-947" aria-hidden="true" tabindex="-1"></a>  recode_params</span>
<span id="cb93-948"><a href="#cb93-948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-949"><a href="#cb93-949" aria-hidden="true" tabindex="-1"></a>d_don_1k_best_params_recode <span class="ot">&lt;-</span> d_don_1k_best_params <span class="sc">%&gt;%</span> recode_params</span>
<span id="cb93-950"><a href="#cb93-950" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-951"><a href="#cb93-951" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-952"><a href="#cb93-952" aria-hidden="true" tabindex="-1"></a><span class="fu">####  Regression Model Pertformance: RMSE and MAE {.unnumbered}</span></span>
<span id="cb93-953"><a href="#cb93-953" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-954"><a href="#cb93-954" aria-hidden="true" tabindex="-1"></a>In order to assess the usefulness of each predictive regression model we consider both root-mean-square-error (RMSE) and mean-absolute-error (MAE). </span>
<span id="cb93-955"><a href="#cb93-955" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-956"><a href="#cb93-956" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb93-957"><a href="#cb93-957" aria-hidden="true" tabindex="-1"></a><span class="fu">## Interpretation and construction of RMSE</span></span>
<span id="cb93-958"><a href="#cb93-958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-959"><a href="#cb93-959" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-960"><a href="#cb93-960" aria-hidden="true" tabindex="-1"></a>RMSE (aka <span class="co">[</span><span class="ot">RMSD</span><span class="co">](https://en.wikipedia.org/wiki/Root-mean-square_deviation)</span>) can be interpreted as the average 'Euclidean distance' between the actual values and the model's prediction. For each observation (in the set-aside 'testing sample'), to construct RMSE we:</span>
<span id="cb93-961"><a href="#cb93-961" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-962"><a href="#cb93-962" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>Measure the differences between the actual and predicted outcome (e.g., donation)</span>
<span id="cb93-963"><a href="#cb93-963" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>Square these differences</span>
<span id="cb93-964"><a href="#cb93-964" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>Take the average of these squared differences across all observations</span>
<span id="cb93-965"><a href="#cb93-965" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>Take the square root of this</span>
<span id="cb93-966"><a href="#cb93-966" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-967"><a href="#cb93-967" aria-hidden="true" tabindex="-1"></a>::: </span>
<span id="cb93-968"><a href="#cb93-968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-969"><a href="#cb93-969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-970"><a href="#cb93-970" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb93-971"><a href="#cb93-971" aria-hidden="true" tabindex="-1"></a><span class="fu">## Interpretation and construction of mean-absolute-error (MAE)</span></span>
<span id="cb93-972"><a href="#cb93-972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-973"><a href="#cb93-973" aria-hidden="true" tabindex="-1"></a>To construct mean-absolute-error (MAE) we simply</span>
<span id="cb93-974"><a href="#cb93-974" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-975"><a href="#cb93-975" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>Measure the *absolute-value* differences between the actual and predicted outcome (e.g., donation) for each observation</span>
<span id="cb93-976"><a href="#cb93-976" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>Take the average of these across all observations</span>
<span id="cb93-977"><a href="#cb93-977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-978"><a href="#cb93-978" aria-hidden="true" tabindex="-1"></a>MAE has a much more straightforward interpretation: it simply asks 'how far off are we, on average?'</span>
<span id="cb93-979"><a href="#cb93-979" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-980"><a href="#cb93-980" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb93-981"><a href="#cb93-981" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-982"><a href="#cb93-982" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-983"><a href="#cb93-983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-984"><a href="#cb93-984" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb93-985"><a href="#cb93-985" aria-hidden="true" tabindex="-1"></a><span class="fu">## RMSE vs MAE</span></span>
<span id="cb93-986"><a href="#cb93-986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-987"><a href="#cb93-987" aria-hidden="true" tabindex="-1"></a>While the RMSE is used in the model *fitting* for various reasons, it is arguably less-interpretable and less-relevant than MAE in *judging* the model's fit in cases like this one. RMSE error negatively assesses the model fit based on *squared* deviations, and is thus very sensitive to 'large mistakes'. This may be relevant where 'large errors are much much worse than small ones' -- here, this is not so clearly the case. In the presence of data with large outlying observations, prediction will tend to be poor by this measure.</span>
<span id="cb93-988"><a href="#cb93-988" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-989"><a href="#cb93-989" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb93-990"><a href="#cb93-990" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-991"><a href="#cb93-991" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-992"><a href="#cb93-992" aria-hidden="true" tabindex="-1"></a>**Transformations:** Note that when considering models where the outcome is transformed (e.g., log(donations)) we construct the RMSE and MAE by exponentiating to generate predictions for the *level* outcomes, and then measure the deviations on the level scale.^[ When considering predicted outcomes on the *logarithmic* scale, both RMSE and MAE indicate roughly 'how many exponential orders of magnitude our predictions for the *non-logged outcomes* are off. E.g., a MSE of 1.5 for 'log donation' suggests an we are off by about $exp(1.5) =$ <span class="in">`r op(exp(1.5))`</span> times in terms of donations, getting them off by a factor of about 5. This conversion avoid such complications.</span>
<span id="cb93-993"><a href="#cb93-993" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb93-994"><a href="#cb93-994" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-995"><a href="#cb93-995" aria-hidden="true" tabindex="-1"></a><span class="fu">### Our regression models' performance</span></span>
<span id="cb93-996"><a href="#cb93-996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-997"><a href="#cb93-997" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-998"><a href="#cb93-998" aria-hidden="true" tabindex="-1"></a>^<span class="co">[</span><span class="ot">Code note: I am using a purrrr:map below but I think it is pointless because it is a 'list of 1' ... I previously had also included the donation share models </span><span class="co">]</span></span>
<span id="cb93-999"><a href="#cb93-999" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1000"><a href="#cb93-1000" aria-hidden="true" tabindex="-1"></a><span class="in">```{r regression-model-performance}</span></span>
<span id="cb93-1001"><a href="#cb93-1001" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1002"><a href="#cb93-1002" aria-hidden="true" tabindex="-1"></a>l_don_av_2yr_best_params_filter <span class="ot">&lt;-</span> l_don_av_2yr_best_params_filter <span class="sc">%&gt;%</span></span>
<span id="cb93-1003"><a href="#cb93-1003" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">dv =</span> <span class="st">"Donation amount*"</span>)</span>
<span id="cb93-1004"><a href="#cb93-1004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1005"><a href="#cb93-1005" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1006"><a href="#cb93-1006" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb93-1007"><a href="#cb93-1007" aria-hidden="true" tabindex="-1"></a>  reg_model_performance <span class="ot">&lt;-</span> purrr<span class="sc">::</span><span class="fu">map</span>(<span class="fu">list</span>(l_don_av_2yr_best_params_filter), <span class="sc">~</span>.x <span class="sc">%&gt;%</span></span>
<span id="cb93-1008"><a href="#cb93-1008" aria-hidden="true" tabindex="-1"></a>      dplyr<span class="sc">::</span><span class="fu">select</span>(dv, rmse, mae, model)</span>
<span id="cb93-1009"><a href="#cb93-1009" aria-hidden="true" tabindex="-1"></a>      ) <span class="sc">%&gt;%</span></span>
<span id="cb93-1010"><a href="#cb93-1010" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>() <span class="sc">%&gt;%</span></span>
<span id="cb93-1011"><a href="#cb93-1011" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="st">"Dependent variable"</span> <span class="ot">=</span> dv,</span>
<span id="cb93-1012"><a href="#cb93-1012" aria-hidden="true" tabindex="-1"></a>         <span class="st">"RMSE"</span> <span class="ot">=</span> rmse,</span>
<span id="cb93-1013"><a href="#cb93-1013" aria-hidden="true" tabindex="-1"></a>         <span class="st">"MAE aka MAD"</span> <span class="ot">=</span> mae,</span>
<span id="cb93-1014"><a href="#cb93-1014" aria-hidden="true" tabindex="-1"></a>         <span class="st">"Model"</span> <span class="ot">=</span> model) <span class="sc">%&gt;%</span></span>
<span id="cb93-1015"><a href="#cb93-1015" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">caption =</span> <span class="st">"Regression model performance"</span>,</span>
<span id="cb93-1016"><a href="#cb93-1016" aria-hidden="true" tabindex="-1"></a>        <span class="at">digits =</span> <span class="dv">2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb93-1017"><a href="#cb93-1017" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>() <span class="sc">%&gt;%</span></span>
<span id="cb93-1018"><a href="#cb93-1018" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_footnote</span>(<span class="st">"Note: While the model was trained using logs of the dependent variable, RMSE and MAD/MAE were calculated in levels"</span>, <span class="at">notation =</span> <span class="st">"symbol"</span>)</span>
<span id="cb93-1019"><a href="#cb93-1019" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb93-1020"><a href="#cb93-1020" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1021"><a href="#cb93-1021" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1022"><a href="#cb93-1022" aria-hidden="true" tabindex="-1"></a><span class="fu">p_load</span>(ie2misc)</span>
<span id="cb93-1023"><a href="#cb93-1023" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1024"><a href="#cb93-1024" aria-hidden="true" tabindex="-1"></a>mad_naive <span class="ot">&lt;-</span> ie2misc<span class="sc">::</span><span class="fu">madstat</span>(df<span class="sc">$</span>donation_usd, <span class="at">na.rm=</span><span class="cn">TRUE</span>)</span>
<span id="cb93-1025"><a href="#cb93-1025" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1026"><a href="#cb93-1026" aria-hidden="true" tabindex="-1"></a>sd_naive <span class="ot">&lt;-</span> <span class="fu">round</span>((<span class="fu">sd</span>(df<span class="sc">$</span>donation_usd, <span class="at">na.rm=</span><span class="cn">TRUE</span>)), <span class="dv">0</span>)</span>
<span id="cb93-1027"><a href="#cb93-1027" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1028"><a href="#cb93-1028" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-1029"><a href="#cb93-1029" aria-hidden="true" tabindex="-1"></a>How does this compare to a 'naive model' in which we predict the average donation for everyone? Note that for the comparable unfiltered data, the mean absolute deviation is <span class="in">`r mad_naive`</span> and the standard deviation^<span class="co">[</span><span class="ot">I.e., the 'standard error' of a model that predicts the mean every time</span><span class="co">]</span> is <span class="in">`r sd_naive`</span>. The predictive model reduces this uncertainty substantially.</span>
<span id="cb93-1030"><a href="#cb93-1030" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1031"><a href="#cb93-1031" aria-hidden="true" tabindex="-1"></a><span class="fu">### Our classification models'  performance</span></span>
<span id="cb93-1032"><a href="#cb93-1032" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1033"><a href="#cb93-1033" aria-hidden="true" tabindex="-1"></a>There are a variety of metrics for the performance of a classifications model; I discuss the basic concepts of precision, recall, and the ROC curve <span class="co">[</span><span class="ot">here</span><span class="co">](https://rethinkpriorities.github.io/methodology-statistics-design/chapters/classification_model_notes.html)</span>. The 'performance of a classifier' is not easy to reduce to a single number; it depends on how you are going to use it, and on the relative the costs and benefits of each type of classifications error  </span>
<span id="cb93-1034"><a href="#cb93-1034" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1035"><a href="#cb93-1035" aria-hidden="true" tabindex="-1"></a>The ROC curve allows us to compare the predictive power of the various models, and to compare it to an uninformed classifier^<span class="co">[</span><span class="ot">which would simply predict a positive outcome with some random probability $p$; thus this maps out the 45 degree line.</span><span class="co">]</span></span>
<span id="cb93-1036"><a href="#cb93-1036" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1037"><a href="#cb93-1037" aria-hidden="true" tabindex="-1"></a><span class="in">```{r roc-curves}</span></span>
<span id="cb93-1038"><a href="#cb93-1038" aria-hidden="true" tabindex="-1"></a><span class="co"># Add column for ROC curve</span></span>
<span id="cb93-1039"><a href="#cb93-1039" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1040"><a href="#cb93-1040" aria-hidden="true" tabindex="-1"></a>roc_curve <span class="ot">&lt;-</span> yardstick<span class="sc">::</span>roc_curve</span>
<span id="cb93-1041"><a href="#cb93-1041" aria-hidden="true" tabindex="-1"></a>unnest <span class="ot">&lt;-</span> tidyr<span class="sc">::</span>unnest</span>
<span id="cb93-1042"><a href="#cb93-1042" aria-hidden="true" tabindex="-1"></a>pr_curve <span class="ot">&lt;-</span> yardstick<span class="sc">::</span>pr_curve</span>
<span id="cb93-1043"><a href="#cb93-1043" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1044"><a href="#cb93-1044" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate ROC curve</span></span>
<span id="cb93-1045"><a href="#cb93-1045" aria-hidden="true" tabindex="-1"></a>d_don_1k_best_params<span class="sc">$</span>roc_curve <span class="ot">&lt;-</span> d_don_1k_best_params <span class="sc">%&gt;%</span> <span class="fu">select</span>(true_y, preds, pred_prob, model) <span class="sc">%&gt;%</span></span>
<span id="cb93-1046"><a href="#cb93-1046" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(<span class="at">cols =</span> <span class="fu">everything</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb93-1047"><a href="#cb93-1047" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(model) <span class="sc">%&gt;%</span></span>
<span id="cb93-1048"><a href="#cb93-1048" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_map</span>(<span class="sc">~</span> <span class="fu">roc_curve</span>(., true_y, .pred_FALSE))</span>
<span id="cb93-1049"><a href="#cb93-1049" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1050"><a href="#cb93-1050" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate AUC</span></span>
<span id="cb93-1051"><a href="#cb93-1051" aria-hidden="true" tabindex="-1"></a>d_don_1k_best_params<span class="sc">$</span>auc <span class="ot">&lt;-</span> d_don_1k_best_params <span class="sc">%&gt;%</span> <span class="fu">select</span>(true_y, preds, pred_prob, model) <span class="sc">%&gt;%</span></span>
<span id="cb93-1052"><a href="#cb93-1052" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(<span class="at">cols =</span> <span class="fu">everything</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb93-1053"><a href="#cb93-1053" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(model) <span class="sc">%&gt;%</span></span>
<span id="cb93-1054"><a href="#cb93-1054" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_map</span>(<span class="sc">~</span> yardstick<span class="sc">::</span><span class="fu">roc_auc</span>(., <span class="at">truth =</span> true_y, <span class="at">estimate =</span> .pred_FALSE))</span>
<span id="cb93-1055"><a href="#cb93-1055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1056"><a href="#cb93-1056" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract AUC</span></span>
<span id="cb93-1057"><a href="#cb93-1057" aria-hidden="true" tabindex="-1"></a>d_don_1k_best_params <span class="ot">&lt;-</span> d_don_1k_best_params <span class="sc">%&gt;%</span></span>
<span id="cb93-1058"><a href="#cb93-1058" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest_wider</span>(., <span class="at">col =</span> auc) <span class="sc">%&gt;%</span></span>
<span id="cb93-1059"><a href="#cb93-1059" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span><span class="fu">c</span>(.metric, .estimator)) <span class="sc">%&gt;%</span></span>
<span id="cb93-1060"><a href="#cb93-1060" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">auc =</span> .estimate)</span>
<span id="cb93-1061"><a href="#cb93-1061" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1062"><a href="#cb93-1062" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot ROC curve</span></span>
<span id="cb93-1063"><a href="#cb93-1063" aria-hidden="true" tabindex="-1"></a>(roc_curve_d_don_1k <span class="ot">&lt;-</span> d_don_1k_best_params <span class="sc">%&gt;%</span> <span class="fu">select</span>(roc_curve, model) <span class="sc">%&gt;%</span></span>
<span id="cb93-1064"><a href="#cb93-1064" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(<span class="at">cols =</span> <span class="fu">everything</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb93-1065"><a href="#cb93-1065" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename_with</span>(snakecase<span class="sc">::</span>to_title_case) <span class="sc">%&gt;%</span></span>
<span id="cb93-1066"><a href="#cb93-1066" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="dv">1</span><span class="sc">-</span>Specificity, <span class="at">y =</span> Sensitivity, <span class="at">colour =</span> Model)) <span class="sc">+</span></span>
<span id="cb93-1067"><a href="#cb93-1067" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb93-1068"><a href="#cb93-1068" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope=</span><span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>) <span class="sc">+</span></span>
<span id="cb93-1069"><a href="#cb93-1069" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb93-1070"><a href="#cb93-1070" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb93-1071"><a href="#cb93-1071" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-1072"><a href="#cb93-1072" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1073"><a href="#cb93-1073" aria-hidden="true" tabindex="-1"></a>An ROC curve plots the true positive rate (sensitivity) as a function of the false positive rate (1-specificity). Here the true positive rate gives the rate at which our model correctly predicts a respondent to donate over \$1000, with the false positive rate giving the rate at which these predictions are incorrect.    </span>
<span id="cb93-1074"><a href="#cb93-1074" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1075"><a href="#cb93-1075" aria-hidden="true" tabindex="-1"></a>Better classifiers will have an ROC curve that is further North-West, with the perfect classifier being an L-shaped curve passing through $(0,0) \rightarrow(0,1) \rightarrow(1,1)$. Where classifiers ROC curves do not cross, it is clear that one will be performing better than another. That is not the case here. Both models seem to be performing relatively similarly, with the ROC curves overlapping somewhat. It is difficult to discern which model is performing the best, and this will depend on our criterion.</span>
<span id="cb93-1076"><a href="#cb93-1076" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1077"><a href="#cb93-1077" aria-hidden="true" tabindex="-1"></a>However, both models yield curves substantially above the 45 degree line, thus substantially outperforming an uninformed classifier. For example, if we are willing to accept about a 25% rate of false positives (falsely predicting a 1k+ donation), the logistic regression model correctly predicts about 75% of true positives (and the random forest model about 73%).</span>
<span id="cb93-1078"><a href="#cb93-1078" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1079"><a href="#cb93-1079" aria-hidden="true" tabindex="-1"></a>We can use the area under the curve (AUC) measure to compare classifiers for all costs of misclassification. This is one measure of 'how close the ROC curve is to the optimal L-shaped curve.'</span>
<span id="cb93-1080"><a href="#cb93-1080" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1081"><a href="#cb93-1081" aria-hidden="true" tabindex="-1"></a>^<span class="co">[</span><span class="ot">Note: the code below is a bit messy; we can probably do better or use some existing package.</span><span class="co">]</span></span>
<span id="cb93-1082"><a href="#cb93-1082" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1083"><a href="#cb93-1083" aria-hidden="true" tabindex="-1"></a><span class="in">```{r auc-values}</span></span>
<span id="cb93-1084"><a href="#cb93-1084" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1085"><a href="#cb93-1085" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1086"><a href="#cb93-1086" aria-hidden="true" tabindex="-1"></a>calculate_metrics <span class="ot">&lt;-</span></span>
<span id="cb93-1087"><a href="#cb93-1087" aria-hidden="true" tabindex="-1"></a>  <span class="cf">function</span>(df,</span>
<span id="cb93-1088"><a href="#cb93-1088" aria-hidden="true" tabindex="-1"></a>    metrics,</span>
<span id="cb93-1089"><a href="#cb93-1089" aria-hidden="true" tabindex="-1"></a>    <span class="at">preds =</span> preds,</span>
<span id="cb93-1090"><a href="#cb93-1090" aria-hidden="true" tabindex="-1"></a>    <span class="at">true_y =</span> true_y) {</span>
<span id="cb93-1091"><a href="#cb93-1091" aria-hidden="true" tabindex="-1"></a>    df <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(purrr<span class="sc">::</span><span class="fu">map2_dfr</span>({</span>
<span id="cb93-1092"><a href="#cb93-1092" aria-hidden="true" tabindex="-1"></a>      {</span>
<span id="cb93-1093"><a href="#cb93-1093" aria-hidden="true" tabindex="-1"></a>        true_y</span>
<span id="cb93-1094"><a href="#cb93-1094" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb93-1095"><a href="#cb93-1095" aria-hidden="true" tabindex="-1"></a>    }, {</span>
<span id="cb93-1096"><a href="#cb93-1096" aria-hidden="true" tabindex="-1"></a>      {</span>
<span id="cb93-1097"><a href="#cb93-1097" aria-hidden="true" tabindex="-1"></a>        preds</span>
<span id="cb93-1098"><a href="#cb93-1098" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb93-1099"><a href="#cb93-1099" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb93-1100"><a href="#cb93-1100" aria-hidden="true" tabindex="-1"></a>      <span class="sc">~</span> purrr<span class="sc">::</span><span class="fu">map_dfc</span>(metrics,</span>
<span id="cb93-1101"><a href="#cb93-1101" aria-hidden="true" tabindex="-1"></a>        do.call,</span>
<span id="cb93-1102"><a href="#cb93-1102" aria-hidden="true" tabindex="-1"></a>        <span class="fu">list</span>(.x, .y))))</span>
<span id="cb93-1103"><a href="#cb93-1103" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb93-1104"><a href="#cb93-1104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1105"><a href="#cb93-1105" aria-hidden="true" tabindex="-1"></a>class_metrics <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">accuracy =</span> yardstick<span class="sc">::</span>accuracy_vec,</span>
<span id="cb93-1106"><a href="#cb93-1106" aria-hidden="true" tabindex="-1"></a>                      <span class="at">recall =</span> yardstick<span class="sc">::</span>recall_vec,</span>
<span id="cb93-1107"><a href="#cb93-1107" aria-hidden="true" tabindex="-1"></a>                      <span class="at">precision =</span> yardstick<span class="sc">::</span>precision_vec,</span>
<span id="cb93-1108"><a href="#cb93-1108" aria-hidden="true" tabindex="-1"></a>                      <span class="at">f1_score =</span> yardstick<span class="sc">::</span>f_meas_vec)</span>
<span id="cb93-1109"><a href="#cb93-1109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1110"><a href="#cb93-1110" aria-hidden="true" tabindex="-1"></a><span class="co"># Adding a no skill classifier to d_don_1k</span></span>
<span id="cb93-1111"><a href="#cb93-1111" aria-hidden="true" tabindex="-1"></a><span class="do">## Messy code</span></span>
<span id="cb93-1112"><a href="#cb93-1112" aria-hidden="true" tabindex="-1"></a>truth <span class="ot">&lt;-</span> d_don_1k_best_params<span class="sc">$</span>true_y[[<span class="dv">1</span>]]</span>
<span id="cb93-1113"><a href="#cb93-1113" aria-hidden="true" tabindex="-1"></a>majority <span class="ot">&lt;-</span> <span class="fu">tail</span>(<span class="fu">names</span>(<span class="fu">sort</span>(<span class="fu">table</span>(truth))), <span class="dv">1</span>)</span>
<span id="cb93-1114"><a href="#cb93-1114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1115"><a href="#cb93-1115" aria-hidden="true" tabindex="-1"></a>pred_majority <span class="ot">&lt;-</span> <span class="fu">as.logical</span>(<span class="fu">rep</span>(majority, <span class="fu">length</span>(truth)))</span>
<span id="cb93-1116"><a href="#cb93-1116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1117"><a href="#cb93-1117" aria-hidden="true" tabindex="-1"></a>.pred_FALSE <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> pred_majority</span>
<span id="cb93-1118"><a href="#cb93-1118" aria-hidden="true" tabindex="-1"></a>.pred_TRUE <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> .pred_FALSE</span>
<span id="cb93-1119"><a href="#cb93-1119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1120"><a href="#cb93-1120" aria-hidden="true" tabindex="-1"></a>pred_prob <span class="ot">&lt;-</span> <span class="fu">tibble</span>(.pred_FALSE, .pred_TRUE, truth)</span>
<span id="cb93-1121"><a href="#cb93-1121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1122"><a href="#cb93-1122" aria-hidden="true" tabindex="-1"></a>no_skill <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">model =</span> <span class="st">"No Skill"</span>,</span>
<span id="cb93-1123"><a href="#cb93-1123" aria-hidden="true" tabindex="-1"></a>                   <span class="at">true_y =</span> <span class="fu">list</span>(truth),</span>
<span id="cb93-1124"><a href="#cb93-1124" aria-hidden="true" tabindex="-1"></a>                   <span class="at">pred_prob =</span> <span class="fu">list</span>(pred_prob),</span>
<span id="cb93-1125"><a href="#cb93-1125" aria-hidden="true" tabindex="-1"></a>                   <span class="at">preds =</span> <span class="fu">list</span>(<span class="fu">factor</span>(pred_majority, <span class="at">levels =</span> <span class="fu">levels</span>(truth)))) <span class="sc">%&gt;%</span></span>
<span id="cb93-1126"><a href="#cb93-1126" aria-hidden="true" tabindex="-1"></a>  <span class="fu">calculate_metrics</span>(class_metrics)</span>
<span id="cb93-1127"><a href="#cb93-1127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1128"><a href="#cb93-1128" aria-hidden="true" tabindex="-1"></a>no_skill<span class="sc">$</span>auc <span class="ot">&lt;-</span> yardstick<span class="sc">::</span><span class="fu">roc_auc_vec</span>(truth, .pred_TRUE)</span>
<span id="cb93-1129"><a href="#cb93-1129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1130"><a href="#cb93-1130" aria-hidden="true" tabindex="-1"></a>purrr<span class="sc">::</span><span class="fu">map_df</span>(<span class="fu">list</span>(no_skill, d_don_1k_best_params), <span class="sc">~</span>.x <span class="sc">%&gt;%</span></span>
<span id="cb93-1131"><a href="#cb93-1131" aria-hidden="true" tabindex="-1"></a>             <span class="fu">select</span>(model, auc, accuracy)) <span class="sc">%&gt;%</span></span>
<span id="cb93-1132"><a href="#cb93-1132" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename_with</span>(snakecase<span class="sc">::</span>to_title_case) <span class="sc">%&gt;%</span></span>
<span id="cb93-1133"><a href="#cb93-1133" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">AUC =</span> Auc) <span class="sc">%&gt;%</span></span>
<span id="cb93-1134"><a href="#cb93-1134" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">3</span>) <span class="sc">%&gt;%</span></span>
<span id="cb93-1135"><a href="#cb93-1135" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>()</span>
<span id="cb93-1136"><a href="#cb93-1136" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-1137"><a href="#cb93-1137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1138"><a href="#cb93-1138" aria-hidden="true" tabindex="-1"></a>Here the tuned logistic regression performs better in terms of the AUC metric, and both perform much better than the no-skill classifier.</span>
<span id="cb93-1139"><a href="#cb93-1139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1140"><a href="#cb93-1140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1141"><a href="#cb93-1141" aria-hidden="true" tabindex="-1"></a><span class="fu">## Illustrate variable importance</span></span>
<span id="cb93-1142"><a href="#cb93-1142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1143"><a href="#cb93-1143" aria-hidden="true" tabindex="-1"></a>^<span class="co">[</span><span class="ot">Some renaming/recoding and helper functions in the code below:</span><span class="co">]</span></span>
<span id="cb93-1144"><a href="#cb93-1144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1145"><a href="#cb93-1145" aria-hidden="true" tabindex="-1"></a><span class="in">```{r plot_vi}</span></span>
<span id="cb93-1146"><a href="#cb93-1146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1147"><a href="#cb93-1147" aria-hidden="true" tabindex="-1"></a>plot_vi <span class="ot">&lt;-</span> <span class="cf">function</span>(df, <span class="at">shapes =</span> shape_colours){</span>
<span id="cb93-1148"><a href="#cb93-1148" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Shortcut function for plotting normalized variable importance (output of norm_vi)</span></span>
<span id="cb93-1149"><a href="#cb93-1149" aria-hidden="true" tabindex="-1"></a>  df <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">y =</span> Variable, <span class="at">x =</span> Norm, <span class="at">colour =</span> model, <span class="at">shape =</span> Sign)) <span class="sc">+</span></span>
<span id="cb93-1150"><a href="#cb93-1150" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_shape_manual</span>(<span class="at">values =</span> shapes) <span class="sc">+</span></span>
<span id="cb93-1151"><a href="#cb93-1151" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">4</span>, <span class="at">stroke =</span> <span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb93-1152"><a href="#cb93-1152" aria-hidden="true" tabindex="-1"></a>    <span class="fu">xlab</span>(<span class="st">"Normalised feature importance"</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">""</span>)</span>
<span id="cb93-1153"><a href="#cb93-1153" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb93-1154"><a href="#cb93-1154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1155"><a href="#cb93-1155" aria-hidden="true" tabindex="-1"></a><span class="co">#specific changing of variable and signs for the below.</span></span>
<span id="cb93-1156"><a href="#cb93-1156" aria-hidden="true" tabindex="-1"></a>mutate_labels_sign_snip <span class="ot">&lt;-</span> <span class="cf">function</span>(df) {</span>
<span id="cb93-1157"><a href="#cb93-1157" aria-hidden="true" tabindex="-1"></a>  df <span class="sc">%&gt;%</span></span>
<span id="cb93-1158"><a href="#cb93-1158" aria-hidden="true" tabindex="-1"></a>     <span class="fu">mutate</span>(</span>
<span id="cb93-1159"><a href="#cb93-1159" aria-hidden="true" tabindex="-1"></a>  <span class="at">Variable =</span> <span class="fu">str_replace_all</span>(Variable,</span>
<span id="cb93-1160"><a href="#cb93-1160" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(<span class="st">"First-heard EA"</span><span class="ot">=</span><span class="st">"Heard EA:"</span>,</span>
<span id="cb93-1161"><a href="#cb93-1161" aria-hidden="true" tabindex="-1"></a>      <span class="st">"response"</span> <span class="ot">=</span> <span class="st">"resp."</span>,</span>
<span id="cb93-1162"><a href="#cb93-1162" aria-hidden="true" tabindex="-1"></a>      <span class="st">"Gender Gender"</span> <span class="ot">=</span> <span class="st">"Gender"</span>,</span>
<span id="cb93-1163"><a href="#cb93-1163" aria-hidden="true" tabindex="-1"></a>      <span class="st">"unknown"</span> <span class="ot">=</span> <span class="st">"No resp."</span>,</span>
<span id="cb93-1164"><a href="#cb93-1164" aria-hidden="true" tabindex="-1"></a>      <span class="st">"Student Student"</span> <span class="ot">=</span> <span class="st">"Student"</span>,</span>
<span id="cb93-1165"><a href="#cb93-1165" aria-hidden="true" tabindex="-1"></a>      <span class="st">"X80000"</span> <span class="ot">=</span> <span class="st">"80000"</span>)),</span>
<span id="cb93-1166"><a href="#cb93-1166" aria-hidden="true" tabindex="-1"></a>  <span class="at">Sign =</span> <span class="fu">if_else</span>(<span class="fu">is.na</span>(Sign), <span class="st">"NA"</span>, Sign)</span>
<span id="cb93-1167"><a href="#cb93-1167" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb93-1168"><a href="#cb93-1168" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb93-1169"><a href="#cb93-1169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1170"><a href="#cb93-1170" aria-hidden="true" tabindex="-1"></a><span class="co"># Set colors for shapes as a named vector</span></span>
<span id="cb93-1171"><a href="#cb93-1171" aria-hidden="true" tabindex="-1"></a>shape_colours <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"NA"</span> <span class="ot">=</span> <span class="dv">120</span>, <span class="st">"NEG"</span> <span class="ot">=</span> <span class="dv">95</span>, <span class="st">"POS"</span> <span class="ot">=</span> <span class="dv">43</span>)</span>
<span id="cb93-1172"><a href="#cb93-1172" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-1173"><a href="#cb93-1173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1174"><a href="#cb93-1174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1175"><a href="#cb93-1175" aria-hidden="true" tabindex="-1"></a>^<span class="co">[</span><span class="ot">adding content from `modeling_vignettes/based_off_of/donations_20.Rmd`</span><span class="co">]</span></span>
<span id="cb93-1176"><a href="#cb93-1176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1177"><a href="#cb93-1177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1178"><a href="#cb93-1178" aria-hidden="true" tabindex="-1"></a><span class="fu">### Log donation outcome ('regression')</span></span>
<span id="cb93-1179"><a href="#cb93-1179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1180"><a href="#cb93-1180" aria-hidden="true" tabindex="-1"></a>Below, we plot the variable importance. </span>
<span id="cb93-1181"><a href="#cb93-1181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1182"><a href="#cb93-1182" aria-hidden="true" tabindex="-1"></a><span class="in">```{r iplot_l_don_av_2yr_best_params_filter}</span></span>
<span id="cb93-1183"><a href="#cb93-1183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1184"><a href="#cb93-1184" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb93-1185"><a href="#cb93-1185" aria-hidden="true" tabindex="-1"></a>iplot_l_don_av_2yr_best_params_filter <span class="ot">&lt;-</span></span>
<span id="cb93-1186"><a href="#cb93-1186" aria-hidden="true" tabindex="-1"></a>  l_don_av_2yr_best_params_recode_filter <span class="sc">%&gt;%</span></span>
<span id="cb93-1187"><a href="#cb93-1187" aria-hidden="true" tabindex="-1"></a>      <span class="fu">filter</span>(<span class="sc">!</span><span class="fu">grepl</span>(<span class="st">"tree"</span>, model, <span class="at">ignore.case =</span> <span class="cn">TRUE</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb93-1188"><a href="#cb93-1188" aria-hidden="true" tabindex="-1"></a>    <span class="fu">norm_vi</span>(<span class="at">slice_top =</span> <span class="dv">10</span>) <span class="sc">%&gt;%</span></span>
<span id="cb93-1189"><a href="#cb93-1189" aria-hidden="true" tabindex="-1"></a>    mutate_labels_sign_snip <span class="sc">%&gt;%</span></span>
<span id="cb93-1190"><a href="#cb93-1190" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_max</span>(Total_Norm, <span class="at">n =</span> <span class="dv">10</span>) <span class="sc">%&gt;%</span></span>
<span id="cb93-1191"><a href="#cb93-1191" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Variable =</span> <span class="fu">fct_reorder</span>(Variable, Norm)) <span class="sc">%&gt;%</span></span>
<span id="cb93-1192"><a href="#cb93-1192" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">y =</span> Variable, <span class="at">x =</span> Norm, <span class="at">colour =</span> model, <span class="at">shape =</span> Sign)) <span class="sc">+</span></span>
<span id="cb93-1193"><a href="#cb93-1193" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_shape_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="dv">120</span>, <span class="dv">95</span>, <span class="dv">43</span>)) <span class="sc">+</span></span>
<span id="cb93-1194"><a href="#cb93-1194" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(</span>
<span id="cb93-1195"><a href="#cb93-1195" aria-hidden="true" tabindex="-1"></a>    <span class="at">position =</span> <span class="fu">position_jitter</span>(<span class="at">seed =</span> <span class="dv">42</span>,  <span class="at">width =</span> <span class="fl">0.1</span>, <span class="at">height =</span> <span class="fl">0.1</span>),</span>
<span id="cb93-1196"><a href="#cb93-1196" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> <span class="dv">4</span>, <span class="at">stroke =</span> <span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb93-1197"><a href="#cb93-1197" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Normalised feature importance"</span>) <span class="sc">+</span></span>
<span id="cb93-1198"><a href="#cb93-1198" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Importance: predict log(don.) (filter: income &lt; 500k)"</span>)</span>
<span id="cb93-1199"><a href="#cb93-1199" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb93-1200"><a href="#cb93-1200" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-1201"><a href="#cb93-1201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1202"><a href="#cb93-1202" aria-hidden="true" tabindex="-1"></a>Above, we report the 'importance scores' for the ten most important features ('variables') for two distinct approaches to predicting log (average) donation.^[Note that (as is common in machine learning modeling) all features have been normalized to be on the same scale; for continuous features such as age and income we take the natural log of each, and divide each by two standard deviations of the logged feature, following @gelmanScalingRegressionInputs2008.</span>
<span id="cb93-1203"><a href="#cb93-1203" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb93-1204"><a href="#cb93-1204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1205"><a href="#cb93-1205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1206"><a href="#cb93-1206" aria-hidden="true" tabindex="-1"></a>These importance scores are technically defined <span class="co">[</span><span class="ot">here</span><span class="co">](https://topepo.github.io/caret/variable-importance.html#model-specific-metrics)</span>. For the elastic net ("linear reg") approzach, we depict the coefficients' signs with a "+" or "-"; for tree/forest-based modeling this is less straightforward.</span>
<span id="cb93-1207"><a href="#cb93-1207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1208"><a href="#cb93-1208" aria-hidden="true" tabindex="-1"></a>Income (normalized, bottom-coded at 5000 USD, and logged) is the most important predictor for each model, by a wide margin. After this, the relative importances vary.^[Note that 'student category non-response' is the second most important predictor in the linear model. This doesn't seem to have a clear interpretation, but including this may help us better interpret other features like student status. To the extent that it is predictive, we might also expect it to be predictive in future cases, and it should go into useful predictions. On the other hand this non-reporting isn't the sort of feature we could apply to predictions and policy judgements for broad groups in the wild, absent a similar survey. We can't say "let's target our program to people who are unlikely to indicate student status in a survey'. </span>
<span id="cb93-1209"><a href="#cb93-1209" aria-hidden="true" tabindex="-1"></a>... We might expect non-response to be associated with lower engagement, and perhaps lower donation rates. However, we are considering non-responses to particular questions *among* those who did report a donation amount.]</span>
<span id="cb93-1210"><a href="#cb93-1210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1211"><a href="#cb93-1211" aria-hidden="true" tabindex="-1"></a>We next focus specifically on the elastic-net regression-based model.</span>
<span id="cb93-1212"><a href="#cb93-1212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1213"><a href="#cb93-1213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1214"><a href="#cb93-1214" aria-hidden="true" tabindex="-1"></a><span class="in">```{r enet-coefs-plot}</span></span>
<span id="cb93-1215"><a href="#cb93-1215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1216"><a href="#cb93-1216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1217"><a href="#cb93-1217" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb93-1218"><a href="#cb93-1218" aria-hidden="true" tabindex="-1"></a>enet_coefs_ldon <span class="ot">&lt;-</span> l_don_av_2yr_best_params_recode_filter <span class="sc">%&gt;%</span></span>
<span id="cb93-1219"><a href="#cb93-1219" aria-hidden="true" tabindex="-1"></a>      <span class="fu">filter</span>(</span>
<span id="cb93-1220"><a href="#cb93-1220" aria-hidden="true" tabindex="-1"></a>        <span class="fu">grepl</span>(<span class="st">"regression"</span>, model, <span class="at">ignore.case =</span> <span class="cn">TRUE</span>)  <span class="sc">&amp;</span> Importance<span class="sc">!=</span><span class="dv">0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb93-1221"><a href="#cb93-1221" aria-hidden="true" tabindex="-1"></a>  mutate_labels_sign_snip <span class="sc">%&gt;%</span></span>
<span id="cb93-1222"><a href="#cb93-1222" aria-hidden="true" tabindex="-1"></a>  <span class="co">#mutate(Norm = scale_var(Importance)) %&gt;%</span></span>
<span id="cb93-1223"><a href="#cb93-1223" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">Variable =</span> <span class="fu">fct_reorder</span>(Variable, Importance)) <span class="sc">%&gt;%</span></span>
<span id="cb93-1224"><a href="#cb93-1224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1225"><a href="#cb93-1225" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">y =</span> Variable, <span class="at">x =</span> Importance, <span class="at">shape =</span> Sign)) <span class="sc">+</span></span>
<span id="cb93-1226"><a href="#cb93-1226" aria-hidden="true" tabindex="-1"></a>      <span class="fu">scale_shape_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="dv">95</span>, <span class="dv">43</span>)) <span class="sc">+</span></span>
<span id="cb93-1227"><a href="#cb93-1227" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">2</span>, <span class="at">stroke =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb93-1228"><a href="#cb93-1228" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Feature importance"</span>) <span class="sc">+</span></span>
<span id="cb93-1229"><a href="#cb93-1229" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Importance scores: predicting log(don.)"</span>)</span>
<span id="cb93-1230"><a href="#cb93-1230" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb93-1231"><a href="#cb93-1231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1232"><a href="#cb93-1232" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-1233"><a href="#cb93-1233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1234"><a href="#cb93-1234" aria-hidden="true" tabindex="-1"></a>The graph above presents the overall ranking of importance scores within the elastic-net linear regression model, with symbols depicting whether these features take on a positive or negative sign.</span>
<span id="cb93-1235"><a href="#cb93-1235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1236"><a href="#cb93-1236" aria-hidden="true" tabindex="-1"></a><span class="fu">###  Donated 1k USD or more outcome (classification)</span></span>
<span id="cb93-1237"><a href="#cb93-1237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1240"><a href="#cb93-1240" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-1241"><a href="#cb93-1241" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb93-1242"><a href="#cb93-1242" aria-hidden="true" tabindex="-1"></a>  iplot_don_1k_best_params <span class="ot">&lt;-</span> d_don_1k_best_params_recode <span class="sc">%&gt;%</span></span>
<span id="cb93-1243"><a href="#cb93-1243" aria-hidden="true" tabindex="-1"></a>      <span class="fu">filter</span>(<span class="sc">!</span><span class="fu">grepl</span>(<span class="st">"tree"</span>, model, <span class="at">ignore.case =</span> <span class="cn">TRUE</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb93-1244"><a href="#cb93-1244" aria-hidden="true" tabindex="-1"></a>    mutate_labels_sign_snip <span class="sc">%&gt;%</span></span>
<span id="cb93-1245"><a href="#cb93-1245" aria-hidden="true" tabindex="-1"></a>    <span class="fu">norm_vi</span>(<span class="at">slice_top =</span> <span class="dv">10</span>) <span class="sc">%&gt;%</span></span>
<span id="cb93-1246"><a href="#cb93-1246" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot_vi</span>() <span class="sc">+</span></span>
<span id="cb93-1247"><a href="#cb93-1247" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Importance scores: predicting donation &gt; 1k USD "</span>)</span>
<span id="cb93-1248"><a href="#cb93-1248" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb93-1249"><a href="#cb93-1249" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-1250"><a href="#cb93-1250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1251"><a href="#cb93-1251" aria-hidden="true" tabindex="-1"></a>Again, both approaches deem (logged, imputed, bottom-coded) income to be the most important predictor of donating 1k USD or more. </span>
<span id="cb93-1252"><a href="#cb93-1252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-1253"><a href="#cb93-1253" aria-hidden="true" tabindex="-1"></a></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->


</body></html>