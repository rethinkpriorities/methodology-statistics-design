<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.113">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>RP: Methods - 21&nbsp; Ch 2. Small/Large Worlds</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: 1;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/3_sampling_the_imaginary.html" rel="next">
<link href="../chapters/1_golem.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><script async="" src="https://hypothes.is/embed.js"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Ch 2. Small/Large Worlds</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">RP: Methods</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/rethinkpriorities/methodology-statistics-design" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle sidebar-tool" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Intro., protocols, style</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction/overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/coding_data.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Coding, data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/presentation_method_discussion.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Presentation/visualisation</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Surveys/trial design</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/survey_designs_methods.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Survey design, item dev.</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/experiments_trials_design.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Experiments: Qualitative design, implementation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/qualitative-design-issues_plus.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Practical issues</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/exp_design_quant.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Quant. issues/VOI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/power_analysis_framework_2.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Power analysis &amp; workflow</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">Statistics/modeling</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/basic_stats.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Frameworks, ‘models’, inference, tests</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/factor_analysis.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Factor analss: EFA/CFA, PCA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/mixed_multilevel_random.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Random/mixed fx, mlm</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/ml_modeling.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Prediction, &amp; ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/time_series_application.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Time Series (applied)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/classification_model_notes.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Classification models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/causal_inf.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Causal Inference</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">Other, worked examples</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/fermi.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">MonteCarlo ‘Fermi est.’</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../from_ea_market_testing/binary_trial_computations_redacted_ed.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Inference/equivalence tests, (binomial)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/other_sections.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Other suggested sections</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">Bayes/Rethinking</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/rethinking_bayes_recoding.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Overview (McE/Bayes)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/1_golem.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Ch 1. Golem of Prague</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/2_small_large_worlds.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Ch 2. Small/Large Worlds</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/3_sampling_the_imaginary.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Ch 3. Sampling the Imaginary (posterior)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/5_spurious_waffles.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Ch 5. The Many Variables &amp; The Spurious Waffles</span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li>
<a href="#garden-of-forking-data" id="toc-garden-of-forking-data" class="nav-link active" data-scroll-target="#garden-of-forking-data"><span class="toc-section-number">21.1</span>  2.1. Garden of Forking data</a>
  <ul class="collapse">
<li><a href="#using-prior-information" id="toc-using-prior-information" class="nav-link" data-scroll-target="#using-prior-information">2.1.2 Using prior information</a></li>
  <li><a href="#from-counts-to-probability" id="toc-from-counts-to-probability" class="nav-link" data-scroll-target="#from-counts-to-probability">2.1.3. From counts to probability</a></li>
  </ul>
</li>
  <li>
<a href="#building-a-model" id="toc-building-a-model" class="nav-link" data-scroll-target="#building-a-model"><span class="toc-section-number">21.2</span>  2.2. Building a model</a>
  <ul class="collapse">
<li><a href="#the-globe-tossing-data-story" id="toc-the-globe-tossing-data-story" class="nav-link" data-scroll-target="#the-globe-tossing-data-story">2.2.1 - the ‘globe tossing’ data story</a></li>
  <li><a href="#bayesian-updating" id="toc-bayesian-updating" class="nav-link" data-scroll-target="#bayesian-updating">2.2.2 Bayesian updating</a></li>
  </ul>
</li>
  <li>
<a href="#components-of-the-model" id="toc-components-of-the-model" class="nav-link" data-scroll-target="#components-of-the-model"><span class="toc-section-number">21.3</span>  2.3. Components of the model</a>
  <ul class="collapse">
<li><a href="#what-prior" id="toc-what-prior" class="nav-link" data-scroll-target="#what-prior">What prior?</a></li>
  </ul>
</li>
  <li>
<a href="#making-the-model-go" id="toc-making-the-model-go" class="nav-link" data-scroll-target="#making-the-model-go"><span class="toc-section-number">21.4</span>  2.4 ‘Making the model go’</a>
  <ul class="collapse">
<li><a href="#bayes-theorem" id="toc-bayes-theorem" class="nav-link" data-scroll-target="#bayes-theorem">2.4.1 Bayes theorem</a></li>
  <li><a href="#grid-approximation" id="toc-grid-approximation" class="nav-link" data-scroll-target="#grid-approximation"><span class="toc-section-number">21.4.1</span>  Grid approximation</a></li>
  <li><a href="#quadratic-approximation-summary" id="toc-quadratic-approximation-summary" class="nav-link" data-scroll-target="#quadratic-approximation-summary">Quadratic approximation (summary)</a></li>
  <li><a href="#markov-chain-monte-carlo-incomplete-explanation" id="toc-markov-chain-monte-carlo-incomplete-explanation" class="nav-link" data-scroll-target="#markov-chain-monte-carlo-incomplete-explanation">Markov chain Monte Carlo (incomplete explanation)</a></li>
  <li><a href="#practice-questions" id="toc-practice-questions" class="nav-link" data-scroll-target="#practice-questions">Practice questions</a></li>
  </ul>
</li>
  </ul><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/rethinkpriorities/methodology-statistics-design/edit/main/chapters/2_small_large_worlds.qmd" class="toc-action">Edit this page</a></p><p><a href="https://github.com/rethinkpriorities/methodology-statistics-design/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="mcelreath_ch2" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Ch 2. Small/Large Worlds</span></span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header><div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/trinker/pacman">pacman</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/pacman/man/p_load.html">p_load</a></span><span class="op">(</span><span class="va">dplyr</span>, <span class="va">magrittr</span>, <span class="va">ggplot2</span>, <span class="va">stringr</span>, <span class="va">tidyr</span>, install <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="garden-of-forking-data" class="level2" data-number="21.1"><h2 data-number="21.1" class="anchored" data-anchor-id="garden-of-forking-data">
<span class="header-section-number">21.1</span> 2.1. Garden of Forking data</h2>
<blockquote class="blockquote">
<p>The small world is the self-contained logical world of the model.</p>
</blockquote>
<blockquote class="blockquote">
<p>The way that Bayesian models learn from evidence is arguably optimal in the small world. When their assumptions approximate reality, they also perform well in the large world. But large world performance has to be demonstrated rather than logically deduced.</p>
</blockquote>
<blockquote class="blockquote">
<p>This demonstrates that there are three (out of 64) ways for a bag containing [a combo of blue and white marbles] to produce the data. The inferential power comes from comparing this count to the numbers of ways each of the other conjectures of the bag’s contents could produce the same data.</p>
</blockquote>
<blockquote class="blockquote">
<p>…. can be computed just by multiplying the new count by the old count. This updating approach amounts to nothing more than asserting that (1) when we have previous information suggesting there are <span class="math inline">\(W_prior\)</span> ways for a conjecture to produce a previous observation <span class="math inline">\(D_{prior}\)</span> and (2) we acquire new observations <span class="math inline">\(D_{new}\)</span> that the same conjecture can produce in <span class="math inline">\(W_{new}\)</span> ways, then (3) the number of ways the conjecture can account for both <span class="math inline">\(D_{prior}\)</span> as well as <span class="math inline">\(D_{new}\)</span> is just the product <span class="math inline">\(W_{prior} \times W_{new}\)</span>.</p>
</blockquote>
<blockquote class="blockquote">
<p>This is sometimes known as the principle of indifference: When there is no reason to say that one conjecture is more plausible than another, weigh all of the conjectures equally. This book does not use nor endorse “ignorance” priors. As we’ll see in later chapters, the structure of the model and the scientific context always provide information that allows us to do better than ignorance.</p>
</blockquote>
<p><img src="images/paste-748728A1.png" class="img-fluid" width="335"></p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note: I’m skipping the construction of the ‘forking paths’ plot pasted above
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Kurz laboriously calculates the values and constructs it using tibbles and ggplot. Not sure what the latter teaches us.</p>
</div>
</div>
</div>
<section id="using-prior-information" class="level3 unnumbered"><h3 class="unnumbered anchored" data-anchor-id="using-prior-information">2.1.2 Using prior information</h3>
<p>Some functions and data for tabulating ‘how likely is the data we drew’ (marbles we saw) given different bag compositions. We ‘count the (equally likely) ways’ below. This is the product of ‘ways of drawing the first (blue) marble’, the second ‘white’, and the third ‘blue’ marble.</p>
<div class="cell">
<details><summary>Ways of producing data</summary><div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># if we make two custom functions, here, it will simplify the code within `mutate()`, below</span></span>
<span><span class="va">n_blue</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">x</span> <span class="op">==</span> <span class="st">"b"</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">n_white</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">x</span> <span class="op">==</span> <span class="st">"w"</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">t</span> <span class="op">&lt;-</span></span>
<span>  <span class="co"># for the first four columns, `p_` indexes position</span></span>
<span>  <span class="fu">tibble</span><span class="op">(</span>p_1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"w"</span>, <span class="st">"b"</span><span class="op">)</span>, times <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span>,</span>
<span>         p_2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"w"</span>, <span class="st">"b"</span><span class="op">)</span>, times <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span>,</span>
<span>         p_3 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"w"</span>, <span class="st">"b"</span><span class="op">)</span>, times <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span>,</span>
<span>         p_4 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"w"</span>, <span class="st">"b"</span><span class="op">)</span>, times <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>`draw 1: blue`  <span class="op">=</span> <span class="fu">n_blue</span><span class="op">(</span><span class="va">.</span><span class="op">)</span>,</span>
<span>         `draw 2: white` <span class="op">=</span> <span class="fu">n_white</span><span class="op">(</span><span class="va">.</span><span class="op">)</span>,</span>
<span>         `draw 3: blue`  <span class="op">=</span> <span class="fu">n_blue</span><span class="op">(</span><span class="va">.</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>`ways to produce` <span class="op">=</span> <span class="va">`draw 1: blue`</span> <span class="op">*</span> <span class="va">`draw 2: white`</span> <span class="op">*</span> <span class="va">`draw 3: blue`</span><span class="op">)</span></span>
<span></span>
<span><span class="va">t</span> <span class="op">%&gt;%</span>  <span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html">kable</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<table class="table table-sm table-striped">
<colgroup>
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 18%">
<col style="width: 19%">
<col style="width: 18%">
<col style="width: 22%">
</colgroup>
<thead><tr class="header">
<th style="text-align: left;">p_1</th>
<th style="text-align: left;">p_2</th>
<th style="text-align: left;">p_3</th>
<th style="text-align: left;">p_4</th>
<th style="text-align: right;">draw 1: blue</th>
<th style="text-align: right;">draw 2: white</th>
<th style="text-align: right;">draw 3: blue</th>
<th style="text-align: right;">ways to produce</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">w</td>
<td style="text-align: left;">w</td>
<td style="text-align: left;">w</td>
<td style="text-align: left;">w</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">b</td>
<td style="text-align: left;">w</td>
<td style="text-align: left;">w</td>
<td style="text-align: left;">w</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
</tr>
<tr class="odd">
<td style="text-align: left;">b</td>
<td style="text-align: left;">b</td>
<td style="text-align: left;">w</td>
<td style="text-align: left;">w</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">8</td>
</tr>
<tr class="even">
<td style="text-align: left;">b</td>
<td style="text-align: left;">b</td>
<td style="text-align: left;">b</td>
<td style="text-align: left;">w</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">9</td>
</tr>
<tr class="odd">
<td style="text-align: left;">b</td>
<td style="text-align: left;">b</td>
<td style="text-align: left;">b</td>
<td style="text-align: left;">b</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Next we get more data: another blue marble (already shown above), and there is a ‘shortcut’:</p>
<blockquote class="blockquote">
<p>You could start all over again, making a garden with four layers to trace out the paths compatible with the data sequence. Or you could take the previous counts—the prior counts—over conjectures (0, 3, 8, 9, 0) and just update them in light of the new observation. It turns out that these two methods are mathematically identical, as long as the new observation is logically independent of the previous observations</p>
</blockquote>
<div class="cell">
<details><summary>Ways; add a marble</summary><div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">t</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">t</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">rename</span><span class="op">(</span>`previous counts` <span class="op">=</span> <span class="va">`ways to produce`</span>,</span>
<span>         `ways to produce` <span class="op">=</span> <span class="va">`draw 1: blue`</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="va">p_1</span><span class="op">:</span><span class="va">p_4</span>, <span class="va">`ways to produce`</span>, <span class="va">`previous counts`</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>`new count` <span class="op">=</span> <span class="va">`ways to produce`</span> <span class="op">*</span> <span class="va">`previous counts`</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We can also incorporate ‘different data’ – e,g., certain amounts of ‘prior counts of each bag in the factory’ … we simply multiply these in. ‘You first draw a factory bag with a particular count … which can occur XXX ways, and then you draw a blue marble from that bag, which can occur YYY ways, etc’.</p>
<div class="cell">
<details><summary>add factory counts</summary><div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">t</span> <span class="op">&lt;-</span> <span class="va">t</span> <span class="op">%&gt;%</span></span>
<span><span class="fu">select</span><span class="op">(</span><span class="va">p_1</span><span class="op">:</span><span class="va">p_4</span>, <span class="va">`new count`</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span><span class="fu">rename</span><span class="op">(</span>`prior count` <span class="op">=</span> <span class="va">`new count`</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>`factory count` <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">3</span><span class="op">:</span><span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span><span class="fu">mutate</span><span class="op">(</span>`new count` <span class="op">=</span> <span class="va">`prior count`</span> <span class="op">*</span> <span class="va">`factory count`</span><span class="op">)</span></span>
<span></span>
<span><span class="va">t</span> <span class="op">%&gt;%</span></span>
<span><span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html">kable</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<table class="table table-sm table-striped">
<thead><tr class="header">
<th style="text-align: left;">p_1</th>
<th style="text-align: left;">p_2</th>
<th style="text-align: left;">p_3</th>
<th style="text-align: left;">p_4</th>
<th style="text-align: right;">prior count</th>
<th style="text-align: right;">factory count</th>
<th style="text-align: right;">new count</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">w</td>
<td style="text-align: left;">w</td>
<td style="text-align: left;">w</td>
<td style="text-align: left;">w</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">b</td>
<td style="text-align: left;">w</td>
<td style="text-align: left;">w</td>
<td style="text-align: left;">w</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">9</td>
</tr>
<tr class="odd">
<td style="text-align: left;">b</td>
<td style="text-align: left;">b</td>
<td style="text-align: left;">w</td>
<td style="text-align: left;">w</td>
<td style="text-align: right;">16</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">32</td>
</tr>
<tr class="even">
<td style="text-align: left;">b</td>
<td style="text-align: left;">b</td>
<td style="text-align: left;">b</td>
<td style="text-align: left;">w</td>
<td style="text-align: right;">27</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">27</td>
</tr>
<tr class="odd">
<td style="text-align: left;">b</td>
<td style="text-align: left;">b</td>
<td style="text-align: left;">b</td>
<td style="text-align: left;">b</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
</div>
</div>
</section><section id="from-counts-to-probability" class="level3 unnumbered"><h3 class="unnumbered anchored" data-anchor-id="from-counts-to-probability">2.1.3. From counts to probability</h3>
<p><img src="images/paste-D5765E47.png" class="img-fluid"></p>
<p>Putting this all together to compute the plausibilities</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
DR question: Is this with a flat prior
</div>
</div>
<div class="callout-body-container callout-body">
<p>Is this with a flat prior… starting with an equal probability of each bag type, or is ‘plausibility’ something different than the posterior?</p>
</div>
</div>
<div class="cell">
<details><summary>plausibilities</summary><div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">t</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="va">p_1</span><span class="op">:</span><span class="va">p_4</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>p                      <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, by <span class="op">=</span> <span class="fl">.25</span><span class="op">)</span>,</span>
<span>         `ways to produce data` <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">3</span>, <span class="fl">8</span>, <span class="fl">9</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>plausibility <span class="op">=</span> <span class="va">`ways to produce data`</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">`ways to produce data`</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 7
  p_1   p_2   p_3   p_4       p `ways to produce data` plausibility
  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;                  &lt;dbl&gt;        &lt;dbl&gt;
1 w     w     w     w      0                         0         0   
2 b     w     w     w      0.25                      3         0.15
3 b     b     w     w      0.5                       8         0.4 
4 b     b     b     w      0.75                      9         0.45
5 b     b     b     b      1                         0         0   </code></pre>
</div>
</div>
</section></section><section id="building-a-model" class="level2" data-number="21.2"><h2 data-number="21.2" class="anchored" data-anchor-id="building-a-model">
<span class="header-section-number">21.2</span> 2.2. Building a model</h2>
<blockquote class="blockquote">
<p>Designing a simple Bayesian model benefits from a design loop with three steps. (1) Data story: Motivate the model by narrating how the data might arise. (2) Update: Educate your model by feeding it the data. (3) Evaluate: All statistical models require supervision, leading to model revision</p>
</blockquote>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
DR question
</div>
</div>
<div class="callout-body-container callout-body">
<p>How can we ‘revise the model’ without overfitting or otherwise cheating in some way that overstates the confidence we should have in our results?</p>
</div>
</div>
<blockquote class="blockquote">
<p>The maximum height of the curve increases with each sample, meaning that fewer values of <span class="math inline">\(p\)</span> amass more plausibility as the amount of evidence increases</p>
</blockquote>
<p><strong>Power of Bayesian inference in small-sample contexts</strong></p>
<blockquote class="blockquote">
<p>Why? In non-Bayesian statistical inference, procedures are often justified by the method’s behavior at very large sample sizes, so-called asymptotic behavior. As a result, performance at small samples sizes is questionable. In contrast, Bayesian estimates are valid for any sample size. This does not mean that more data isn’t helpful—it certainly is. Rather, the estimates have a clear and valid interpretation, no matter the sample size. But the price for this power is dependency upon the initial plausibilities, the prior. If the prior is a bad one, then the resulting inference will be misleading.</p>
</blockquote>
<p><em>DR note</em>: There are some frequentist/non-Bayesian procedures and tests that don’t rely on large sample approximations; e.g., Fisher’s exact test</p>
<section id="the-globe-tossing-data-story" class="level3 unnumbered"><h3 class="unnumbered anchored" data-anchor-id="the-globe-tossing-data-story">2.2.1 - the ‘globe tossing’ data story</h3>
</section><section id="bayesian-updating" class="level3 unnumbered"><h3 class="unnumbered anchored" data-anchor-id="bayesian-updating">2.2.2 Bayesian updating</h3>
<p>Start with a particular sequence of data, accumulate trials and successes</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="op">(</span><span class="va">d</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu">tibble</span><span class="op">(</span></span>
<span>      toss <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"w"</span>, <span class="st">"l"</span>, <span class="st">"w"</span>, <span class="st">"w"</span>, <span class="st">"w"</span>, <span class="st">"l"</span>, <span class="st">"w"</span>, <span class="st">"l"</span>, <span class="st">"w"</span><span class="op">)</span>,</span>
<span>      n_trials <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">9</span>,</span>
<span>n_success <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cumsum.html">cumsum</a></span><span class="op">(</span><span class="va">toss</span> <span class="op">==</span> <span class="st">"w"</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code># A tibble: 9 × 3
  toss  n_trials n_success
  &lt;chr&gt;    &lt;int&gt;     &lt;int&gt;
1 w            1         1
2 l            2         1
3 w            3         2
4 w            4         3
5 w            5         4
6 l            6         4
7 w            7         5
8 l            8         5
9 w            9         6</code></pre>
</div>
</div>
<p>Next, we compute and plot the plausibility of every ‘true share of water p’ after observing the draws from the globe-tossing. We update this after each toss.</p>
<p>OK I need to construct some data on this globe tossing first; I skipped this earlier</p>
<p>Next we build the tibble plausibility/updating tibble.</p>
<p>Going through the coding steps for my own benefit… First we expand the tibble to consider each of 50 possible <code>p_water</code> values after each trial (toss).</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">sequence_length</span> <span class="op">&lt;-</span> <span class="fl">50</span></span>
<span></span>
<span><span class="op">(</span></span>
<span><span class="va">plaus_globe_updates</span> <span class="op">&lt;-</span></span>
<span><span class="va">d</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">expand</span><span class="op">(</span><span class="fu">nesting</span><span class="op">(</span><span class="va">n_trials</span>, <span class="va">toss</span>, <span class="va">n_success</span><span class="op">)</span>,</span>
<span>         p_water <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="va">sequence_length</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code># A tibble: 450 × 4
   n_trials toss  n_success p_water
      &lt;int&gt; &lt;chr&gt;     &lt;int&gt;   &lt;dbl&gt;
 1        1 w             1  0     
 2        1 w             1  0.0204
 3        1 w             1  0.0408
 4        1 w             1  0.0612
 5        1 w             1  0.0816
 6        1 w             1  0.102 
 7        1 w             1  0.122 
 8        1 w             1  0.143 
 9        1 w             1  0.163 
10        1 w             1  0.184 
# … with 440 more rows</code></pre>
</div>
</div>
<p>Next we create the ‘lagged’ columns (for ease of plotting the updating):</p>
<div class="cell">
<details><summary>updating globe tossing - lags</summary><div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">plaus_globe_updates</span> <span class="op">%&lt;&gt;%</span></span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">p_water</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span> <span class="co"># you can learn more about lagging here: https://www.rdocumentation.org/packages/stats/versions/3.5.1/topics/lag or here: https://dplyr.tidyverse.org/reference/lead-lag.html</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>lagged_n_trials  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lag.html">lag</a></span><span class="op">(</span><span class="va">n_trials</span>,  k <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,</span>
<span>         lagged_n_success <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lag.html">lag</a></span><span class="op">(</span><span class="va">n_success</span>, k <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">ungroup</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">plaus_globe_updates</span><span class="op">[</span><span class="fl">95</span><span class="op">:</span><span class="fl">105</span>,<span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code># A tibble: 11 × 6
   n_trials toss  n_success p_water lagged_n_trials lagged_n_success
      &lt;int&gt; &lt;chr&gt;     &lt;int&gt;   &lt;dbl&gt;           &lt;int&gt;            &lt;int&gt;
 1        2 l             1  0.898                1                1
 2        2 l             1  0.918                1                1
 3        2 l             1  0.939                1                1
 4        2 l             1  0.959                1                1
 5        2 l             1  0.980                1                1
 6        2 l             1  1                    1                1
 7        3 w             2  0                    2                1
 8        3 w             2  0.0204               2                1
 9        3 w             2  0.0408               2                1
10        3 w             2  0.0612               2                1
11        3 w             2  0.0816               2                1</code></pre>
</div>
</div>
<p>Next we start with a flat prior and, for each ‘trial’ …</p>
<ul>
<li>compute the likelihood of the data (sucesses and trials) given each probability of water, according to the <em>binomial probability function</em>.</li>
<li>both with the previous ‘lagged’ data and adding the new data point</li>
<li>normalize each of these by dividing by the likelihood of the data that has arisen,</li>
<li>this yields the ‘plausbility’ of each probability of water . (I.e., the posterior?)</li>
</ul>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">plaus_globe_updates</span> <span class="op">%&lt;&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>prior  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">n_trials</span> <span class="op">==</span> <span class="fl">1</span>, <span class="fl">1</span>, <span class="co">#DR: I adjusted this to =1 to avoid confusing it with a certainty that p=.5</span></span>
<span>          <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span></span>
<span>            x<span class="op">=</span> <span class="va">lagged_n_success</span>,</span>
<span>            size <span class="op">=</span> <span class="va">lagged_n_trials</span>,</span>
<span>            prob <span class="op">=</span> <span class="va">p_water</span><span class="op">)</span><span class="op">)</span>,</span>
<span>         likelihood <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span>x  <span class="op">=</span> <span class="va">n_success</span>,</span>
<span>                             size <span class="op">=</span> <span class="va">n_trials</span>,</span>
<span>                             prob <span class="op">=</span> <span class="va">p_water</span><span class="op">)</span>,</span>
<span>         strip      <span class="op">=</span> <span class="fu">str_c</span><span class="op">(</span><span class="st">"n = "</span>, <span class="va">n_trials</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="co"># the next three lines allow us to normalize the prior and the likelihood,</span></span>
<span>  <span class="co"># putting them both in a probability metric</span></span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">n_trials</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>prior      <span class="op">=</span> <span class="va">prior</span>      <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">prior</span><span class="op">)</span>,</span>
<span>         likelihood <span class="op">=</span> <span class="va">likelihood</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">likelihood</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Plotting this:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">plaus_globe_updates</span> <span class="op">%&gt;%</span></span>
<span>  <span class="co"># filter(n_trials==5) %&gt;%</span></span>
<span>  <span class="co"># plot!</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">p_water</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>y <span class="op">=</span> <span class="va">prior</span><span class="op">)</span>, linetype <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>y <span class="op">=</span> <span class="va">likelihood</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_x_continuous</span><span class="op">(</span><span class="st">"proportion water"</span>, breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">.5</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_y_continuous</span><span class="op">(</span><span class="st">"plausibility"</span>, breaks <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>panel.grid <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span><span class="va">strip</span>, scales <span class="op">=</span> <span class="st">"free_y"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="2_small_large_worlds_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid" width="576"></p>
</div>
</div>
<p><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Other love letter notes on the above
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<blockquote class="blockquote">
<p>If it wasn’t clear in the code, the dashed curves are normalized prior densities. The solid ones are normalized likelihoods. If you don’t normalize (i.e., divide the density by the sum of the density), their respective heights don’t match up with those in the text. Furthermore, it’s the normalization that makes them directly comparable.</p>
</blockquote>
<blockquote class="blockquote">
<p>To learn more about <code><a href="https://dplyr.tidyverse.org/reference/group_by.html">dplyr::group_by()</a></code> and its opposite <code><a href="https://dplyr.tidyverse.org/reference/group_by.html">dplyr::ungroup()</a></code>, check out <a href="https://r4ds.had.co.nz/transform.html"><em>R4DS</em>, Chapter 5</a>. To learn about <code><a href="https://tidyr.tidyverse.org/reference/expand.html">tidyr::expand()</a></code>, go <a href="https://tidyr.tidyverse.org/reference/expand.html">here</a>.</p>
</blockquote>
</div>
</div>
</div>
</section></section><section id="components-of-the-model" class="level2" data-number="21.3"><h2 data-number="21.3" class="anchored" data-anchor-id="components-of-the-model">
<span class="header-section-number">21.3</span> 2.3. Components of the model</h2>
<blockquote class="blockquote">
<ol type="1">
<li>a likelihood function: “the number of ways each conjecture could produce an observation”</li>
</ol>
</blockquote>
<blockquote class="blockquote">
<ol start="2" type="1">
<li>one or more parameters: “the accumulated number of ways each conjecture could produce the entire data”</li>
</ol>
</blockquote>
<blockquote class="blockquote">
<ol start="3" type="1">
<li>a prior: “the initial plausibility of each conjectured cause of the data”</li>
</ol>
</blockquote>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Coding tip: <code>dbinom</code>, <code>pbinom</code>, <code>rbinom</code>, etc
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<blockquote class="blockquote">
<p>“d” in <code>dbinom</code> stands for density. Functions named in this way almost always have corresponding partners that begin with “r” for random samples and that begin with “-p” for cumulative probabilities</p>
</blockquote>
</div>
</div>
</div>
<blockquote class="blockquote">
<p>The distributions we assign to the observed variables typically have their own variables.</p>
</blockquote>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
(Comparing frameworks) Rethinking: A central role for likelihood.
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<blockquote class="blockquote">
<p>A great deal of ink has been spilled focusing on how Bayesian and non-Bayesian data analyses differ. Focusing on differences is useful, but sometimes it distracts us from fundamental similarities. Notably, the most influential assumptions in both Bayesian and many non-Bayesian models are the distributions assigned to data, the likelihood functions. The likelihoods influence inference for every piece of data, and as sample size increases, the likelihood matters more and more. This helps to explain why Bayesian and non-Bayesian inferences are often so similar. If we had to explain Bayesian inference using only one aspect of it, we should describe likelihood, not priors.</p>
</blockquote>
<p>(DR: move this to our discussion of compring statistical frameworks?)</p>
</div>
</div>
</div>
<section id="what-prior" class="level3 unnumbered"><h3 class="unnumbered anchored" data-anchor-id="what-prior">What prior?</h3>
<blockquote class="blockquote">
<p>So where do priors come from? They are both engineering assumptions, chosen to help the machine learn, and scientific assumptions, chosen to reflect what we know about a phenomenon. The flat prior in Figure 2.5 is very common, but it is hardly ever the best prior.</p>
</blockquote>
<blockquote class="blockquote">
<p>There is a school of Bayesian inference that emphasizes choosing priors based upon the personal beliefs of the analyst. While this subjective Bayesian approach thrives in some statistics and philosophy and economics programs, it is rare in the sciences.</p>
</blockquote>
<blockquote class="blockquote">
<p>If your goal is to lie with statistics, you’d be a fool to do it with priors, because such a lie would be easily uncovered. Better to use the more opaque machinery of the likelihood. Or better yet-don’t actually take this advice!—massage the data, drop some “outliers,” and otherwise engage in motivated data transformation</p>
</blockquote>
<blockquote class="blockquote">
<p>because non-Bayesian procedures need to make choices that Bayesian ones do not, such as choice of estimator or likelihood penalty.</p>
</blockquote>
<p><em>DR: I skip the construction of the ‘multiply prior by likelihood to get posterior’ graphs for now …</em></p>
<p><em>Below: flat, stepped, Laplace priors</em></p>
<p><img src="images/paste-47A2FD04.png" class="img-fluid"></p>
</section></section><section id="making-the-model-go" class="level2" data-number="21.4"><h2 data-number="21.4" class="anchored" data-anchor-id="making-the-model-go">
<span class="header-section-number">21.4</span> 2.4 ‘Making the model go’</h2>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>DR: I think this section is particularly important. It’s our first pass on ‘how to actually do this stuff’. Reading group: I suggest we put some focus on it, maybe in the next session.</p>
</div>
</div>
<section id="bayes-theorem" class="level3 unnumbered"><h3 class="unnumbered anchored" data-anchor-id="bayes-theorem">2.4.1 Bayes theorem</h3>
<p>In word form:</p>
<blockquote class="blockquote">
<p>Posterior (probability of any given value of <span class="math inline">\(p\)</span>) =</p>
</blockquote>
<p>(Probability of the data [given p] <span class="math inline">\(\times\)</span> [Prior probability of p]) divided by the ‘Average probability of the data’</p>
<p>I.e., (in my own words) ‘how likely is this data <em>and</em> the particular parameter p’ divided by ‘the probability of this data overall’ (given any p, with the probability of each p following the prior)</p>
<blockquote class="blockquote">
<p>‘average probability of the data’</p>
</blockquote>
<blockquote class="blockquote">
<p>Averaged over what? Averaged over the prior. It’s job is just to standardize the posterior, to ensure it sums (integrates) to one. In mathematical form: Pr(W, L) = E</p>
</blockquote>
<p>Probability of one Water followed by one Land:</p>
<p><span class="math display">\[Pr(W, L|p)\]</span> <span class="math display">\[=E\Big( Pr(W, L|p) Big)\]</span></p>
<p><span class="math display">\[= \int  Pr(W,L|p) Pr(p)dp \]</span></p>
<blockquote class="blockquote">
<p>The key lesson is that the posterior is proportional to the product of the prior and the probability of the data [given the prior]. Why? Because for each specific value of p, the number of paths through the garden of forking data is the product of the prior number of paths and the new number of paths. A flat prior constructs a posterior that is simply proportional to the likelihood</p>
</blockquote>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
“Bayesian data analysis isn’t about Bayes’ theorem”
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Dissing the ‘HIV test false positive’ thing</p>
<blockquote class="blockquote">
<p>Inference under any probability concept will eventually make use of Bayes’ theorem. Common introductory examples of ‘Bayesian’ analysis using HIV and DNA testing are not uniquely Bayesian</p>
</blockquote>
</div>
</div>
</div>
<blockquote class="blockquote">
<p>Numerical techniques for computing posterior distributions: (1) Grid approximation (2) Quadratic approximation (3) Markov chain Monte Carlo (MCMC)</p>
</blockquote>
<blockquote class="blockquote">
<p>Grid approximation: Basically mechanical Bayesian updating of the probability of a parameter value being in a range, dividing up the space of possible parameters into different ranges. (And then smoothing?)</p>
</blockquote>
<blockquote class="blockquote">
<p>… achieve an excellent approximation of the continuous posterior distribution by considering only a finite grid of parameter values</p>
</blockquote>
<blockquote class="blockquote">
<p>in most of your real modeling, grid approximation isn’t practical. The reason is that it scales very poorly, as the number of parameters increases</p>
</blockquote>
</section><section id="grid-approximation" class="level3" data-number="21.4.1"><h3 data-number="21.4.1" class="anchored" data-anchor-id="grid-approximation">
<span class="header-section-number">21.4.1</span> Grid approximation</h3>
<p>The code below makes a data frame with</p>
<ol type="1">
<li>20 Probabilities between 0 and 1</li>
<li>A ‘flat’ density (=1 everywhere) for these</li>
<li>The likelihood of “6 waters in 9” (the data) given each of the 20 probabilities (binomial distribution)</li>
<li>This likelihood <span class="math inline">\(\times\)</span> the prior for each <code>p_water</code>.</li>
</ol>
<ul>
<li>Rem: this is likelihood of a particular <code>p_water</code> <em>and</em> the observed data given that <code>p_water</code>
</li>
<li>Given the flat prior it is simply the latter</li>
</ul>
<ol start="5" type="1">
<li>Standardizing this by dividing by the probability of the data observed</li>
</ol>
<div class="cell">
<details><summary>Grid, computing posteriors</summary><div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="op">(</span></span>
<span>  <span class="va">d</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu">tibble</span><span class="op">(</span>p_grid <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">20</span><span class="op">)</span>,      <span class="co"># define grid</span></span>
<span>           prior  <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">%&gt;%</span>                                       <span class="co"># define prior</span></span>
<span>    <span class="fu">mutate</span><span class="op">(</span>likelihood <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">6</span>, size <span class="op">=</span> <span class="fl">9</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>  <span class="co"># compute likelihood at each value in grid</span></span>
<span>    <span class="fu">mutate</span><span class="op">(</span>unstd_posterior <span class="op">=</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span><span class="op">)</span> <span class="op">%&gt;%</span>             <span class="co"># compute product of likelihood and prior</span></span>
<span>    <span class="fu">mutate</span><span class="op">(</span>posterior <span class="op">=</span> <span class="va">unstd_posterior</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd_posterior</span><span class="op">)</span><span class="op">)</span>   <span class="co"># standardize the posterior, so it sums to 1</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code># A tibble: 20 × 5
   p_grid prior likelihood unstd_posterior   posterior
    &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;       &lt;dbl&gt;
 1 0          1 0               0          0          
 2 0.0526     1 0.00000152      0.00000152 0.000000799
 3 0.105      1 0.0000819       0.0000819  0.0000431  
 4 0.158      1 0.000777        0.000777   0.000409   
 5 0.211      1 0.00360         0.00360    0.00189    
 6 0.263      1 0.0112          0.0112     0.00587    
 7 0.316      1 0.0267          0.0267     0.0140     
 8 0.368      1 0.0529          0.0529     0.0279     
 9 0.421      1 0.0908          0.0908     0.0478     
10 0.474      1 0.138           0.138      0.0728     
11 0.526      1 0.190           0.190      0.0999     
12 0.579      1 0.236           0.236      0.124      
13 0.632      1 0.267           0.267      0.140      
14 0.684      1 0.271           0.271      0.143      
15 0.737      1 0.245           0.245      0.129      
16 0.789      1 0.190           0.190      0.0999     
17 0.842      1 0.118           0.118      0.0621     
18 0.895      1 0.0503          0.0503     0.0265     
19 0.947      1 0.00885         0.00885    0.00466    
20 1          1 0               0          0          </code></pre>
</div>
</div>
<p>We then plot the posterior probabilities of each <code>p_water</code>:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="op">(</span></span>
<span>  <span class="va">p1</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">d</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">p_grid</span>, y <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>subtitle <span class="op">=</span> <span class="st">"20 points"</span>,</span>
<span>       x <span class="op">=</span> <span class="st">"probability of water"</span>,</span>
<span>       y <span class="op">=</span> <span class="st">"posterior probability"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>panel.grid <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="2_small_large_worlds_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section><section id="quadratic-approximation-summary" class="level3 unnumbered"><h3 class="unnumbered anchored" data-anchor-id="quadratic-approximation-summary">Quadratic approximation (summary)</h3>
<blockquote class="blockquote">
<p>Under quite general conditions, the region near the peak of the posterior distribution will be nearly Gaussian-or “normal”—in shape. This means the posterior distribution can be usefully approximated by a Gaussian distribution. A Gaussian distribution is convenient, because it can be completely described by only two numbers: the location of its center (mean) and its spread (variance)</p>
</blockquote>
<blockquote class="blockquote">
<p>logarithm of a Gaussian distribution forms a parabola. And a parabola is a quadratic function</p>
</blockquote>
<blockquote class="blockquote">
<p>For many of the most common procedures in applied statistics-linear regression, for example—the approximation works very well</p>
</blockquote>
<p><strong>Stepping through this</strong></p>
<blockquote class="blockquote">
<ol type="1">
<li>Find the posterior mode</li>
</ol>
</blockquote>
<p>Some optimization algorithm, a procedure that virtually “climbs” the posterior distribution</p>
<blockquote class="blockquote">
<ol start="2" type="1">
<li>estimate the curvature near the peak. This curvature is sufficient to compute a quadratic approximation of the entire posterior distribution. In some cases, these calculations can be done analytically, but…</li>
</ol>
</blockquote>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
DR question
</div>
</div>
<div class="callout-body-container callout-body">
<p>But how does it do this estimate of the curvature? Does it come out of many simulations, or the optimizing hill climbing thing, or??</p>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
The Hession and quadratic approximation
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<blockquote class="blockquote">
<p>Hessian is a square matrix of second derivatives. It is used for many purposes in mathematics, but in the quadratic approximation it is second derivatives of the log of posterior probability with respect to the parameters. It turns out that these derivatives are sufficient to describe a Gaussian distribution, because the logarithm of a Gaussian distribution is just a parabola. Parabolas have no derivatives beyond the second</p>
</blockquote>
</div>
</div>
</div>
<p>Applying the quadratic approximation to the globe tossing data with <code><a href="https://rdrr.io/pkg/rethinking/man/quap.html">rethinking::map()</a></code>.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
<code><a href="https://rdrr.io/pkg/rethinking/man/quap.html">rethinking::map()</a></code> coding notes
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Here the ‘love letter’ uses McElreath’s rethinking package instead of brms … I guess it’s because quadratic approximation is more for learning than for real use?</p>
<p><code>quap</code> and <code>map</code>:</p>
<ul>
<li>“Find mode of posterior distribution for arbitrary fixed effect models”</li>
<li>“and then produce an approximation of the full posterior using the quadratic curvature at the mode.”</li>
</ul>
<p>(This has nothing to do with <code><a href="https://purrr.tidyverse.org/reference/map.html">purrr::map</a></code> iteration package thing.)</p>
</div>
</div>
</div>
<div class="cell">
<details><summary>quap with <code>rethinking::map</code></summary><div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">rethinking</span><span class="op">)</span></span>
<span></span>
<span><span class="va">globe_qa</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>      <span class="va">w</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">9</span>, <span class="va">p</span><span class="op">)</span>,  <span class="co"># binomial likelihood</span></span>
<span>      <span class="va">p</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>    <span class="co"># uniform prior</span></span>
<span>    <span class="op">)</span>, </span>
<span>    data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>w <span class="op">=</span> <span class="fl">6</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># display summary of quadratic approximation</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/precis.html">precis</a></span><span class="op">(</span><span class="va">globe_qa</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>       mean        sd      5.5%     94.5%
p 0.6666664 0.1571338 0.4155362 0.9177967</code></pre>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Syntax of above code
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><code>alist</code> is a way of specifying a list (iirc) that preserves it as a ‘name of the math we want to compute on’ rather than it actually expanding/evaluating it.</p>
<p><code>precis</code> is just a handy tool for seeing data .</p>
<p>The output <code>globe_qa</code> contains a lot of content (try <code>str(globe_qa)</code>).</p>
</div>
</div>
</div>
<p>Above, the <code>precis</code> gives us some summary statistics on the estimated posterior.</p>
<p><em>DR: I will skip the code that produces the figure below showing how <code>quap</code> updates with more data, for now</em>.</p>
<p><img src="images/paste-B716044F.png" class="img-fluid"></p>
</section><section id="markov-chain-monte-carlo-incomplete-explanation" class="level3 unnumbered"><h3 class="unnumbered anchored" data-anchor-id="markov-chain-monte-carlo-incomplete-explanation">Markov chain Monte Carlo (incomplete explanation)</h3>
<p>DR:MCMC is not fully explained here. Somehow you ’sample from the posterior (over the parameter values)” and do some magic. Maybe weighting these by how consistent they are with the prior and the data?</p>
<blockquote class="blockquote">
<p>Grid approximation routinely fails here, because it just takes too long—the Sun will go dark before your computer finishes the grid. Special forms of quadratic approximation might work, if everything is just right. But commonly, something is not just right. Furthermore, multilevel models do not always allow us to write down a single, unified function for the posterior distribution. This means that the function to maximize (when finding the MAP) is not known, but must be computed in pieces</p>
</blockquote>
<blockquote class="blockquote">
<p>is fair to say that MCMC is largely responsible for the insurgence of Bayesian data analysis that began in the 1990s.</p>
</blockquote>
<blockquote class="blockquote">
<p>highly non-obvious strategy. Instead of attempting to compute or approximate the posterior distribution directly, MCMC techniques merely draw samples from the posterior. You end up with a collection of parameter values, and the frequencies of these values correspond to the posterior plausibilities. You can then build a picture of the posterior from the histogram of these samples. We nearly always work directly with these samples, rather than first constructing some mathematical estimate from them</p>
</blockquote>
<blockquote class="blockquote">
<p>, a working Markov chain for the globe tossing model does not require much code</p>
</blockquote>
<p>He starts with <span class="math inline">\(p=.5\)</span>, considers the likelihood of the data under this probability, adjusts p.</p>
<p><br></p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
DR question
</div>
</div>
<div class="callout-body-container callout-body">
<p>I don’t see how this MCMC works; anyone have more insight? And where does the prior come in here?)</p>
</div>
</div>
<p><br></p>
<section id="kurz-markov-chain-monte-carlo" class="level4 unnumbered"><h4 class="unnumbered anchored" data-anchor-id="kurz-markov-chain-monte-carlo">Kurz: Markov chain Monte Carlo</h4>
<p>Bringing in <code>brms</code></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/paul-buerkner/brms">brms</a></span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<blockquote class="blockquote">
<p>Here re-fit the last model from above, the one for which <span class="math inline">\(w = 24\)</span> and <span class="math inline">\(n = 36\)</span>.</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">b2.1</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/brms/man/brm.html">brm</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>w <span class="op">=</span> <span class="fl">24</span><span class="op">)</span>, </span>
<span>      family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"identity"</span><span class="op">)</span>,</span>
<span>      <span class="va">w</span> <span class="op">|</span> <span class="fu">trials</span><span class="op">(</span><span class="fl">36</span><span class="op">)</span> <span class="op">~</span> <span class="fl">1</span>,</span>
<span>      <span class="fu"><a href="https://rdrr.io/pkg/brms/man/set_prior.html">prior</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Special.html">beta</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">Intercept</span><span class="op">)</span>,</span>
<span>      iter <span class="op">=</span> <span class="fl">4000</span>, warmup <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>      control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>adapt_delta <span class="op">=</span> <span class="fl">.95</span><span class="op">)</span>,</span>
<span>      seed <span class="op">=</span> <span class="fl">2</span>,</span>
<span>      file <span class="op">=</span> <span class="st">"b02.01"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><em>DR: Not sure why we save a file here</em></p>
<blockquote class="blockquote">
<p>The model output from brms looks like so.</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">b2.1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> Family: binomial 
  Links: mu = identity 
Formula: w | trials(36) ~ 1 
   Data: list(w = 24) (Number of observations: 1) 
  Draws: 4 chains, each with iter = 4000; warmup = 1000; thin = 1;
         total post-warmup draws = 12000

Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept     0.66      0.07     0.50     0.79 1.00     3965     4326

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>There’s a lot going on in that output, which we’ll start to clarify in Chapter 4. For now, focus on the ‘Intercept’ line. As we’ll also learn in Chapter 4, the intercept of a regression model with no predictors is the same as its mean. In the special case of a model using the binomial likelihood, the mean is the probability of a 1 in a given trial, <span class="math inline">\(\theta\)</span>.</p>
</blockquote>
<p>Let’s plot the results of our model and compare them with those from <code><a href="https://rdrr.io/pkg/rethinking/man/quap.html">rethinking::map()</a></code>, above.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/brms/man/posterior_samples.brmsfit.html">posterior_samples</a></span><span class="op">(</span><span class="va">b2.1</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>n <span class="op">=</span> <span class="st">"n = 36"</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">b_Intercept</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_density</span><span class="op">(</span>fill <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_x_continuous</span><span class="op">(</span><span class="st">"proportion water"</span>, limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>panel.grid <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span><span class="va">n</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="2_small_large_worlds_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid" width="288"></p>
</div>
</div>
<blockquote class="blockquote">
<p>If you’re still confused. Cool. This is just a preview. We’ll start walking through fitting models in brms in [Chapter 4][A Gaussian model of height] and we’ll learn a lot about regression with the binomial likelihood in [Chapter 10][Counting and Classification].</p>
</blockquote>
</section></section><section id="practice-questions" class="level3 unnumbered"><h3 class="unnumbered anchored" data-anchor-id="practice-questions">Practice questions</h3>
<blockquote class="blockquote">
<p>The target of inference in Bayesian inference is a posterior probability distribution. Posterior probabilities state the relative numbers of ways each conjectured cause of the data could have produced the data</p>
</blockquote>


<!-- -->

</section></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1"><p>DR note: although the plot looks smooth, I think this is only because we chose a small interval of probability … 50 different probabilities. When I reduce it to 5 probabilities this gets choppy<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../chapters/1_golem.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Ch 1. Golem of Prague</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/3_sampling_the_imaginary.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Ch 3. Sampling the Imaginary (posterior)</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb25" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Ch 2. Small/Large Worlds {#mcelreath_ch2}</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pacman)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="fu">p_load</span>(dplyr, magrittr, ggplot2, stringr, tidyr, <span class="at">install =</span> <span class="cn">FALSE</span>)</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="fu">## 2.1. Garden of Forking data</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The small world is the self-contained logical world of the model.</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The way that Bayesian models learn from evidence is arguably optimal in the small world. When their assumptions approximate reality, they also perform well in the large world. But large world performance has to be demonstrated rather than logically deduced.</span></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; This demonstrates that there are three (out of 64) ways for a bag containing </span><span class="sc">\[</span><span class="at">a combo of blue and white marbles</span><span class="sc">\]</span><span class="at"> to produce the data. The inferential power comes from comparing this count to the numbers of ways each of the other conjectures of the bag's contents could produce the same data.</span></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; .... can be computed just by multiplying the new count by the old count. This updating approach amounts to nothing more than asserting that (1) when we have previous information suggesting there are $W_prior$ ways for a conjecture to produce a previous observation $D_{prior}$ and (2) we acquire new observations $D_{new}$ that the same conjecture can produce in $W_{new}$ ways, then (3) the number of ways the conjecture can account for both $D_{prior}$ as well as $D_{new}$ is just the product $W_{prior} \times W_{new}$.</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; This is sometimes known as the principle of indifference: When there is no reason to say that one conjecture is more plausible than another, weigh all of the conjectures equally. This book does not use nor endorse "ignorance" priors. As we'll see in later chapters, the structure of the model and the scientific context always provide information that allows us to do better than ignorance.</span></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/paste-748728A1.png)</span>{width="335"}</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a><span class="fu">## Note: I'm skipping the construction of the 'forking paths' plot pasted above</span></span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>Kurz laboriously calculates the values and constructs it using tibbles and ggplot. Not sure what the latter teaches us.</span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2.1.2 Using prior information {.unnumbered}</span></span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>Some functions and data for tabulating 'how likely is the data we drew' (marbles we saw) given different bag compositions. We 'count the (equally likely) ways' below. This is the product of 'ways of drawing the first (blue) marble', the second 'white', and the third 'blue' marble.</span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: marble_ways</span></span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Ways of producing data"</span></span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a><span class="co"># if we make two custom functions, here, it will simplify the code within `mutate()`, below</span></span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a>n_blue <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rowSums</span>(x <span class="sc">==</span> <span class="st">"b"</span>)</span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a>n_white <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rowSums</span>(x <span class="sc">==</span> <span class="st">"w"</span>)</span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb25-49"><a href="#cb25-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-50"><a href="#cb25-50" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span></span>
<span id="cb25-51"><a href="#cb25-51" aria-hidden="true" tabindex="-1"></a>  <span class="co"># for the first four columns, `p_` indexes position</span></span>
<span id="cb25-52"><a href="#cb25-52" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">p_1 =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"w"</span>, <span class="st">"b"</span>), <span class="at">times =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">4</span>)),</span>
<span id="cb25-53"><a href="#cb25-53" aria-hidden="true" tabindex="-1"></a>         <span class="at">p_2 =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"w"</span>, <span class="st">"b"</span>), <span class="at">times =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>)),</span>
<span id="cb25-54"><a href="#cb25-54" aria-hidden="true" tabindex="-1"></a>         <span class="at">p_3 =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"w"</span>, <span class="st">"b"</span>), <span class="at">times =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">2</span>)),</span>
<span id="cb25-55"><a href="#cb25-55" aria-hidden="true" tabindex="-1"></a>         <span class="at">p_4 =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"w"</span>, <span class="st">"b"</span>), <span class="at">times =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">1</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb25-56"><a href="#cb25-56" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="st">`</span><span class="at">draw 1: blue</span><span class="st">`</span>  <span class="ot">=</span> <span class="fu">n_blue</span>(.),</span>
<span id="cb25-57"><a href="#cb25-57" aria-hidden="true" tabindex="-1"></a>         <span class="st">`</span><span class="at">draw 2: white</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">n_white</span>(.),</span>
<span id="cb25-58"><a href="#cb25-58" aria-hidden="true" tabindex="-1"></a>         <span class="st">`</span><span class="at">draw 3: blue</span><span class="st">`</span>  <span class="ot">=</span> <span class="fu">n_blue</span>(.)) <span class="sc">%&gt;%</span></span>
<span id="cb25-59"><a href="#cb25-59" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="st">`</span><span class="at">ways to produce</span><span class="st">`</span> <span class="ot">=</span> <span class="st">`</span><span class="at">draw 1: blue</span><span class="st">`</span> <span class="sc">*</span> <span class="st">`</span><span class="at">draw 2: white</span><span class="st">`</span> <span class="sc">*</span> <span class="st">`</span><span class="at">draw 3: blue</span><span class="st">`</span>)</span>
<span id="cb25-60"><a href="#cb25-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-61"><a href="#cb25-61" aria-hidden="true" tabindex="-1"></a>t <span class="sc">%&gt;%</span>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span>
<span id="cb25-62"><a href="#cb25-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-63"><a href="#cb25-63" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-64"><a href="#cb25-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-65"><a href="#cb25-65" aria-hidden="true" tabindex="-1"></a>Next we get more data: another blue marble (already shown above), and there is a 'shortcut':</span>
<span id="cb25-66"><a href="#cb25-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-67"><a href="#cb25-67" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; You could start all over again, making a garden with four layers to trace out the paths compatible with the data sequence. Or you could take the previous counts---the prior counts---over conjectures (0, 3, 8, 9, 0) and just update them in light of the new observation. It turns out that these two methods are mathematically identical, as long as the new observation is logically independent of the previous observations</span></span>
<span id="cb25-68"><a href="#cb25-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-71"><a href="#cb25-71" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-72"><a href="#cb25-72" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: add_marble</span></span>
<span id="cb25-73"><a href="#cb25-73" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Ways; add a marble"</span></span>
<span id="cb25-74"><a href="#cb25-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-75"><a href="#cb25-75" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span></span>
<span id="cb25-76"><a href="#cb25-76" aria-hidden="true" tabindex="-1"></a>  t <span class="sc">%&gt;%</span></span>
<span id="cb25-77"><a href="#cb25-77" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="st">`</span><span class="at">previous counts</span><span class="st">`</span> <span class="ot">=</span> <span class="st">`</span><span class="at">ways to produce</span><span class="st">`</span>,</span>
<span id="cb25-78"><a href="#cb25-78" aria-hidden="true" tabindex="-1"></a>         <span class="st">`</span><span class="at">ways to produce</span><span class="st">`</span> <span class="ot">=</span> <span class="st">`</span><span class="at">draw 1: blue</span><span class="st">`</span>) <span class="sc">%&gt;%</span></span>
<span id="cb25-79"><a href="#cb25-79" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(p_1<span class="sc">:</span>p_4, <span class="st">`</span><span class="at">ways to produce</span><span class="st">`</span>, <span class="st">`</span><span class="at">previous counts</span><span class="st">`</span>) <span class="sc">%&gt;%</span></span>
<span id="cb25-80"><a href="#cb25-80" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="st">`</span><span class="at">new count</span><span class="st">`</span> <span class="ot">=</span> <span class="st">`</span><span class="at">ways to produce</span><span class="st">`</span> <span class="sc">*</span> <span class="st">`</span><span class="at">previous counts</span><span class="st">`</span>)</span>
<span id="cb25-81"><a href="#cb25-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-82"><a href="#cb25-82" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-83"><a href="#cb25-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-84"><a href="#cb25-84" aria-hidden="true" tabindex="-1"></a>We can also incorporate 'different data' -- e,g., certain amounts of 'prior counts of each bag in the factory' ... we simply multiply these in. 'You first draw a factory bag with a particular count ... which can occur XXX ways, and then you draw a blue marble from that bag, which can occur YYY ways, etc'.</span>
<span id="cb25-85"><a href="#cb25-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-88"><a href="#cb25-88" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-89"><a href="#cb25-89" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: factory_counts</span></span>
<span id="cb25-90"><a href="#cb25-90" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "add factory counts"</span></span>
<span id="cb25-91"><a href="#cb25-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-92"><a href="#cb25-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-93"><a href="#cb25-93" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> t <span class="sc">%&gt;%</span></span>
<span id="cb25-94"><a href="#cb25-94" aria-hidden="true" tabindex="-1"></a><span class="fu">select</span>(p_1<span class="sc">:</span>p_4, <span class="st">`</span><span class="at">new count</span><span class="st">`</span>) <span class="sc">%&gt;%</span></span>
<span id="cb25-95"><a href="#cb25-95" aria-hidden="true" tabindex="-1"></a><span class="fu">rename</span>(<span class="st">`</span><span class="at">prior count</span><span class="st">`</span> <span class="ot">=</span> <span class="st">`</span><span class="at">new count</span><span class="st">`</span>) <span class="sc">%&gt;%</span></span>
<span id="cb25-96"><a href="#cb25-96" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="st">`</span><span class="at">factory count</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">3</span><span class="sc">:</span><span class="dv">0</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb25-97"><a href="#cb25-97" aria-hidden="true" tabindex="-1"></a><span class="fu">mutate</span>(<span class="st">`</span><span class="at">new count</span><span class="st">`</span> <span class="ot">=</span> <span class="st">`</span><span class="at">prior count</span><span class="st">`</span> <span class="sc">*</span> <span class="st">`</span><span class="at">factory count</span><span class="st">`</span>)</span>
<span id="cb25-98"><a href="#cb25-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-99"><a href="#cb25-99" aria-hidden="true" tabindex="-1"></a>t <span class="sc">%&gt;%</span></span>
<span id="cb25-100"><a href="#cb25-100" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>()</span>
<span id="cb25-101"><a href="#cb25-101" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-102"><a href="#cb25-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-103"><a href="#cb25-103" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2.1.3. From counts to probability {.unnumbered}</span></span>
<span id="cb25-104"><a href="#cb25-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-105"><a href="#cb25-105" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/paste-D5765E47.png)</span></span>
<span id="cb25-106"><a href="#cb25-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-107"><a href="#cb25-107" aria-hidden="true" tabindex="-1"></a>Putting this all together to compute the plausibilities</span>
<span id="cb25-108"><a href="#cb25-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-109"><a href="#cb25-109" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb25-110"><a href="#cb25-110" aria-hidden="true" tabindex="-1"></a><span class="fu">## DR question: Is this with a flat prior</span></span>
<span id="cb25-111"><a href="#cb25-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-112"><a href="#cb25-112" aria-hidden="true" tabindex="-1"></a>Is this with a flat prior... starting with an equal probability of each bag type, or is 'plausibility' something different than the posterior?</span>
<span id="cb25-113"><a href="#cb25-113" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb25-114"><a href="#cb25-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-117"><a href="#cb25-117" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-118"><a href="#cb25-118" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: plausibilities</span></span>
<span id="cb25-119"><a href="#cb25-119" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "plausibilities"</span></span>
<span id="cb25-120"><a href="#cb25-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-121"><a href="#cb25-121" aria-hidden="true" tabindex="-1"></a>t <span class="sc">%&gt;%</span></span>
<span id="cb25-122"><a href="#cb25-122" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(p_1<span class="sc">:</span>p_4) <span class="sc">%&gt;%</span></span>
<span id="cb25-123"><a href="#cb25-123" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">p                      =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">by =</span> .<span class="dv">25</span>),</span>
<span id="cb25-124"><a href="#cb25-124" aria-hidden="true" tabindex="-1"></a>         <span class="st">`</span><span class="at">ways to produce data</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">0</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb25-125"><a href="#cb25-125" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">plausibility =</span> <span class="st">`</span><span class="at">ways to produce data</span><span class="st">`</span> <span class="sc">/</span> <span class="fu">sum</span>(<span class="st">`</span><span class="at">ways to produce data</span><span class="st">`</span>))</span>
<span id="cb25-126"><a href="#cb25-126" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-127"><a href="#cb25-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-128"><a href="#cb25-128" aria-hidden="true" tabindex="-1"></a><span class="fu">## 2.2. Building a model</span></span>
<span id="cb25-129"><a href="#cb25-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-130"><a href="#cb25-130" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Designing a simple Bayesian model benefits from a design loop with three steps. (1) Data story: Motivate the model by narrating how the data might arise. (2) Update: Educate your model by feeding it the data. (3) Evaluate: All statistical models require supervision, leading to model revision</span></span>
<span id="cb25-131"><a href="#cb25-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-132"><a href="#cb25-132" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb25-133"><a href="#cb25-133" aria-hidden="true" tabindex="-1"></a><span class="fu">## DR question</span></span>
<span id="cb25-134"><a href="#cb25-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-135"><a href="#cb25-135" aria-hidden="true" tabindex="-1"></a>How can we 'revise the model' without overfitting or otherwise cheating in some way that overstates the confidence we should have in our results?</span>
<span id="cb25-136"><a href="#cb25-136" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb25-137"><a href="#cb25-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-138"><a href="#cb25-138" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The maximum height of the curve increases with each sample, meaning that fewer values of $p$ amass more plausibility as the amount of evidence increases</span></span>
<span id="cb25-139"><a href="#cb25-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-140"><a href="#cb25-140" aria-hidden="true" tabindex="-1"></a>**Power of Bayesian inference in small-sample contexts**</span>
<span id="cb25-141"><a href="#cb25-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-142"><a href="#cb25-142" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Why? In non-Bayesian statistical inference, procedures are often justified by the method's behavior at very large sample sizes, so-called asymptotic behavior. As a result, performance at small samples sizes is questionable. In contrast, Bayesian estimates are valid for any sample size. This does not mean that more data isn't helpful---it certainly is. Rather, the estimates have a clear and valid interpretation, no matter the sample size. But the price for this power is dependency upon the initial plausibilities, the prior. If the prior is a bad one, then the resulting inference will be misleading.</span></span>
<span id="cb25-143"><a href="#cb25-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-144"><a href="#cb25-144" aria-hidden="true" tabindex="-1"></a>*DR note*: There are some frequentist/non-Bayesian procedures and tests that don't rely on large sample approximations; e.g., Fisher's exact test</span>
<span id="cb25-145"><a href="#cb25-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-146"><a href="#cb25-146" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2.2.1 - the 'globe tossing' data story {.unnumbered}</span></span>
<span id="cb25-147"><a href="#cb25-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-148"><a href="#cb25-148" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2.2.2 Bayesian updating {.unnumbered}</span></span>
<span id="cb25-149"><a href="#cb25-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-150"><a href="#cb25-150" aria-hidden="true" tabindex="-1"></a>Start with a particular sequence of data, accumulate trials and successes</span>
<span id="cb25-151"><a href="#cb25-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-154"><a href="#cb25-154" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-155"><a href="#cb25-155" aria-hidden="true" tabindex="-1"></a>(d <span class="ot">&lt;-</span></span>
<span id="cb25-156"><a href="#cb25-156" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tibble</span>(</span>
<span id="cb25-157"><a href="#cb25-157" aria-hidden="true" tabindex="-1"></a>      <span class="at">toss =</span> <span class="fu">c</span>(<span class="st">"w"</span>, <span class="st">"l"</span>, <span class="st">"w"</span>, <span class="st">"w"</span>, <span class="st">"w"</span>, <span class="st">"l"</span>, <span class="st">"w"</span>, <span class="st">"l"</span>, <span class="st">"w"</span>),</span>
<span id="cb25-158"><a href="#cb25-158" aria-hidden="true" tabindex="-1"></a>      <span class="at">n_trials =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>,</span>
<span id="cb25-159"><a href="#cb25-159" aria-hidden="true" tabindex="-1"></a><span class="at">n_success =</span> <span class="fu">cumsum</span>(toss <span class="sc">==</span> <span class="st">"w"</span>)</span>
<span id="cb25-160"><a href="#cb25-160" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb25-161"><a href="#cb25-161" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-162"><a href="#cb25-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-163"><a href="#cb25-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-164"><a href="#cb25-164" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-165"><a href="#cb25-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-166"><a href="#cb25-166" aria-hidden="true" tabindex="-1"></a>Next, we compute and plot the plausibility of every 'true share of water p' after observing the draws from the globe-tossing. We update this after each toss.</span>
<span id="cb25-167"><a href="#cb25-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-168"><a href="#cb25-168" aria-hidden="true" tabindex="-1"></a>OK I need to construct some data on this globe tossing first; I skipped this earlier</span>
<span id="cb25-169"><a href="#cb25-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-170"><a href="#cb25-170" aria-hidden="true" tabindex="-1"></a>Next we build the tibble plausibility/updating tibble.</span>
<span id="cb25-171"><a href="#cb25-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-172"><a href="#cb25-172" aria-hidden="true" tabindex="-1"></a>Going through the coding steps for my own benefit... First we expand the tibble to consider each of 50 possible <span class="in">`p_water`</span> values after each trial (toss).</span>
<span id="cb25-173"><a href="#cb25-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-176"><a href="#cb25-176" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-177"><a href="#cb25-177" aria-hidden="true" tabindex="-1"></a>sequence_length <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb25-178"><a href="#cb25-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-179"><a href="#cb25-179" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb25-180"><a href="#cb25-180" aria-hidden="true" tabindex="-1"></a>plaus_globe_updates <span class="ot">&lt;-</span></span>
<span id="cb25-181"><a href="#cb25-181" aria-hidden="true" tabindex="-1"></a>d <span class="sc">%&gt;%</span></span>
<span id="cb25-182"><a href="#cb25-182" aria-hidden="true" tabindex="-1"></a>  <span class="fu">expand</span>(<span class="fu">nesting</span>(n_trials, toss, n_success),</span>
<span id="cb25-183"><a href="#cb25-183" aria-hidden="true" tabindex="-1"></a>         <span class="at">p_water =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> sequence_length))</span>
<span id="cb25-184"><a href="#cb25-184" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-185"><a href="#cb25-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-186"><a href="#cb25-186" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-187"><a href="#cb25-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-188"><a href="#cb25-188" aria-hidden="true" tabindex="-1"></a>Next we create the 'lagged' columns (for ease of plotting the updating):</span>
<span id="cb25-189"><a href="#cb25-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-192"><a href="#cb25-192" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-193"><a href="#cb25-193" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: plaus_globe_updates</span></span>
<span id="cb25-194"><a href="#cb25-194" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "updating globe tossing - lags"</span></span>
<span id="cb25-195"><a href="#cb25-195" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb25-196"><a href="#cb25-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-197"><a href="#cb25-197" aria-hidden="true" tabindex="-1"></a>plaus_globe_updates <span class="sc">%&lt;&gt;%</span></span>
<span id="cb25-198"><a href="#cb25-198" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(p_water) <span class="sc">%&gt;%</span></span>
<span id="cb25-199"><a href="#cb25-199" aria-hidden="true" tabindex="-1"></a> <span class="co"># you can learn more about lagging here: https://www.rdocumentation.org/packages/stats/versions/3.5.1/topics/lag or here: https://dplyr.tidyverse.org/reference/lead-lag.html</span></span>
<span id="cb25-200"><a href="#cb25-200" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">lagged_n_trials  =</span> <span class="fu">lag</span>(n_trials,  <span class="at">k =</span> <span class="dv">1</span>),</span>
<span id="cb25-201"><a href="#cb25-201" aria-hidden="true" tabindex="-1"></a>         <span class="at">lagged_n_success =</span> <span class="fu">lag</span>(n_success, <span class="at">k =</span> <span class="dv">1</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb25-202"><a href="#cb25-202" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>()</span>
<span id="cb25-203"><a href="#cb25-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-204"><a href="#cb25-204" aria-hidden="true" tabindex="-1"></a>plaus_globe_updates[<span class="dv">95</span><span class="sc">:</span><span class="dv">105</span>,]</span>
<span id="cb25-205"><a href="#cb25-205" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-206"><a href="#cb25-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-207"><a href="#cb25-207" aria-hidden="true" tabindex="-1"></a>Next we start with a flat prior and, for each 'trial' ...</span>
<span id="cb25-208"><a href="#cb25-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-209"><a href="#cb25-209" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>compute the likelihood of the data (sucesses and trials) given each probability of water, according to the *binomial probability function*.</span>
<span id="cb25-210"><a href="#cb25-210" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>both with the previous 'lagged' data and adding the new data point</span>
<span id="cb25-211"><a href="#cb25-211" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>normalize each of these by dividing by the likelihood of the data that has arisen,</span>
<span id="cb25-212"><a href="#cb25-212" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>this yields the 'plausbility' of each probability of water . (I.e., the posterior?)</span>
<span id="cb25-213"><a href="#cb25-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-216"><a href="#cb25-216" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-217"><a href="#cb25-217" aria-hidden="true" tabindex="-1"></a>plaus_globe_updates <span class="sc">%&lt;&gt;%</span></span>
<span id="cb25-218"><a href="#cb25-218" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">prior  =</span> <span class="fu">ifelse</span>(n_trials <span class="sc">==</span> <span class="dv">1</span>, <span class="dv">1</span>, <span class="co">#DR: I adjusted this to =1 to avoid confusing it with a certainty that p=.5</span></span>
<span id="cb25-219"><a href="#cb25-219" aria-hidden="true" tabindex="-1"></a>          <span class="fu">dbinom</span>(</span>
<span id="cb25-220"><a href="#cb25-220" aria-hidden="true" tabindex="-1"></a>            <span class="at">x=</span> lagged_n_success,</span>
<span id="cb25-221"><a href="#cb25-221" aria-hidden="true" tabindex="-1"></a>            <span class="at">size =</span> lagged_n_trials,</span>
<span id="cb25-222"><a href="#cb25-222" aria-hidden="true" tabindex="-1"></a>            <span class="at">prob =</span> p_water)),</span>
<span id="cb25-223"><a href="#cb25-223" aria-hidden="true" tabindex="-1"></a>         <span class="at">likelihood =</span> <span class="fu">dbinom</span>(<span class="at">x  =</span> n_success,</span>
<span id="cb25-224"><a href="#cb25-224" aria-hidden="true" tabindex="-1"></a>                             <span class="at">size =</span> n_trials,</span>
<span id="cb25-225"><a href="#cb25-225" aria-hidden="true" tabindex="-1"></a>                             <span class="at">prob =</span> p_water),</span>
<span id="cb25-226"><a href="#cb25-226" aria-hidden="true" tabindex="-1"></a>         <span class="at">strip      =</span> <span class="fu">str_c</span>(<span class="st">"n = "</span>, n_trials)) <span class="sc">%&gt;%</span></span>
<span id="cb25-227"><a href="#cb25-227" aria-hidden="true" tabindex="-1"></a>  <span class="co"># the next three lines allow us to normalize the prior and the likelihood,</span></span>
<span id="cb25-228"><a href="#cb25-228" aria-hidden="true" tabindex="-1"></a>  <span class="co"># putting them both in a probability metric</span></span>
<span id="cb25-229"><a href="#cb25-229" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(n_trials) <span class="sc">%&gt;%</span></span>
<span id="cb25-230"><a href="#cb25-230" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">prior      =</span> prior      <span class="sc">/</span> <span class="fu">sum</span>(prior),</span>
<span id="cb25-231"><a href="#cb25-231" aria-hidden="true" tabindex="-1"></a>         <span class="at">likelihood =</span> likelihood <span class="sc">/</span> <span class="fu">sum</span>(likelihood))</span>
<span id="cb25-232"><a href="#cb25-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-233"><a href="#cb25-233" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-234"><a href="#cb25-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-235"><a href="#cb25-235" aria-hidden="true" tabindex="-1"></a>Plotting this:</span>
<span id="cb25-236"><a href="#cb25-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-237"><a href="#cb25-237" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, fig.width = 6, fig.height = 5}</span></span>
<span id="cb25-238"><a href="#cb25-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-239"><a href="#cb25-239" aria-hidden="true" tabindex="-1"></a>plaus_globe_updates <span class="sc">%&gt;%</span></span>
<span id="cb25-240"><a href="#cb25-240" aria-hidden="true" tabindex="-1"></a>  <span class="co"># filter(n_trials==5) %&gt;%</span></span>
<span id="cb25-241"><a href="#cb25-241" aria-hidden="true" tabindex="-1"></a>  <span class="co"># plot!</span></span>
<span id="cb25-242"><a href="#cb25-242" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> p_water)) <span class="sc">+</span></span>
<span id="cb25-243"><a href="#cb25-243" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> prior), <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb25-244"><a href="#cb25-244" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> likelihood)) <span class="sc">+</span></span>
<span id="cb25-245"><a href="#cb25-245" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="st">"proportion water"</span>, <span class="at">breaks =</span> <span class="fu">c</span>(<span class="dv">0</span>, .<span class="dv">5</span>, <span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb25-246"><a href="#cb25-246" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="st">"plausibility"</span>, <span class="at">breaks =</span> <span class="cn">NULL</span>) <span class="sc">+</span></span>
<span id="cb25-247"><a href="#cb25-247" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">panel.grid =</span> <span class="fu">element_blank</span>()) <span class="sc">+</span></span>
<span id="cb25-248"><a href="#cb25-248" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>strip, <span class="at">scales =</span> <span class="st">"free_y"</span>)</span>
<span id="cb25-249"><a href="#cb25-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-250"><a href="#cb25-250" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-251"><a href="#cb25-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-252"><a href="#cb25-252" aria-hidden="true" tabindex="-1"></a><span class="ot">[^small_large_worlds-1]</span></span>
<span id="cb25-253"><a href="#cb25-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-254"><a href="#cb25-254" aria-hidden="true" tabindex="-1"></a><span class="ot">[^small_large_worlds-1]: </span>DR note: although the plot looks smooth, I think this is only because we chose a small interval of probability ... 50 different probabilities. When I reduce it to 5 probabilities this gets choppy</span>
<span id="cb25-255"><a href="#cb25-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-256"><a href="#cb25-256" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb25-257"><a href="#cb25-257" aria-hidden="true" tabindex="-1"></a><span class="fu">## Other love letter notes on the above</span></span>
<span id="cb25-258"><a href="#cb25-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-259"><a href="#cb25-259" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; If it wasn't clear in the code, the dashed curves are normalized prior densities. The solid ones are normalized likelihoods. If you don't normalize (i.e., divide the density by the sum of the density), their respective heights don't match up with those in the text. Furthermore, it's the normalization that makes them directly comparable.</span></span>
<span id="cb25-260"><a href="#cb25-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-261"><a href="#cb25-261" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; To learn more about </span><span class="in">`dplyr::group_by()`</span><span class="at"> and its opposite </span><span class="in">`dplyr::ungroup()`</span><span class="at">, check out </span><span class="co">[</span><span class="ot">*R4DS*, Chapter 5</span><span class="co">](https://r4ds.had.co.nz/transform.html)</span><span class="at">. To learn about </span><span class="in">`tidyr::expand()`</span><span class="at">, go </span><span class="co">[</span><span class="ot">here</span><span class="co">](https://tidyr.tidyverse.org/reference/expand.html)</span><span class="at">.</span></span>
<span id="cb25-262"><a href="#cb25-262" aria-hidden="true" tabindex="-1"></a><span class="at">:::</span></span>
<span id="cb25-263"><a href="#cb25-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-264"><a href="#cb25-264" aria-hidden="true" tabindex="-1"></a><span class="fu">## 2.3. Components of the model</span></span>
<span id="cb25-265"><a href="#cb25-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-266"><a href="#cb25-266" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 1.  a likelihood function: "the number of ways each conjecture could produce an observation"</span></span>
<span id="cb25-267"><a href="#cb25-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-268"><a href="#cb25-268" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 2.  one or more parameters: "the accumulated number of ways each conjecture could produce the entire data"</span></span>
<span id="cb25-269"><a href="#cb25-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-270"><a href="#cb25-270" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3.  a prior: "the initial plausibility of each conjectured cause of the data"</span></span>
<span id="cb25-271"><a href="#cb25-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-272"><a href="#cb25-272" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb25-273"><a href="#cb25-273" aria-hidden="true" tabindex="-1"></a><span class="fu">## Coding tip: `dbinom`, `pbinom`, `rbinom`, etc</span></span>
<span id="cb25-274"><a href="#cb25-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-275"><a href="#cb25-275" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "d" in </span><span class="in">`dbinom`</span><span class="at"> stands for density. Functions named in this way almost always have corresponding partners that begin with "r" for random samples and that begin with "-p" for cumulative probabilities</span></span>
<span id="cb25-276"><a href="#cb25-276" aria-hidden="true" tabindex="-1"></a><span class="at">:::</span></span>
<span id="cb25-277"><a href="#cb25-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-278"><a href="#cb25-278" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The distributions we assign to the observed variables typically have their own variables.</span></span>
<span id="cb25-279"><a href="#cb25-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-280"><a href="#cb25-280" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb25-281"><a href="#cb25-281" aria-hidden="true" tabindex="-1"></a><span class="fu">## (Comparing frameworks) Rethinking: A central role for likelihood.</span></span>
<span id="cb25-282"><a href="#cb25-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-283"><a href="#cb25-283" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; A great deal of ink has been spilled focusing on how Bayesian and non-Bayesian data analyses differ. Focusing on differences is useful, but sometimes it distracts us from fundamental similarities. Notably, the most influential assumptions in both Bayesian and many non-Bayesian models are the distributions assigned to data, the likelihood functions. The likelihoods influence inference for every piece of data, and as sample size increases, the likelihood matters more and more. This helps to explain why Bayesian and non-Bayesian inferences are often so similar. If we had to explain Bayesian inference using only one aspect of it, we should describe likelihood, not priors.</span></span>
<span id="cb25-284"><a href="#cb25-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-285"><a href="#cb25-285" aria-hidden="true" tabindex="-1"></a>(DR: move this to our discussion of compring statistical frameworks?)</span>
<span id="cb25-286"><a href="#cb25-286" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb25-287"><a href="#cb25-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-288"><a href="#cb25-288" aria-hidden="true" tabindex="-1"></a><span class="fu">### What prior? {.unnumbered}</span></span>
<span id="cb25-289"><a href="#cb25-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-290"><a href="#cb25-290" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; So where do priors come from? They are both engineering assumptions, chosen to help the machine learn, and scientific assumptions, chosen to reflect what we know about a phenomenon. The flat prior in Figure 2.5 is very common, but it is hardly ever the best prior.</span></span>
<span id="cb25-291"><a href="#cb25-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-292"><a href="#cb25-292" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; There is a school of Bayesian inference that emphasizes choosing priors based upon the personal beliefs of the analyst. While this subjective Bayesian approach thrives in some statistics and philosophy and economics programs, it is rare in the sciences.</span></span>
<span id="cb25-293"><a href="#cb25-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-294"><a href="#cb25-294" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; If your goal is to lie with statistics, you'd be a fool to do it with priors, because such a lie would be easily uncovered. Better to use the more opaque machinery of the likelihood. Or better yet-don't actually take this advice!---massage the data, drop some "outliers," and otherwise engage in motivated data transformation</span></span>
<span id="cb25-295"><a href="#cb25-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-296"><a href="#cb25-296" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; because non-Bayesian procedures need to make choices that Bayesian ones do not, such as choice of estimator or likelihood penalty.</span></span>
<span id="cb25-297"><a href="#cb25-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-298"><a href="#cb25-298" aria-hidden="true" tabindex="-1"></a>*DR: I skip the construction of the 'multiply prior by likelihood to get posterior' graphs for now ...*</span>
<span id="cb25-299"><a href="#cb25-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-300"><a href="#cb25-300" aria-hidden="true" tabindex="-1"></a>*Below: flat, stepped, Laplace priors*</span>
<span id="cb25-301"><a href="#cb25-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-302"><a href="#cb25-302" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/paste-47A2FD04.png)</span></span>
<span id="cb25-303"><a href="#cb25-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-304"><a href="#cb25-304" aria-hidden="true" tabindex="-1"></a><span class="fu">## 2.4 'Making the model go'</span></span>
<span id="cb25-305"><a href="#cb25-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-306"><a href="#cb25-306" aria-hidden="true" tabindex="-1"></a>::: callout-important</span>
<span id="cb25-307"><a href="#cb25-307" aria-hidden="true" tabindex="-1"></a>DR: I think this section is particularly important. It's our first pass on 'how to actually do this stuff'. Reading group: I suggest we put some focus on it, maybe in the next session.</span>
<span id="cb25-308"><a href="#cb25-308" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb25-309"><a href="#cb25-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-310"><a href="#cb25-310" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2.4.1 Bayes theorem {.unnumbered}</span></span>
<span id="cb25-311"><a href="#cb25-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-312"><a href="#cb25-312" aria-hidden="true" tabindex="-1"></a>In word form:</span>
<span id="cb25-313"><a href="#cb25-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-314"><a href="#cb25-314" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Posterior (probability of any given value of $p$) =</span></span>
<span id="cb25-315"><a href="#cb25-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-316"><a href="#cb25-316" aria-hidden="true" tabindex="-1"></a>(Probability of the data <span class="sc">\[</span>given p<span class="sc">\]</span> $\times$ <span class="sc">\[</span>Prior probability of p<span class="sc">\]</span>) divided by the 'Average probability of the data'</span>
<span id="cb25-317"><a href="#cb25-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-318"><a href="#cb25-318" aria-hidden="true" tabindex="-1"></a>I.e., (in my own words) 'how likely is this data *and* the particular parameter p' divided by 'the probability of this data overall' (given any p, with the probability of each p following the prior)</span>
<span id="cb25-319"><a href="#cb25-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-320"><a href="#cb25-320" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 'average probability of the data'</span></span>
<span id="cb25-321"><a href="#cb25-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-322"><a href="#cb25-322" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Averaged over what? Averaged over the prior. It's job is just to standardize the posterior, to ensure it sums (integrates) to one. In mathematical form: Pr(W, L) = E</span></span>
<span id="cb25-323"><a href="#cb25-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-324"><a href="#cb25-324" aria-hidden="true" tabindex="-1"></a>Probability of one Water followed by one Land:</span>
<span id="cb25-325"><a href="#cb25-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-326"><a href="#cb25-326" aria-hidden="true" tabindex="-1"></a>$$Pr(W, L|p)$$ $$=E\Big( Pr(W, L|p) Big)$$</span>
<span id="cb25-327"><a href="#cb25-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-328"><a href="#cb25-328" aria-hidden="true" tabindex="-1"></a>$$= \int  Pr(W,L|p) Pr(p)dp $$</span>
<span id="cb25-329"><a href="#cb25-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-330"><a href="#cb25-330" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The key lesson is that the posterior is proportional to the product of the prior and the probability of the data </span><span class="sc">\[</span><span class="at">given the prior</span><span class="sc">\]</span><span class="at">. Why? Because for each specific value of p, the number of paths through the garden of forking data is the product of the prior number of paths and the new number of paths. A flat prior constructs a posterior that is simply proportional to the likelihood</span></span>
<span id="cb25-331"><a href="#cb25-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-332"><a href="#cb25-332" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb25-333"><a href="#cb25-333" aria-hidden="true" tabindex="-1"></a><span class="fu">## "Bayesian data analysis isn't about Bayes' theorem"</span></span>
<span id="cb25-334"><a href="#cb25-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-335"><a href="#cb25-335" aria-hidden="true" tabindex="-1"></a>Dissing the 'HIV test false positive' thing</span>
<span id="cb25-336"><a href="#cb25-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-337"><a href="#cb25-337" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Inference under any probability concept will eventually make use of Bayes' theorem. Common introductory examples of 'Bayesian' analysis using HIV and DNA testing are not uniquely Bayesian</span></span>
<span id="cb25-338"><a href="#cb25-338" aria-hidden="true" tabindex="-1"></a><span class="at">:::</span></span>
<span id="cb25-339"><a href="#cb25-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-340"><a href="#cb25-340" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Numerical techniques for computing posterior distributions: (1) Grid approximation (2) Quadratic approximation (3) Markov chain Monte Carlo (MCMC)</span></span>
<span id="cb25-341"><a href="#cb25-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-342"><a href="#cb25-342" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Grid approximation: Basically mechanical Bayesian updating of the probability of a parameter value being in a range, dividing up the space of possible parameters into different ranges. (And then smoothing?)</span></span>
<span id="cb25-343"><a href="#cb25-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-344"><a href="#cb25-344" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ... achieve an excellent approximation of the continuous posterior distribution by considering only a finite grid of parameter values</span></span>
<span id="cb25-345"><a href="#cb25-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-346"><a href="#cb25-346" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; in most of your real modeling, grid approximation isn't practical. The reason is that it scales very poorly, as the number of parameters increases</span></span>
<span id="cb25-347"><a href="#cb25-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-348"><a href="#cb25-348" aria-hidden="true" tabindex="-1"></a><span class="fu">### Grid approximation</span></span>
<span id="cb25-349"><a href="#cb25-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-350"><a href="#cb25-350" aria-hidden="true" tabindex="-1"></a>The code below makes a data frame with</span>
<span id="cb25-351"><a href="#cb25-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-352"><a href="#cb25-352" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>20 Probabilities between 0 and 1</span>
<span id="cb25-353"><a href="#cb25-353" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>A 'flat' density (=1 everywhere) for these</span>
<span id="cb25-354"><a href="#cb25-354" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>The likelihood of "6 waters in 9" (the data) given each of the 20 probabilities (binomial distribution)</span>
<span id="cb25-355"><a href="#cb25-355" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>This likelihood $\times$ the prior for each <span class="in">`p_water`</span>.</span>
<span id="cb25-356"><a href="#cb25-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-357"><a href="#cb25-357" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Rem: this is likelihood of a particular <span class="in">`p_water`</span> *and* the observed data given that <span class="in">`p_water`</span></span>
<span id="cb25-358"><a href="#cb25-358" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Given the flat prior it is simply the latter</span>
<span id="cb25-359"><a href="#cb25-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-360"><a href="#cb25-360" aria-hidden="true" tabindex="-1"></a><span class="ss">5.  </span>Standardizing this by dividing by the probability of the data observed</span>
<span id="cb25-361"><a href="#cb25-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-364"><a href="#cb25-364" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-365"><a href="#cb25-365" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: grid_approx_calcs</span></span>
<span id="cb25-366"><a href="#cb25-366" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Grid, computing posteriors"</span></span>
<span id="cb25-367"><a href="#cb25-367" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb25-368"><a href="#cb25-368" aria-hidden="true" tabindex="-1"></a>  d <span class="ot">&lt;-</span></span>
<span id="cb25-369"><a href="#cb25-369" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tibble</span>(<span class="at">p_grid =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">20</span>),      <span class="co"># define grid</span></span>
<span id="cb25-370"><a href="#cb25-370" aria-hidden="true" tabindex="-1"></a>           <span class="at">prior  =</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span>                                       <span class="co"># define prior</span></span>
<span id="cb25-371"><a href="#cb25-371" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">likelihood =</span> <span class="fu">dbinom</span>(<span class="dv">6</span>, <span class="at">size =</span> <span class="dv">9</span>, <span class="at">prob =</span> p_grid)) <span class="sc">%&gt;%</span>  <span class="co"># compute likelihood at each value in grid</span></span>
<span id="cb25-372"><a href="#cb25-372" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">unstd_posterior =</span> likelihood <span class="sc">*</span> prior) <span class="sc">%&gt;%</span>             <span class="co"># compute product of likelihood and prior</span></span>
<span id="cb25-373"><a href="#cb25-373" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">posterior =</span> unstd_posterior <span class="sc">/</span> <span class="fu">sum</span>(unstd_posterior))   <span class="co"># standardize the posterior, so it sums to 1</span></span>
<span id="cb25-374"><a href="#cb25-374" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-375"><a href="#cb25-375" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-376"><a href="#cb25-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-377"><a href="#cb25-377" aria-hidden="true" tabindex="-1"></a>We then plot the posterior probabilities of each <span class="in">`p_water`</span>:</span>
<span id="cb25-378"><a href="#cb25-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-381"><a href="#cb25-381" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-382"><a href="#cb25-382" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb25-383"><a href="#cb25-383" aria-hidden="true" tabindex="-1"></a>  p1 <span class="ot">&lt;-</span></span>
<span id="cb25-384"><a href="#cb25-384" aria-hidden="true" tabindex="-1"></a>  d <span class="sc">%&gt;%</span> </span>
<span id="cb25-385"><a href="#cb25-385" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> p_grid, <span class="at">y =</span> posterior)) <span class="sc">+</span></span>
<span id="cb25-386"><a href="#cb25-386" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb25-387"><a href="#cb25-387" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb25-388"><a href="#cb25-388" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">subtitle =</span> <span class="st">"20 points"</span>,</span>
<span id="cb25-389"><a href="#cb25-389" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"probability of water"</span>,</span>
<span id="cb25-390"><a href="#cb25-390" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"posterior probability"</span>) <span class="sc">+</span></span>
<span id="cb25-391"><a href="#cb25-391" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">panel.grid =</span> <span class="fu">element_blank</span>())</span>
<span id="cb25-392"><a href="#cb25-392" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-393"><a href="#cb25-393" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-394"><a href="#cb25-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-395"><a href="#cb25-395" aria-hidden="true" tabindex="-1"></a><span class="fu">### Quadratic approximation (summary) {.unnumbered}</span></span>
<span id="cb25-396"><a href="#cb25-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-397"><a href="#cb25-397" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Under quite general conditions, the region near the peak of the posterior distribution will be nearly Gaussian-or "normal"---in shape. This means the posterior distribution can be usefully approximated by a Gaussian distribution. A Gaussian distribution is convenient, because it can be completely described by only two numbers: the location of its center (mean) and its spread (variance)</span></span>
<span id="cb25-398"><a href="#cb25-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-399"><a href="#cb25-399" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; logarithm of a Gaussian distribution forms a parabola. And a parabola is a quadratic function</span></span>
<span id="cb25-400"><a href="#cb25-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-401"><a href="#cb25-401" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; For many of the most common procedures in applied statistics-linear regression, for example---the approximation works very well</span></span>
<span id="cb25-402"><a href="#cb25-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-403"><a href="#cb25-403" aria-hidden="true" tabindex="-1"></a>**Stepping through this**</span>
<span id="cb25-404"><a href="#cb25-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-405"><a href="#cb25-405" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; (1) Find the posterior mode</span></span>
<span id="cb25-406"><a href="#cb25-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-407"><a href="#cb25-407" aria-hidden="true" tabindex="-1"></a>Some optimization algorithm, a procedure that virtually "climbs" the posterior distribution</span>
<span id="cb25-408"><a href="#cb25-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-409"><a href="#cb25-409" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; (2) estimate the curvature near the peak. This curvature is sufficient to compute a quadratic approximation of the entire posterior distribution. In some cases, these calculations can be done analytically, but...</span></span>
<span id="cb25-410"><a href="#cb25-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-411"><a href="#cb25-411" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb25-412"><a href="#cb25-412" aria-hidden="true" tabindex="-1"></a><span class="fu">## DR question</span></span>
<span id="cb25-413"><a href="#cb25-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-414"><a href="#cb25-414" aria-hidden="true" tabindex="-1"></a>But how does it do this estimate of the curvature? Does it come out of many simulations, or the optimizing hill climbing thing, or??</span>
<span id="cb25-415"><a href="#cb25-415" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb25-416"><a href="#cb25-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-417"><a href="#cb25-417" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb25-418"><a href="#cb25-418" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Hession and quadratic approximation</span></span>
<span id="cb25-419"><a href="#cb25-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-420"><a href="#cb25-420" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Hessian is a square matrix of second derivatives. It is used for many purposes in mathematics, but in the quadratic approximation it is second derivatives of the log of posterior probability with respect to the parameters. It turns out that these derivatives are sufficient to describe a Gaussian distribution, because the logarithm of a Gaussian distribution is just a parabola. Parabolas have no derivatives beyond the second</span></span>
<span id="cb25-421"><a href="#cb25-421" aria-hidden="true" tabindex="-1"></a><span class="at">:::</span></span>
<span id="cb25-422"><a href="#cb25-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-423"><a href="#cb25-423" aria-hidden="true" tabindex="-1"></a>Applying the quadratic approximation to the globe tossing data with <span class="in">`rethinking::map()`</span>.</span>
<span id="cb25-424"><a href="#cb25-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-425"><a href="#cb25-425" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb25-426"><a href="#cb25-426" aria-hidden="true" tabindex="-1"></a><span class="fu">## `rethinking::map()` coding notes</span></span>
<span id="cb25-427"><a href="#cb25-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-428"><a href="#cb25-428" aria-hidden="true" tabindex="-1"></a>Here the 'love letter' uses McElreath's rethinking package instead of brms ... I guess it's because quadratic approximation is more for learning than for real use?</span>
<span id="cb25-429"><a href="#cb25-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-430"><a href="#cb25-430" aria-hidden="true" tabindex="-1"></a><span class="in">`quap`</span> and <span class="in">`map`</span>:</span>
<span id="cb25-431"><a href="#cb25-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-432"><a href="#cb25-432" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>"Find mode of posterior distribution for arbitrary fixed effect models"</span>
<span id="cb25-433"><a href="#cb25-433" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>"and then produce an approximation of the full posterior using the quadratic curvature at the mode."</span>
<span id="cb25-434"><a href="#cb25-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-435"><a href="#cb25-435" aria-hidden="true" tabindex="-1"></a>(This has nothing to do with <span class="in">`purrr::map`</span> iteration package thing.)</span>
<span id="cb25-436"><a href="#cb25-436" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb25-437"><a href="#cb25-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-440"><a href="#cb25-440" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-441"><a href="#cb25-441" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: quap_globetoss</span></span>
<span id="cb25-442"><a href="#cb25-442" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "quap with `rethinking::map`"</span></span>
<span id="cb25-443"><a href="#cb25-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-444"><a href="#cb25-444" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rethinking)</span>
<span id="cb25-445"><a href="#cb25-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-446"><a href="#cb25-446" aria-hidden="true" tabindex="-1"></a>globe_qa <span class="ot">&lt;-</span></span>
<span id="cb25-447"><a href="#cb25-447" aria-hidden="true" tabindex="-1"></a>  rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb25-448"><a href="#cb25-448" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb25-449"><a href="#cb25-449" aria-hidden="true" tabindex="-1"></a>      w <span class="sc">~</span> <span class="fu">dbinom</span>(<span class="dv">9</span>, p),  <span class="co"># binomial likelihood</span></span>
<span id="cb25-450"><a href="#cb25-450" aria-hidden="true" tabindex="-1"></a>      p <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">1</span>)    <span class="co"># uniform prior</span></span>
<span id="cb25-451"><a href="#cb25-451" aria-hidden="true" tabindex="-1"></a>    ), </span>
<span id="cb25-452"><a href="#cb25-452" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> <span class="fu">list</span>(<span class="at">w =</span> <span class="dv">6</span>))</span>
<span id="cb25-453"><a href="#cb25-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-454"><a href="#cb25-454" aria-hidden="true" tabindex="-1"></a><span class="co"># display summary of quadratic approximation</span></span>
<span id="cb25-455"><a href="#cb25-455" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(globe_qa)</span>
<span id="cb25-456"><a href="#cb25-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-457"><a href="#cb25-457" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-458"><a href="#cb25-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-459"><a href="#cb25-459" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb25-460"><a href="#cb25-460" aria-hidden="true" tabindex="-1"></a><span class="fu">## Syntax of above code</span></span>
<span id="cb25-461"><a href="#cb25-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-462"><a href="#cb25-462" aria-hidden="true" tabindex="-1"></a><span class="in">`alist`</span> is a way of specifying a list (iirc) that preserves it as a 'name of the math we want to compute on' rather than it actually expanding/evaluating it.</span>
<span id="cb25-463"><a href="#cb25-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-464"><a href="#cb25-464" aria-hidden="true" tabindex="-1"></a><span class="in">`precis`</span> is just a handy tool for seeing data .</span>
<span id="cb25-465"><a href="#cb25-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-466"><a href="#cb25-466" aria-hidden="true" tabindex="-1"></a>The output <span class="in">`globe_qa`</span> contains a lot of content (try <span class="in">`str(globe_qa)`</span>).</span>
<span id="cb25-467"><a href="#cb25-467" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb25-468"><a href="#cb25-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-469"><a href="#cb25-469" aria-hidden="true" tabindex="-1"></a>Above, the <span class="in">`precis`</span> gives us some summary statistics on the estimated posterior.</span>
<span id="cb25-470"><a href="#cb25-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-471"><a href="#cb25-471" aria-hidden="true" tabindex="-1"></a>*DR: I will skip the code that produces the figure below showing how `quap` updates with more data, for now*.</span>
<span id="cb25-472"><a href="#cb25-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-473"><a href="#cb25-473" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/paste-B716044F.png)</span></span>
<span id="cb25-474"><a href="#cb25-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-475"><a href="#cb25-475" aria-hidden="true" tabindex="-1"></a><span class="fu">### Markov chain Monte Carlo (incomplete explanation) {.unnumbered}</span></span>
<span id="cb25-476"><a href="#cb25-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-477"><a href="#cb25-477" aria-hidden="true" tabindex="-1"></a>DR:MCMC is not fully explained here. Somehow you 'sample from the posterior (over the parameter values)" and do some magic. Maybe weighting these by how consistent they are with the prior and the data?</span>
<span id="cb25-478"><a href="#cb25-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-479"><a href="#cb25-479" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Grid approximation routinely fails here, because it just takes too long---the Sun will go dark before your computer finishes the grid. Special forms of quadratic approximation might work, if everything is just right. But commonly, something is not just right. Furthermore, multilevel models do not always allow us to write down a single, unified function for the posterior distribution. This means that the function to maximize (when finding the MAP) is not known, but must be computed in pieces</span></span>
<span id="cb25-480"><a href="#cb25-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-481"><a href="#cb25-481" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; is fair to say that MCMC is largely responsible for the insurgence of Bayesian data analysis that began in the 1990s.</span></span>
<span id="cb25-482"><a href="#cb25-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-483"><a href="#cb25-483" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; highly non-obvious strategy. Instead of attempting to compute or approximate the posterior distribution directly, MCMC techniques merely draw samples from the posterior. You end up with a collection of parameter values, and the frequencies of these values correspond to the posterior plausibilities. You can then build a picture of the posterior from the histogram of these samples. We nearly always work directly with these samples, rather than first constructing some mathematical estimate from them</span></span>
<span id="cb25-484"><a href="#cb25-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-485"><a href="#cb25-485" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; , a working Markov chain for the globe tossing model does not require much code</span></span>
<span id="cb25-486"><a href="#cb25-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-487"><a href="#cb25-487" aria-hidden="true" tabindex="-1"></a>He starts with $p=.5$, considers the likelihood of the data under this probability, adjusts p.</span>
<span id="cb25-488"><a href="#cb25-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-489"><a href="#cb25-489" aria-hidden="true" tabindex="-1"></a>\</span>
<span id="cb25-490"><a href="#cb25-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-491"><a href="#cb25-491" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb25-492"><a href="#cb25-492" aria-hidden="true" tabindex="-1"></a><span class="fu">## DR question</span></span>
<span id="cb25-493"><a href="#cb25-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-494"><a href="#cb25-494" aria-hidden="true" tabindex="-1"></a>I don't see how this MCMC works; anyone have more insight? And where does the prior come in here?)</span>
<span id="cb25-495"><a href="#cb25-495" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb25-496"><a href="#cb25-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-497"><a href="#cb25-497" aria-hidden="true" tabindex="-1"></a>\</span>
<span id="cb25-498"><a href="#cb25-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-499"><a href="#cb25-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-500"><a href="#cb25-500" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Kurz: Markov chain Monte Carlo {-}</span></span>
<span id="cb25-501"><a href="#cb25-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-502"><a href="#cb25-502" aria-hidden="true" tabindex="-1"></a>Bringing in <span class="in">`brms`</span> </span>
<span id="cb25-503"><a href="#cb25-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-504"><a href="#cb25-504" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, warning = F, message = F}</span></span>
<span id="cb25-505"><a href="#cb25-505" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(brms)</span>
<span id="cb25-506"><a href="#cb25-506" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-507"><a href="#cb25-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-508"><a href="#cb25-508" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Here re-fit the last model from above, the one for which $w = 24$ and $n = 36$.</span></span>
<span id="cb25-509"><a href="#cb25-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-510"><a href="#cb25-510" aria-hidden="true" tabindex="-1"></a><span class="in">```{r b2.01}</span></span>
<span id="cb25-511"><a href="#cb25-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-512"><a href="#cb25-512" aria-hidden="true" tabindex="-1"></a>b2<span class="fl">.1</span> <span class="ot">&lt;-</span></span>
<span id="cb25-513"><a href="#cb25-513" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span>(<span class="at">data =</span> <span class="fu">list</span>(<span class="at">w =</span> <span class="dv">24</span>), </span>
<span id="cb25-514"><a href="#cb25-514" aria-hidden="true" tabindex="-1"></a>      <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">"identity"</span>),</span>
<span id="cb25-515"><a href="#cb25-515" aria-hidden="true" tabindex="-1"></a>      w <span class="sc">|</span> <span class="fu">trials</span>(<span class="dv">36</span>) <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb25-516"><a href="#cb25-516" aria-hidden="true" tabindex="-1"></a>      <span class="fu">prior</span>(<span class="fu">beta</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb25-517"><a href="#cb25-517" aria-hidden="true" tabindex="-1"></a>      <span class="at">iter =</span> <span class="dv">4000</span>, <span class="at">warmup =</span> <span class="dv">1000</span>,</span>
<span id="cb25-518"><a href="#cb25-518" aria-hidden="true" tabindex="-1"></a>      <span class="at">control =</span> <span class="fu">list</span>(<span class="at">adapt_delta =</span> .<span class="dv">95</span>),</span>
<span id="cb25-519"><a href="#cb25-519" aria-hidden="true" tabindex="-1"></a>      <span class="at">seed =</span> <span class="dv">2</span>,</span>
<span id="cb25-520"><a href="#cb25-520" aria-hidden="true" tabindex="-1"></a>      <span class="at">file =</span> <span class="st">"b02.01"</span>)</span>
<span id="cb25-521"><a href="#cb25-521" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-522"><a href="#cb25-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-523"><a href="#cb25-523" aria-hidden="true" tabindex="-1"></a>*DR: Not sure why we save a file here*</span>
<span id="cb25-524"><a href="#cb25-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-525"><a href="#cb25-525" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The model output from brms looks like so.</span></span>
<span id="cb25-526"><a href="#cb25-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-529"><a href="#cb25-529" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-530"><a href="#cb25-530" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(b2<span class="fl">.1</span>)</span>
<span id="cb25-531"><a href="#cb25-531" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-532"><a href="#cb25-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-533"><a href="#cb25-533" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; There's a lot going on in that output, which we'll start to clarify in Chapter 4. For now, focus on the 'Intercept' line. As we'll also learn in Chapter 4, the intercept of a regression model with no predictors is the same as its mean. In the special case of a model using the binomial likelihood, the mean is the probability of a 1 in a given trial, $\theta$.</span></span>
<span id="cb25-534"><a href="#cb25-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-535"><a href="#cb25-535" aria-hidden="true" tabindex="-1"></a>Let's plot the results of our model and compare them with those from <span class="in">`rethinking::map()`</span>, above.</span>
<span id="cb25-536"><a href="#cb25-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-537"><a href="#cb25-537" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, fig.width = 3, fig.height = 2.75}</span></span>
<span id="cb25-538"><a href="#cb25-538" aria-hidden="true" tabindex="-1"></a><span class="fu">posterior_samples</span>(b2<span class="fl">.1</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb25-539"><a href="#cb25-539" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">n =</span> <span class="st">"n = 36"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb25-540"><a href="#cb25-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-541"><a href="#cb25-541" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> b_Intercept)) <span class="sc">+</span></span>
<span id="cb25-542"><a href="#cb25-542" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">fill =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb25-543"><a href="#cb25-543" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="st">"proportion water"</span>, <span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb25-544"><a href="#cb25-544" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">panel.grid =</span> <span class="fu">element_blank</span>()) <span class="sc">+</span></span>
<span id="cb25-545"><a href="#cb25-545" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>n)</span>
<span id="cb25-546"><a href="#cb25-546" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-547"><a href="#cb25-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-548"><a href="#cb25-548" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; If you're still confused. Cool. This is just a preview. We'll start walking through fitting models in brms in </span><span class="sc">\[</span><span class="at">Chapter 4</span><span class="sc">\]\[</span><span class="at">A Gaussian model of height</span><span class="sc">\]</span><span class="at"> and we'll learn a lot about regression with the binomial likelihood in </span><span class="sc">\[</span><span class="at">Chapter 10</span><span class="sc">\]\[</span><span class="at">Counting and Classification</span><span class="sc">\]</span><span class="at">.</span></span>
<span id="cb25-549"><a href="#cb25-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-550"><a href="#cb25-550" aria-hidden="true" tabindex="-1"></a><span class="fu">### Practice questions {.unnumbered}</span></span>
<span id="cb25-551"><a href="#cb25-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-552"><a href="#cb25-552" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The target of inference in Bayesian inference is a posterior probability distribution. Posterior probabilities state the relative numbers of ways each conjectured cause of the data could have produced the data</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>