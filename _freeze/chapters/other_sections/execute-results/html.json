{
  "hash": "a8d2f760694dd0a5e1e981107d7d0ffe",
  "result": {
    "markdown": "# Other suggested sections\n\n## 'Conjoint analysis' \n\nSee end of [this Slack thread](https://rethinkpriorities.slack.com/archives/G01962YABHB/p1670240321964009)\n\n\n## (Open and robust science: RP attitudes, discussions, resources) {#opensci}\n\nIntegrate from:\n\n[Reinstein discussions here](https://daaronr.github.io/metrics_discussion/robust-diag.html)\n\nCode to do [Robustness checks as a 'specification chart'](https://github.com/ArielOrtizBobea/spec_chart), and sensitivity analysis\n\nSource: https://pbs.twimg.com/media/ESyDHGjUYAYHfva?format=jpg&name=medium\n\n## (Meta-analysis) {#meta}\n\nIncorporate and consolidate from [Reinsteins meta notes](https://daaronr.github.io/metrics_discussion/metaanalysis.html) and more\n\n### Relates to 'aggregating expert judgment' {-}\n\nTesting out the `AggreCAT` package on the ACX prediction contest\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Install aggreCAT\"}\ninstall.packages(\"devtools\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nInstalling devtools [2.4.5] ...\n\tOK [linked cache]\n```\n:::\n\n```{.r .cell-code  code-summary=\"Install aggreCAT\"}\n#install.packages(\"sessioninfo\", dependencies = TRUE)\n\ndevtools::install_github(\"metamelb-repliCATS/aggreCAT\")\n#Note: this failed initially because dependent packages needed updating.  `update.packages()` nay solve it. Nope, it didn't but all sorts of errors in that update\n\nlibrary(aggreCAT)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"input_acx_prediction_data\"}\nacx <- read_csv(here(\"sample_data\", \"acx_2023blindmode_predictions.csv\"))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in read_csv(here(\"sample_data\", \"acx_2023blindmode_predictions.csv\")): could not find function \"read_csv\"\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"identify my own predictions\"}\nacx  %<>%  mutate(\n  d_reinstein =  ifelse(\n    `@1.WillVladimirPutinbePresidentofRussia`==82 & `@2.WillUkrainecontrolthecityofSevastopol`==54, TRUE, FALSE)\n)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in acx %<>% mutate(d_reinstein = ifelse(`@1.WillVladimirPutinbePresidentofRussia` == : could not find function \"%<>%\"\n```\n:::\n:::\n\n\n\nWhat can `aggreCAT` do for us? \n\n\nFirst testing with their built-in data\n\n> Below we demonstrate how to use the most simple commonly implemented aggregation method ArMean, which takes the arithmetic mean of participant Best Estimates. We first use a small subset of 5 participants for a single claim, 28\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(data_ratings)\nset.seed(1234)\n\nparticipant_subset <- data_ratings %>% #just 5 users with names\n  distinct(user_name) %>%\n  sample_n(5) %>%\n  mutate(participant_name = paste(\"participant\", rep(1:n()))) #numbers rather than id codenames\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in mutate(., participant_name = paste(\"participant\", rep(1:n()))): could not find function \"mutate\"\n```\n:::\n\n```{.r .cell-code}\nsingle_claim <- data_ratings %>% \n  filter(paper_id == \"28\") %>% #all data on a single claim\n  right_join(participant_subset, by = \"user_name\") #join to the above 5 users (keeping only these 5)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in right_join(., participant_subset, by = \"user_name\"): could not find function \"right_join\"\n```\n:::\n\n```{.r .cell-code}\n#note this stat only uses the rows with element == `three_point_best`\nsingle_claim %>% \n  filter(element == \"three_point_best\") %>% \nAverageWAgg(expert_judgements = ., \n            type = \"ArMean\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in as.ts(x): object 'single_claim' not found\n```\n:::\n:::\n\nCan we do similar across multiple claims with this package?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_claims <- data_ratings %>% \n  right_join(participant_subset, by = \"user_name\")   #join to the above 5 users (keeping only these 5) \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in right_join(., participant_subset, by = \"user_name\"): could not find function \"right_join\"\n```\n:::\n\n```{.r .cell-code}\nall_claims %>% \n filter(element == \"three_point_best\") %>% \nAverageWAgg(expert_judgements = ., \n            type = \"ArMean\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in as.ts(x): object 'all_claims' not found\n```\n:::\n:::\n\n\nThis seems to work, at least with the data structured as they have it. Now what if we want multiple aggregation methods?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthree_aggregations <- purrr::map_dfr(.x = list(AverageWAgg, IntervalWAgg, ShiftingWAgg),\n                                .f = ~ .x(data_ratings))\n\nthree_aggregations %>%  tabyl(method)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in tabyl(., method): could not find function \"tabyl\"\n```\n:::\n:::\n\n\nNow let's see what can be done with our ACX dataset. As they don't ask for CIs, I'd either have to estimate these arbitrarily (e.g., make them larger for people with less experience), or only use a subset of their measures.  First I'll check which ones might work, using *their* data for all aggregations (with baseline settings for each)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_aggsOK <- list(AverageWAgg,  IntervalWAgg, ShiftingWAgg, ExtremisationWAgg)\n\nall_aggs <- list(LinearWAgg, AverageWAgg, BayesianWAgg, IntervalWAgg, ShiftingWAgg, ReasoningWAgg, DistributionWAgg, ExtremisationWAgg)\n\n\nthree_aggs <- list(LinearWAgg, AverageWAgg, BayesianWAgg)\n\n\nall_claims %>% \n filter(element == \"three_point_best\") %>% \n  purrr::map_dfr(.x = all_aggsOK,\n                                .f = ~ .x(data_ratings)) %>%\n  tabsums(cs, method)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in tabsums(., cs, method): could not find function \"tabsums\"\n```\n:::\n:::\n\nAll of the aggregators  seemed computable even without having elements other than 'three_point_best' What's going on here? E.g,. `IntervalWAgg` says 'the weights are dependent on the lower and upper bounds of three-point elicitation' ... but I left those out. 'ShiftingWAgg' is meant to depend on discussion; but here I have no indicators of that. Yet still, these all seem to come up with different means. `BetaARMean` which is meant to do some extremisation wotks rather strangely; shifting everything to 1, apparently.\n\n\nFocusing in on some key interesting methods.\n\nI've been told 'Geometric Mean' is good in these sorts of situations\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_ratings %>% \n filter(element == \"three_point_best\") %>% \nAverageWAgg(expert_judgements = ., \n            type = \"GeoMean\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in filter(., element == \"three_point_best\"): object 'element' not found\n```\n:::\n:::\n\n\n\n`LinearWAgg` seems interesting, either suppliying some sort of weights by `Participant` (e.g., downweight those who haven't done forecasting), or with the supplied `GranWAgg` -- \"granularity of best estimates\"\n\nLet's move to trying to use these on the ACX data. First I adjust the data to make it more compatible with the aggreCAT package.\n\n\n::: {.callout-note collapse=\"true\"}\n## Note -- it cannot deal with NAs:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_ratings2 <- data_ratings\ndata_ratings2[4,6] <- NA_real_\n\ndata_ratings2 %>% \nAverageWAgg(expert_judgements = ., \n            type = \"GeoMean\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in `preprocess_judgements()`:\n! NAs Found in Values\n```\n:::\n:::\n\n::: \n\n\n\nUpweights and downweighting people -- ad-hoc\n\nNow, I have little time left, so I'll come up with some ad-hoc weights. We have some idea of how different characteristics predicted success in previous prediction contests. But how should we map those into weights? I'm not sure, and it would take me some time to figure this out. \n\nI guess I will do something lame and ad-hoc. \n\nEveryone starts out with weight 1. \n\n1. Anyone who has no forecasting experience is downweighted fivefold (x0.2),\n2. Superforecasters are upweighted 20x\n3. SAT math uprated if above average (unless already a superforecaster)\n4. PHd upweighted 1.5x\n5. Downweight x 0.1 if you put 98+ or lt 4% chance of Putin being in power\n6. Downweight by quantile of share of 'exact 50% predictions' (up to about 90% downweighting)\n\n\nAlso, replace all '50% predictions' with the arithmetic average  (done later)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get column names starting with \"@\"\npred_cols <- colnames(acx)[startsWith(colnames(acx), \"@\")]\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in is.data.frame(x): object 'acx' not found\n```\n:::\n\n```{.r .cell-code}\nacx_for_ag_wts <- acx \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'acx' not found\n```\n:::\n\n```{.r .cell-code}\nacx_for_ag_wts$share50 <- (rowSums(acx[pred_cols]==50, na.rm=TRUE))/50\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in is.data.frame(x): object 'acx' not found\n```\n:::\n\n```{.r .cell-code}\n# subset data based on column names and calculate row sums\n\nacx_for_ag_wts %<>%\n   mutate(\n    user_name = row_number()\n    ) %>% \n mutate(\n   SATscoremath =  case_when(\n     (SATscoremath>800|SATscoremath<100) ~ NA_real_, \n     TRUE ~ SATscoremath),\n   SAT_math_rank = percent_rank(SATscoremath),\n    SAT_math_rank=\n     case_when(\n    is.na(SAT_math_rank) ~ mean(0.5, na.rm=TRUE),\n    TRUE ~ SAT_math_rank),\n   share50_qtl = percent_rank(share50) \n    ) %>% \n      mutate(across(c(ForecastingExperience, Superforecaster, Degree), ~replace(., is.na(.), \"No\"))) %>% \nmutate(\n  weight = \n    (ifelse(ForecastingExperience==\"No\",0.2,1))*\n    (ifelse(Superforecaster==\"Yes\",20,1))*\n    (1+((SAT_math_rank>0.5)*(Superforecaster!=\"Yes\")*(SAT_math_rank-0.5))*4)*\n    (1+(Degree==\"Ph D.\")*.5)*\n    (ifelse(`@1.WillVladimirPutinbePresidentofRussia`>=99,0.1,1))*\n    (ifelse(`@1.WillVladimirPutinbePresidentofRussia`< -0.05, 0.1,1))*\n  (1-(share50_qtl)/1.2) \n)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in mutate(., weight = (ifelse(ForecastingExperience == \"No\", 0.2, : could not find function \"mutate\"\n```\n:::\n\n```{.r .cell-code}\nacx_for_ag_wts_only <- acx_for_ag_wts %>% \n  select(user_name, weight)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in select(., user_name, weight): could not find function \"select\"\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nacx_for_ag_wts_long <- acx_for_ag_wts %>%  \n   select(where(~n_distinct(.) > 1)) %>%  #delete columns that are identical everywhere\n  pivot_longer( #each 'question' needs it's own row for each 'user'\n    contains(\"@\"),\n    names_to = \"paper_id\",\n    values_to = \"value\"\n    ) \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in pivot_longer(., contains(\"@\"), names_to = \"paper_id\", values_to = \"value\"): could not find function \"pivot_longer\"\n```\n:::\n\n```{.r .cell-code}\nacx_for_ag_wts_long %<>%  select(user_name, paper_id, value, everything()) %>%  #make all predictions (for an individual) into a row \n  mutate(element = \"three_point_best\",\n    round = \"round_2\") %>% #aggreCAT needs these things \n  group_by(paper_id) %>% \n  mutate(\n    value = \n    case_when(\n      is.na(value) ~ mean(value, na.rm=TRUE), #Sadly the package can't deal with NAs so I cheaply set them to the arithmetic average\n      value == 0.5 ~ mean(value, na.rm=TRUE),\n      TRUE ~ value\n  )\n  ) %>% ungroup  \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ungroup(.): could not find function \"ungroup\"\n```\n:::\n:::\n\n\n\nLet's see if it works\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacx_for_ag_wts_long %>%  \n  ungroup() %>% \n filter(paper_id==\"@1.WillVladimirPutinbePresidentofRussia\") %>%\n  filter(user_name<=154)  %>% \n  AverageWAgg(expert_judgements = ., \n            type = \"GeoMean\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ungroup(.): could not find function \"ungroup\"\n```\n:::\n\n```{.r .cell-code}\nacx_for_ag_wts_long %>%  \n  ungroup() %>% \nfilter(paper_id==\"@1.WillVladimirPutinbePresidentofRussia\") %>%\n  filter(user_name<=155)  %>% \n  AverageWAgg(expert_judgements = ., \n            type = \"GeoMean\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ungroup(.): could not find function \"ungroup\"\n```\n:::\n:::\n\n\nStrangely, this seems to only work here  with 155 or less rows!\n\nNow to do some funny calculations and blend them with my own predictions\n\n`acx_for_ag_wts_results`: The weighted arithmetic means\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacx_for_ag_wts_results <- acx_for_ag_wts_long %>%\n LinearWAgg(expert_judgements = ., \n            type = \"Participant\", \n   weights = acx_for_ag_wts_only\n    )\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in preprocess_judgements(., percent_toggle = {: object 'acx_for_ag_wts_long' not found\n```\n:::\n:::\n\n\n\nNow weighted geometric means\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweighted.geomean <- function(x, w, ...)\n{\n  return(prod(x^w, ...)^(1/sum(w, na.rm = TRUE)))\n}\n\nacx_for_ag_geom_wt <- acx_for_ag_wts_long %>%\n  group_by(paper_id) %>% \n    summarize(\n      w_geom_mean = weighted.geomean(value, weight)\n    )\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in summarize(., w_geom_mean = weighted.geomean(value, weight)): could not find function \"summarize\"\n```\n:::\n:::\n",
    "supporting": [
      "other_sections_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}