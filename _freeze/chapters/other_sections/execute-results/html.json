{
  "hash": "5349322490c9f78f47e33d7f886d94c9",
  "result": {
    "markdown": "# Other suggested sections\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(here(\"code\", \"methods_setup.R\"))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in here(\"code\", \"methods_setup.R\"): could not find function \"here\"\n```\n:::\n:::\n\n\n\n## 'Conjoint analysis' \n\nSee end of [this Slack thread](https://rethinkpriorities.slack.com/archives/G01962YABHB/p1670240321964009)\n\n\n## (Open and robust science: RP attitudes, discussions, resources) {#opensci}\n\nIntegrate from:\n\n[Reinstein discussions here](https://daaronr.github.io/metrics_discussion/robust-diag.html)\n\nCode to do [Robustness checks as a 'specification chart'](https://github.com/ArielOrtizBobea/spec_chart), and sensitivity analysis\n\nSource: https://pbs.twimg.com/media/ESyDHGjUYAYHfva?format=jpg&name=medium\n\n## (Meta-analysis) {#meta}\n\nIncorporate and consolidate from [Reinsteins meta notes](https://daaronr.github.io/metrics_discussion/metaanalysis.html) and more\n\n## Related:  'aggregating expert judgment' {-}\n\nTesting out the `AggreCAT` package on the ACX prediction contest\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Install aggreCAT\"}\ninstall.packages(\"devtools\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nInstalling devtools [2.4.5] ...\n\tOK [linked cache]\n```\n:::\n\n```{.r .cell-code  code-summary=\"Install aggreCAT\"}\n#install.packages(\"sessioninfo\", dependencies = TRUE)\n\ndevtools::install_github(\"metamelb-repliCATS/aggreCAT\")\n#Note: this failed initially because dependent packages needed updating.  `update.packages()` nay solve it. Nope, it didn't but all sorts of errors in that update\n\nlibrary(aggreCAT)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"input_acx_prediction_data\"}\nacx <- read_csv(here(\"sample_data\", \"acx_2023blindmode_predictions.csv\"))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in read_csv(here(\"sample_data\", \"acx_2023blindmode_predictions.csv\")): could not find function \"read_csv\"\n```\n:::\n\n```{.r .cell-code  code-summary=\"input_acx_prediction_data\"}\n#Improve: source from a hosted file or API\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"identify my own predictions\"}\nacx  %<>%  mutate(\n  d_reinstein =  ifelse(\n    `@1.WillVladimirPutinbePresidentofRussia`==82 & `@2.WillUkrainecontrolthecityofSevastopol`==54, TRUE, FALSE)\n)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in acx %<>% mutate(d_reinstein = ifelse(`@1.WillVladimirPutinbePresidentofRussia` == : could not find function \"%<>%\"\n```\n:::\n:::\n\n\n\nWhat can `aggreCAT` do for us? \n\nFirst testing this package with their built-in data.\n\n> Below we demonstrate how to use the most simple commonly implemented aggregation method ArMean, which takes the arithmetic mean of participant Best Estimates. We first use a small subset of 5 participants for a single claim, 28\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(data_ratings)\nset.seed(1234)\n\nparticipant_subset <- data_ratings %>% #just 5 users with names\n  distinct(user_name) %>%\n  sample_n(5) %>%\n  mutate(participant_name = paste(\"participant\", rep(1:n()))) #numbers rather than id codenames\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in mutate(., participant_name = paste(\"participant\", rep(1:n()))): could not find function \"mutate\"\n```\n:::\n\n```{.r .cell-code}\nsingle_claim <- data_ratings %>% \n  filter(paper_id == \"28\") %>% #all data on a single claim\n  right_join(participant_subset, by = \"user_name\") #join to the above 5 users (keeping only these 5)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in right_join(., participant_subset, by = \"user_name\"): could not find function \"right_join\"\n```\n:::\n\n```{.r .cell-code}\n#note this stat only uses the rows with element == `three_point_best`\nsingle_claim %>% \n  filter(element == \"three_point_best\") %>% \nAverageWAgg(expert_judgements = ., \n            type = \"ArMean\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in as.ts(x): object 'single_claim' not found\n```\n:::\n:::\n\n\nCan we do similar across multiple claims with this package?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_claims <- data_ratings %>% \n  right_join(participant_subset, by = \"user_name\")   #join to the above 5 users (keeping only these 5) \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in right_join(., participant_subset, by = \"user_name\"): could not find function \"right_join\"\n```\n:::\n\n```{.r .cell-code}\nall_claims %>% \n filter(element == \"three_point_best\") %>% \nAverageWAgg(expert_judgements = ., \n            type = \"ArMean\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in as.ts(x): object 'all_claims' not found\n```\n:::\n:::\n\n\nThis seems to work, at least with the data structured as they have it. Now what if we want multiple aggregation methods?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthree_aggregations <- purrr::map_dfr(.x = list(AverageWAgg, IntervalWAgg, ShiftingWAgg),\n                                .f = ~ .x(data_ratings))\n\nthree_aggregations %>%  tabyl(method)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in tabyl(., method): could not find function \"tabyl\"\n```\n:::\n:::\n\n\nNow let's see what can be done with our ACX dataset. As ACX doesn't ask for CIs (and doesn't have multiple rounds of expert revisions), `aggreCAT` may be of limited use here.^[I'd  have to estimate these bounds arbitrarily (e.g., make them larger for people with less experience). Only a subset of their measures may be informative.  First I'll check which ones might work, using *their* data for all aggregations (with baseline settings for each), but only keeping this 'best prediction' for each. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_aggsOK <- list(AverageWAgg,  IntervalWAgg, ShiftingWAgg, ExtremisationWAgg)\n\nall_aggs <- list(LinearWAgg, AverageWAgg, BayesianWAgg, IntervalWAgg, ShiftingWAgg, ReasoningWAgg, DistributionWAgg, ExtremisationWAgg)\n\n\nthree_aggs <- list(LinearWAgg, AverageWAgg, BayesianWAgg)\n\n\ndata_ratings %>% \n filter(element == \"three_point_best\") %>% \n  purrr::map_dfr(.x = all_aggsOK,\n                                .f = ~ .x(data_ratings)) %>%\n  tabsums(cs, method)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in tabsums(., cs, method): could not find function \"tabsums\"\n```\n:::\n:::\n\nAll of the aggregators seemed computable even without having elements other than 'three_point_best' What's going on here? E.g,. `IntervalWAgg` says 'the weights are dependent on the lower and upper bounds of three-point elicitation' ... but I left those out. 'ShiftingWAgg' is meant to depend on discussion; but here I have no indicators of that. Yet still, these all seem to come up with different means. `BetaARMean` which is meant to do some extremisation wotks rather strangely; shifting everything to 1, apparently.\n\n\nFocusing in on some key interesting methods... I've been told 'Geometric Means' are good in these sorts of situations\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_ratings %>% \n filter(element == \"three_point_best\") %>% \nAverageWAgg(expert_judgements = ., \n            type = \"GeoMean\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in filter(., element == \"three_point_best\"): object 'element' not found\n```\n:::\n:::\n\n\n\n`LinearWAgg` seems interesting, either suppliying some sort of weights by `Participant` (e.g., downweight those who haven't done forecasting), or with the supplied `GranWAgg` -- \"granularity of best estimates\"\n\nLet's move to trying to use these on the ACX data. First I adjust the data to make it more compatible with the aggreCAT package.\n\n\n::: {.callout-note collapse=\"true\"}\n## Note -- it cannot deal with NAs:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_ratings2 <- data_ratings\ndata_ratings2[4,6] <- NA_real_\n\ndata_ratings2 %>% \nAverageWAgg(expert_judgements = ., \n            type = \"GeoMean\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in `preprocess_judgements()`:\n! NAs Found in Values\n```\n:::\n:::\n\n::: \n\n\nUpweighting and downweighting people -- ad-hoc.\n\nNow, I have little time left, so I'll come up with some ad-hoc weights. \n\n\n::: {.callout-note collapse=\"false\"}\n## How to use what we know/what ACX suggested in aggregation\n\nWe have some idea of how different characteristics predicted success in previous prediction contests. Suppose I had a model that was good at predict in the accuracy of an individual's prediction, as a function of their demography, their other prediction, etc. How would I then use that (along with everyone's predictions), to come up with a good prediction aggregation?\n\nE.g., how should we map those into the 'weights' suggested? I'm not sure, and it would take me some time to figure this out. \n\n\n::: \n\nI guess I will do something lame and ad-hoc.  Everyone starts out with weight 1. \n\n1. Anyone who has no forecasting experience is downweighted fivefold (x0.2),\n2. Superforecasters are upweighted 20x\n3. SAT math uprated if above average (unless already a superforecaster)\n4. PHd upweighted 1.5x\n5. Downweight x 0.1 if you put 98+ or lt 4% chance of Putin being in power\n6. Downweight by quantile of share of 'exact 50% predictions' (up to about 90% downweighting)\n\n\nAlso, replace all '50% predictions' with the arithmetic average  (done later)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get column names starting with \"@\"\npred_cols <- colnames(acx)[startsWith(colnames(acx), \"@\")]\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in is.data.frame(x): object 'acx' not found\n```\n:::\n\n```{.r .cell-code}\nacx_for_ag_wts <- acx \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'acx' not found\n```\n:::\n\n```{.r .cell-code}\nacx_for_ag_wts$share50 <- (rowSums(acx[pred_cols]==50, na.rm=TRUE))/50\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in is.data.frame(x): object 'acx' not found\n```\n:::\n\n```{.r .cell-code}\n# subset data based on column names and calculate row sums\n\nacx_for_ag_wts %<>%\n   mutate(\n    user_name = row_number()\n    ) %>% \n mutate(\n   SATscoremath =  case_when(\n     (SATscoremath>800|SATscoremath<100) ~ NA_real_, \n     TRUE ~ SATscoremath),\n   SAT_math_rank = percent_rank(SATscoremath),\n    SAT_math_rank=\n     case_when(\n    is.na(SAT_math_rank) ~ mean(0.5, na.rm=TRUE),\n    TRUE ~ SAT_math_rank),\n   share50_qtl = percent_rank(share50) \n    ) %>% \n      mutate(across(c(ForecastingExperience, Superforecaster, Degree), ~replace(., is.na(.), \"No\"))) %>% \nmutate(\n  weight = \n    (ifelse(ForecastingExperience==\"No\",0.2,1))*\n    (ifelse(Superforecaster==\"Yes\",20,1))*\n    (1+((SAT_math_rank>0.5)*(Superforecaster!=\"Yes\")*(SAT_math_rank-0.5))*4)*\n    (1+(Degree==\"Ph D.\")*.5)*\n    (ifelse(`@1.WillVladimirPutinbePresidentofRussia`>=99,0.1,1))*\n    (ifelse(`@1.WillVladimirPutinbePresidentofRussia`< 5, 0.1,1))*\n  (1-(share50_qtl)/1.2) \n)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in mutate(., weight = (ifelse(ForecastingExperience == \"No\", 0.2, : could not find function \"mutate\"\n```\n:::\n\n```{.r .cell-code}\n#the code above is kind of crappy; better to convert it to logs to allow simple addition?\n\nacx_for_ag_wts_only <- acx_for_ag_wts %>% \n  select(user_name, weight)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in select(., user_name, weight): could not find function \"select\"\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nacx_for_ag_wts_long <- acx_for_ag_wts %>%  \n   select(where(~n_distinct(.) > 1)) %>%  #delete columns that are identical everywhere\n  pivot_longer( #each 'question' needs it's own row for each 'user'\n    contains(\"@\"),\n    names_to = \"paper_id\",\n    values_to = \"value\"\n    ) \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in pivot_longer(., contains(\"@\"), names_to = \"paper_id\", values_to = \"value\"): could not find function \"pivot_longer\"\n```\n:::\n\n```{.r .cell-code}\nacx_for_ag_wts_long %<>%  select(user_name, paper_id, value, everything()) %>%  #make all predictions (for an individual) into a row \n  mutate(element = \"three_point_best\",\n    round = \"round_2\") %>% #aggreCAT needs these things \n  group_by(paper_id) %>% \n  mutate(\n    value = \n    case_when(\n      is.na(value) ~ mean(value, na.rm=TRUE), #Sadly the package can't deal with NAs so I cheaply set them to the arithmetic average\n      value == 0.5 ~ mean(value, na.rm=TRUE),\n      TRUE ~ value\n  )\n  ) %>% ungroup  \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ungroup(.): could not find function \"ungroup\"\n```\n:::\n:::\n\n\n\nLet's see if it works\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacx_for_ag_wts_long %>%  \n  ungroup() %>% \n filter(paper_id==\"@1.WillVladimirPutinbePresidentofRussia\") %>%\n  filter(user_name<=154)  %>% \n  AverageWAgg(expert_judgements = ., \n            type = \"GeoMean\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ungroup(.): could not find function \"ungroup\"\n```\n:::\n\n```{.r .cell-code}\nacx_for_ag_wts_long %>%  \n  ungroup() %>% \nfilter(paper_id==\"@1.WillVladimirPutinbePresidentofRussia\") %>%\n  filter(user_name<=155)  %>% \n  AverageWAgg(expert_judgements = ., \n            type = \"GeoMean\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ungroup(.): could not find function \"ungroup\"\n```\n:::\n:::\n\n\nStrangely, this seems to only work here  with 155 or less rows!\n\nNow to do some funny calculations and blend them with my own predictions\n\n`acx_for_ag_wts_results`: The weighted arithmetic means\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacx_for_ag_wts_results <- acx_for_ag_wts_long %>%\n LinearWAgg(expert_judgements = ., \n            type = \"Participant\", \n   weights = acx_for_ag_wts_only\n    ) %>%  \n    mutate(agg = \"linear_wt\", \n      value = cs)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in mutate(., agg = \"linear_wt\", value = cs): could not find function \"mutate\"\n```\n:::\n:::\n\n\n\nNow (weighted?) geometric means\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweighted.geomean <- function(x, w, ...)\n{\n  return(prod(x^w, ...)^(1/sum(w, na.rm = TRUE)))\n}\n\nweighted.geomean <- function(x, w, ...) exp(weighted.mean(log(x), w, ...))\n\n\nsumwt <- sum(acx_for_ag_wts_long$weight[acx_for_ag_wts_long$weight>1], na.rm=TRUE)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'acx_for_ag_wts_long' not found\n```\n:::\n\n```{.r .cell-code}\nreg.geomean <- function(x, ...)\n{\n  return(prod(x, ...))\n}\n\nacx_for_ag_geom_wt <- acx_for_ag_wts_long %>%\n  filter(!is.na(weight)  & !is.na(value))  %>%\n  group_by(paper_id) %>% \n  mutate(\n    sumwt = sum(weight, na.rm=TRUE)\n   ) %>% \n    summarize(\n      weighted_geomean = weighted.geomean(value, weight),\n    ) %>% \n  mutate(agg = \"geom_wt\",\n    value = weighted_geomean)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in mutate(., agg = \"geom_wt\", value = weighted_geomean): could not find function \"mutate\"\n```\n:::\n:::\n\n\n\nOK, looks like I forgot about the prediction market data in [metaculus HERE](https://www.metaculus.com/project/2023-contest/) on the same thing.\n\nI'll make a tibble of the weighted linear mean, weighted geometric mean, metaculus data, my own predictions) \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#p_load(DataEditR)\n#metaculus_data <- acx_for_ag_wts_results %>% \n # select(paper_id)  %>% \n  #mutate(value=50)\n  \n\n#data_edit(metaculus_data)\n\n\nmetaculus_data <- read_csv(here(\"sample_data\", \"metaculus.csv\")) %>% \n  mutate(agg = \"metaculus\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in mutate(., agg = \"metaculus\"): could not find function \"mutate\"\n```\n:::\n\n```{.r .cell-code}\n#and me\n\nreinstein_pred <- acx %>%  \n  filter(d_reinstein) %>% \n  select(starts_with(\"@\")) %>% \n  pivot_longer(col=everything()) %>% \n  rename(paper_id = name) %>% \n  mutate(agg = 'reinstein_pred')\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in mutate(., agg = \"reinstein_pred\"): could not find function \"mutate\"\n```\n:::\n\n```{.r .cell-code}\naggregates <- bind_rows(reinstein_pred, metaculus_data, acx_for_ag_geom_wt, acx_for_ag_wts_results) %>%  \n  select(-method, -cs, -n_experts, -weighted_geomean) %>%  \n  pivot_wider(names_from=agg, id_cols = paper_id, values_from=value) %>% \n  mutate(guided_weight = 0.2*reinstein_pred + 0.4*metaculus + 0.2*linear_wt +  0.2*geom_wt,\n    final_impulsive_choice = guided_weight)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in mutate(., guided_weight = 0.2 * reinstein_pred + 0.4 * metaculus + : could not find function \"mutate\"\n```\n:::\n\n```{.r .cell-code}\nwrite_csv(aggregates, here(\"sample_data\", \"aggregates.csv\"))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in write_csv(aggregates, here(\"sample_data\", \"aggregates.csv\")): could not find function \"write_csv\"\n```\n:::\n\n```{.r .cell-code}\n#data_edit(aggregates)\n```\n:::\n\n\n\nFixed some stuff at end and cleaned it and made some ad-hoc extremizing around a few correlated events\n\n",
    "supporting": [
      "other_sections_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}