# Survey design, item dev. {#surveydesign}

This section will cover specific 'survey' related content, as well as some content that overlaps with experiments and trials.^M[ore technical and involved discussion of overlapping content will often be deferred to the 'experiments' related sections, with placeholders and links.]


## Some key resources and things to incorporte


- [Katja Grace, 'things I believe after making some surveys'](https://www.lesswrong.com/posts/oyKzz7bvcZMEPaDs6/survey-advice)   


-  Link or incorporate William Elsey's work [HERE](https://willemsleegers.github.io/how-to-science/content/methodology/survey-design/),

- and [Reinstein's sloppy notes here](https://daaronr.github.io/metrics_discussion/surveys.html) focusing on probability sampling and sampling rare populations; see embeds below

:::


## (Willem Sleegers, to incorporate)

[item development](https://willemsleegers.github.io/how-to-science/content/methodology/survey-design/item-development.html)

[wayback link](https://web.archive.org/web/20220630084700/https://willemsleegers.github.io/how-to-science/content/methodology/survey-design/item-development.html)

```{r }

knitr::include_url("https://willemsleegers.github.io/how-to-science/content/methodology/survey-design/item-development.html")

```

## Reinstein misc notes to incorporate {-}

```{r }

knitr::include_url("https://daaronr.github.io/metrics_discussion/surveys.html")

```

## Suggested sections...

**'Qualitative' issues** (hopefully backed by evidence)

- How to ask good survey questions

- Avoiding pitfalls (framing, agreeability bias, comprehension, attention,  etc.)

- Validating the measure is capturing 'the thing you intend'

\

**'Quantitative issues'**

- Constructing reliable indices and scales

- Sampling issues and representativeness
   - Elsey on "Mr P"
   - Reinstein on ['sampling'](https://daaronr.github.io/metrics_discussion/surveys.html#survey-samplingintake) and ['measuring a rare population'](https://daaronr.github.io/metrics_discussion/surveys.html#jazz-case) with reference to the EA survey

\




## Discussions to integrate


1. Disputing claim that "One doesn't need to worry about framing effects" because of Morewedge et al, 2015; Khan et al, 2006; Baumer et al, 2015 [private slack conversation link](https://rethinkpriorities.slack.com/archives/G01962YABHB/p1655407493604669)


2. In asking a series of attitude measures that have a natural order, present them in that order or randomize (e.g., [here](https://docs.google.com/document/d/16lmVZu9sjoHLceh8Zdgs8A_n4sxmZudahn7825ctRW4/edit#heading=h.gwnnifgo8qd)  https://docs.google.com/document/d/16lmVZu9sjoHLceh8Zdgs8A_n4sxmZudahn7825ctRW4/edit#heading=h.gwnnifgo8qd) ... I found it interesting, I am enthusiastic, I would definitely sign up, etc.)

> DR:   I see the case for increasing order is 'it makes it more clear for them to follow/more coherent to respond.  On the other hand, it could lead to less careful consideration of each response and a mechanical 'I better increase it'

> DM: If we want to test how many people will say they would be likely to do 1/2/3/4/5/6 I think we want to minimise the influence of order (or anything extraneous) on their likelihood of selecting 1/2/3/4/5/6. Ordering them by perceived commitment seems like it can only serve to nudge them in untoward ways to be more or less likely to select some.

> Also I don't think we have good grounds to predict what the order of increasing commitment is or to assume this is invariant across respondents.

> DR: OK, I see your point, if we actually  want to know, and see these as measures of how many people will do/think each of these things. As a 'measure of commitment and affinity' the ordering makes some sense to me.

