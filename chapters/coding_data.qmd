# Coding, data  {#coding}

Integrate further content from [getting, cleaning, and using data](https://daaronr.github.io/metrics_discussion/data-sci.html) (Reinstein,

## Coding and organisational issues

- Data protection (e.g., EA Survey data pre-2021 is not publicly shareable!)

- Good data management

- Reproducability

- Git and github

- R and Rmd

- How to leave comments and collaborate?

- `trackdown` to convert to Gdoc for feedback

- Folder structure, use of packages; esp `Renv`

- Functions etc pulled from `dr-rstuff` repo

- I (DR) love `lower_snake_case`

\

## Automation and 'dynamic documents' {-}

'Soft-code' as much as possible to avoid conflicting versions when data updates, and to make everything reproduceable and transparent

[Inline code in Rmd](https://bookdown.org/yihui/rmarkdown-cookbook/r-code.html) is great but it can be a double-edged sword.

Sometimes its better to 'do the important and complicated coding' in a chunk before this, not in the inline code itself because

- the 'bookdown' doesn't show the *code* generating the inline computation ... so a separate chunk makes it more transparent for external readers

- inline code isn't spaced well and its hard to read and debug.


## Data management

- Track it from its 'source'; use API to grab directly from Qualtrics (etc.) if possible

- A `main.R` file in the root directory should run everything

- Data import; external 'dictionary' can be helpful (see, e.g., [here](https://docs.google.com/spreadsheets/d/1dWy-CZxd9lzx0bLZ5ntmCSmwGPTrwjGcKpY4ORLom8E/edit#gid=0) for EAS integrated with Google sheet; R code [here](https://github.com/rethinkpriorities/ea-data/blob/master/build/fmt_label_with_dic_dhj_ok.R) brings it in

- import, cleaning, variable creation separate from analysis (unless its a very 'one-off-for-analysis' thing)
   - import and cleaning in `.R` rather than `.Rmd` perhaps

- 'raw' data in separate folder from 'munged' data

- `codebook` package -- make a codebook

- minimize 'versions' of the data frames ... code and use 'filter objects' instead
  - see ['lists of filters'](https://daaronr.github.io/metrics_discussion/data-sci.html#building-results-based-on-lists-of-filters-of-the-data-set) but actually defining the filter with `quo()` seems better.


## Standard cleaning steps

`janitor::remove_empty()` # removes empty rows and columns


## Naming columns and objects

`janitor::clean_names()` is a helpful shortcut to snake case


We sometimes input a 'dictionary' for renaming many columns at a time. ^[However, I don't think I found a tidy way to do the renaming, at least I can't remember it.]

`names(rename2020) <- eas_dictionary$true_name`




## Labelling columns

Some example code below




Put list of labels and renamings in objects in a separate location ... to avoid duplication and clutter:

```{r}

key_eas_all_labels <- c( #note these are converted to a list with as.list before assigning them
    donation_usd = "Donation (USD)",
    l_don_usd = "Log Don. (USD)",
    l_don_av_2yr = "Log Don. 'avg.'",
    ln_age = "Log age",
    don_av2_yr = "Don. 'avg'",
    donation_plan_usd = "Don. plan (USD)")
```

Variable labels are helpful

```{r}
eas_all %<>%
  labelled::set_variable_labels(.labels = as.list(key_eas_all_labels), .strict=FALSE)
```

