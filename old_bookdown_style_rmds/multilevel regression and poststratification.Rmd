---
title: "Multilevel regression and poststratification"
author: "Jamie Elsey"
date: "11/24/2021"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Intro

This document provides a practical guide to using multilevel regression and poststratification (MRP) in R. I follow the general procedure outlined by Kennedy and Gelman (https://doi.org/10.1037/met0000362). The goal of MRP is to produce parameter estimates (e.g., for voting, for support of a policy, for attitudes about animals) from potentially biased data that are more closely aligned to the population that one wishes to draw inferences about, relative to simply taking the estimate directly from the raw data. Notably, the procedure need not only be used to try and get some kind of 'general population' estimate. One may wish to generalise to a very specific, also non-representative population, and MRP also allows this.

The basic procedure for MRP is quite simple:
1. Gather data, including relevant features that may be important for 'rebalancing' the sample (e.g., sex and age - precisely what is chosen will depend on one's goals for generalisation)
2. Model the data including hierarchical components that allow the parameter estimates to vary according to the relevant features
3. Use the model to generate new, predicted data, feeding the model 'participants' in proportions that match the population to which you want to make inferences
4. Summarise/assess the predicted data, which should now be more representative of the target population than the raw data (assuming the raw data was indeed a biased sample)

It stands to reason that the validity of the predicted estimates hinges upon us having a good understanding/description of the population we wish to generalise to (i.e., the specific features expected in that population). If we completely miss or cannot properly weight by some feature that is perhaps unwittingly over-represented in our sample, and which also relates to the outcome of interest, then our estimates will be correspondingly off.

## Simulated example
To test the potential of this approach, I will use simulated data, because in that case we can have a clear benchmark against which to test how well our MRP procedure is working. We will simulate a hypothetical total population that we wish to draw inferences about, with demographic features that are associated with some outcome (say, concern over animal welfare). We will then select a biased sample from this population, and try to perform MRP on it. We will then see if by using MRP, we can generate estimates that are more representative of the actual population than our raw sample.

### Generate population and sample data
I use a clearly simplified set of features for demonstrative purpose: (Sex: M, F; Age: Under 30, 30-50, and 50+; Politics: Green, Labour, Conservative), and assign them some probabilities as they might appear in a total population (not trying to be very realistic with these!). I then make a set of proportions for a biased sample, that will skew younger, a bit more female, and with greater representation of Green and Labour voters:

```{r fake-proportions, message = FALSE, warning = FALSE}

library(tidyverse)
library(brms)
library(tidybayes)

# make categories
sex <- c('Male', 'Female')
politics <- c('Green', 'Labour', 'Conservative')
age <- c('Under 30', '30 to 50', 'Over 50')

# get all combos of categories in a tibble
population.features <- as_tibble(expand.grid(sex, politics, age))

# give the features to correct names
population.features <- population.features %>% 
  rename('sex' = Var1,
         'politics' = Var2,
         'age' = Var3)

# assign proportions to feature combinations in the population
population.features$pop.proportions <- c((.35 * .15 * .5),
                               (.35 * .15 * .5),
                               (.35 * .5 * .5),
                               (.35 * .5 * .5),
                               (.35 * .35 * .5),
                               (.35 * .35 * .5),
                               (.35 * .1 * .5),
                               (.35 * .1 * .5),
                               (.35 * .45 * .5),
                               (.35 * .45 * .5),
                               (.35 * .45 * .5),
                               (.35 * .45 * .5),
                               (.3 * .05 * .5),
                               (.3 * .05 * .5),
                               (.3 * .4 * .5),
                               (.3 * .4 * .5),
                               (.3 * .55 * .5),
                               (.3 * .55 * .5))

# assign proportions to feature combinations in the biased sample
population.features$sample.proportions <- c((.52 * .25 * .4),
                                            (.52 * .25 * .6),
                                            (.52 * .5 * .4),
                                            (.52 * .5 * .6),
                                            (.52 * .25 * .5),
                                            (.52 * .25 * .5),
                                            (.34 * .25* .4),
                                            (.34 * .25* .6),
                                            (.34 * .5  * .4),
                                            (.34 * .5  * .6),
                                            (.34 * .25 * .5),
                                            (.34 * .25 * .5),
                                            (.14 * .25 * .4),
                                            (.14 * .25 * .6),
                                            (.14 * .5 * .4),
                                            (.14 * .5 * .6),
                                            (.14 * .25 * .5),
                                            (.14 * .25 * .5))


```

After assigning the proportions, we make a function to generate a set number of participants from either the true population, or from a biased sample:

```{r generate-ppts, message = FALSE, warning = FALSE}

# function takes our designated proportions and creates row for each ppt
# with chosen features and sample size
pop.maker <- function(proportions, sample.size, type = 'population') {
  
  if(type == 'population') {
    n <- proportions[[1, 'pop.proportions']] * sample.size
  }
  else if(type == 'sample') {
    n <- proportions[[1, 'sample.proportions']] * sample.size
    }
  
  participants <- tibble(sex = rep(proportions[[1, 'sex']], n),
                         politics = rep(proportions[[1, 'politics']], n),
                         age = rep(proportions[[1, 'age']], n),
                         type = type)
  
  return(participants)
  
}

population.features.split <- population.features %>%
  group_by(sex, politics, age) %>%
  group_split()

bias.sample <- map_dfr(.x = population.features.split,
                       .f = pop.maker, sample.size = 4000,
                       type = 'sample')

population.tot <- map_dfr(.x = population.features.split,
                          .f = pop.maker, sample.size = 250000,
                          type = 'population')


```

We then generate responses for these participants, perhaps reflecting e.g., their concern over animal welfare. We imagine that being younger, being a Green voter especially, or being a Labour voter slightly, and being female, are each associate with larger reported concern over animal welfare. When we not plot a 'population' of 250k respondents vs. a biased sample of 4000 respondents who lean younger, more Green, and slightly more female, we can see that the sample mean represents an overestimate of the true population mean:

```{r get-responses, message = FALSE, warning = FALSE}

# add random noise for simulated data
bias.sample$noise <- rnorm(nrow(bias.sample), 3.5, 1)

# make different features be associated with different responses
bias.sample <- bias.sample %>% 
  mutate(sex.effect = case_when(sex == 'Male' ~ -.12,
                                                      sex == 'Female' ~ .25),
                            pol.effect = case_when(politics == 'Green' ~ 1,
                                                   politics == 'Labour' ~ .3,
                                                   politics == 'Conservative' ~ -.33),
                            age.effect = case_when(age == 'Under 30' ~ .75,
                                                   age == '30 to 50' ~ .1,
                                                   age == 'Over 50' ~ -.3),
                            response = noise + sex.effect + pol.effect + age.effect)

population.tot$noise <- rnorm(nrow(population.tot), 3.5, 1)
population.tot <- population.tot %>%
  mutate(sex.effect = case_when(sex == 'Male' ~ -.12,
                                                      sex == 'Female' ~ .25),
                            pol.effect = case_when(politics == 'Green' ~ 1,
                                                   politics == 'Labour' ~ .3,
                                                   politics == 'Conservative' ~ -.33),
                            age.effect = case_when(age == 'Under 30' ~ .75,
                                                   age == '30 to 50' ~ .1,
                                                   age == 'Over 50' ~ -.3),
                            response = noise + sex.effect + pol.effect + age.effect)

plot.data <- bind_rows(population.tot, bias.sample)

ggplot(data = plot.data) +
  scale_x_continuous(breaks = seq(from = 0, to = 8)) +
  geom_density(aes(x = response, fill = type), alpha = .33, linetype = 'blank') +
  geom_vline(data = population.tot, aes(xintercept = mean(response)), color = 'skyblue') +
  geom_vline(data = bias.sample, aes(xintercept = mean(response)), color = 'maroon') +
  scale_fill_manual(values = c('skyblue', 'maroon')) +
  theme_minimal()
```

### Run a multilevel regression
Now we run a multilevel regression on the data, allowing the value we wish to estimate to vary according to the variables we are interested in stratifying by. The formula, priors, and regression for this are presented below:

```{r multilevel-regression, message = FALSE, warning = FALSE}

# sex is a fixed effect because there are 2 levels
# we use hierarchical structure for age and politics
formula <- response ~ 1 + sex + (1 | age) + (1 | politics)

# priors might change with a different model
reg.prior <- c(set_prior("normal(3.5, 1.25)", class = "Intercept"),
               set_prior("normal(0 , 1)", class = "b"),
               set_prior("normal(0, 1.5)", class = "sigma"),
               set_prior("normal(0, 1.5)", class = "sd"))

ml.regression <- brm(formula = formula,
                     data = bias.sample,
                     family = gaussian(),
                     control = list(adapt_delta = .99,
                                    max_treedepth = 15),
                     chains = 3,
                     cores = 3,
                     iter = 3000,
                     warmup = 500,
                     prior = reg.prior)

ml.regression

```

### Post-stratify according to variables of interest and intended population for generalisation
Now all we need to do is make predicted values from our regression model, while feeding the model a 'sample' to predict from that matches the population to which we wish to generalise. In this case, our desired population is the overall population, for which we have information about the proportion of people with different feature combinations. To do this, we can use the same function above. When we generate the predicted values, we also request that they be made for mutliple draws from the posterior distribution, so that we also factor in an element of the Bayesian uncertainty around the estimates we receive.

```{r get-predicted-values, message = FALSE, warning = FALSE}

# for comparison, we will also run an estimate from the biased sample data
sample.predicted.values <- add_predicted_draws(newdata = bias.sample, 
                                               model = ml.regression, 
                                               n = 1000, # n draws from posterior
                                               scale = 'response')

# we ask for ~10000 new participants with feature proportions
# matching the population values
stratified.sample <- map_dfr(.x = population.features.split,
                             .f = pop.maker, sample.size = 10000, 
                             type = 'population')

stratified.predicted.values <- add_predicted_draws(newdata = stratified.sample,
                                                   model = ml.regression,
                                                   n = 1000, # n draws from posterior
                                                   scale = 'response')

```

Now we simply get the mean from each draw from the posterior and plot a posterior distribution for our estimate of the mean support. By overlaying the actual population mean and the sample mean (dashed lines), we can see that the estimate from the post-stratified sample (in blue) far more closely matches the population value that the estimate simply from our sample (in red).

```{r plot-poststratification, message = FALSE, warning = FALSE}

# function just to get the mean of each predicted sample
get.mean <- function(posterior) {
  
  output <- tibble(mean = mean(posterior$`.prediction`))
  
  return(output)
  
}

# group the predicted data by the posterior draw
# so we can summarise each draw
sample.predicted.values <- sample.predicted.values %>% 
  group_by(.draw) %>% 
  group_split()

stratified.predicted.values <- stratified.predicted.values %>% 
  group_by(.draw) %>% 
  group_split()

# run the predicted data through the mean-making function
sample.posterior.mean <- map_dfr(.x = sample.predicted.values,
                                 .f = get.mean)

stratified.posterior.mean <- map_dfr(.x = stratified.predicted.values,
                                     .f = get.mean)


# plot the predictions and true sample mean
ggplot(data = bias.sample) +
  scale_x_continuous(limits = c(3.5, 4.5),
                     breaks = seq(from = 3.5, to = 4.5, by = .25)) +
  geom_density(data = sample.posterior.mean,
               aes(x = mean), fill = 'maroon',
               alpha = .25, linetype = 'blank') +
  geom_density(data = stratified.posterior.mean,
               aes(x = mean), fill = 'skyblue',
               alpha = .25, linetype = 'blank') +
  geom_vline(data = stratified.posterior.mean,
             aes(xintercept = mean(mean)),
             color = 'skyblue') +
  geom_vline(data = sample.posterior.mean,
             aes(xintercept = mean(mean)),
             color = 'maroon') +
  geom_vline(aes(xintercept = mean(response)),
             color = 'maroon',
             linetype = 'dashed') +
  geom_vline(data = population.tot,
             aes(xintercept = mean(response)),
             color = 'skyblue',
             linetype = 'dashed') +
  theme_minimal()

```

### Summary
MRP allows one to reach estimates that more closely approach the true values of a target population from a biased sample than when basing estimates purely on the sample data. The extent to which this holds will depend on various factors, however. Our sample might too heavily under-represent certain groups to get a reasonable estimate for that class of people. In the analysis above, we also used a quite simple model of how the different features affect the outcome, but in reality there might be certain subgroups where several features interact to produce strikingly different or unexpected behavior. Hence, we do still need to be careful when drawing inferences from MRP with regards to their representativeness.